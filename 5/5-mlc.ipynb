{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fef4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ecbbdec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_path = './winequality-white.csv'\n",
    "wine_df = pd.read_csv(wine_path, delimiter=';')\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c4a9229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='quality', ylabel='count'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'quality', data=wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e232a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass classification의 target은 [0, n]\n",
    "# 현재 데이터셋의 target 범위는 [3, 9]\n",
    "# target 범위 [0, 6]으로 조정하기\n",
    "class2idx = {\n",
    "    3:0,\n",
    "    4:1,\n",
    "    5:2,\n",
    "    6:3,\n",
    "    7:4,\n",
    "    8:5,\n",
    "    9:6\n",
    "}\n",
    "\n",
    "idx2class = {v:k for k, v in class2idx.items()}\n",
    "\n",
    "wine_df['quality'].replace(class2idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff9e85a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 컬럼은 target\n",
    "X = wine_df.iloc[:, 0:-1]\n",
    "y = wine_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "afb8da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val, test 분리\n",
    "# 6:2:2\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cb8e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = torch.tensor(scaler.fit_transform(X_train))\n",
    "X_val_scaled = torch.tensor(scaler.transform(X_val))\n",
    "X_test_scaled = torch.tensor(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba350171",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(np.array(y_train))\n",
    "y_val = torch.tensor(np.array(y_val))\n",
    "y_test = torch.tensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8095555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target의 class별 데이터분포 계산\n",
    "def get_class_distribution(obj):\n",
    "    count_dict = {\n",
    "        '3': 0,\n",
    "        '4': 0,\n",
    "        '5': 0,\n",
    "        '6': 0,\n",
    "        '7': 0,\n",
    "        '8': 0,\n",
    "        '9': 0\n",
    "    }\n",
    "    \n",
    "    for i in obj:\n",
    "        if i == 0: \n",
    "            count_dict['3'] += 1\n",
    "        elif i == 1: \n",
    "            count_dict['4'] += 1\n",
    "        elif i == 2: \n",
    "            count_dict['5'] += 1\n",
    "        elif i == 3: \n",
    "            count_dict['6'] += 1\n",
    "        elif i == 4: \n",
    "            count_dict['7'] += 1  \n",
    "        elif i == 5: \n",
    "            count_dict['8'] += 1              \n",
    "        elif i == 6: \n",
    "            count_dict['9'] += 1              \n",
    "        else:\n",
    "            print('oops...')\n",
    "            \n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0fe443fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch Dataset 만들기\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "train_dataset = CustomDataset(X_train_scaled.float(), y_train.long())\n",
    "val_dataset = CustomDataset(X_val_scaled.float(), y_val.long())\n",
    "test_dataset = CustomDataset(X_test_scaled.float(), y_test.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "227fa67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버샘플링에 사용할 sampler 만들기\n",
    "# val, test는 모델 평가용 set이므로 오버샘플링 안해도 됨\n",
    "target_list = torch.tensor([target for target in train_dataset.y_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06abc64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = [i for i in get_class_distribution(y_train).values()]\n",
    "class_weights = 1.0 / torch.tensor(class_count, dtype=torch.float)\n",
    "class_weights_all = class_weights[target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0b52b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WeightedRandomSampler\n",
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights=class_weights_all,\n",
    "    num_samples=len(class_weights_all),\n",
    "    replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "06274e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 하이퍼파라미터\n",
    "EPOCHS = 4000\n",
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE = 0.0017\n",
    "\n",
    "NUM_FEATURES = len(X.columns)\n",
    "NUM_CLASSES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b30a9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch DataLoader\n",
    "# 오버샘플링 한 train_loader\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, sampler=weighted_sampler)\n",
    "# 오버샘플링 안한 train_loader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "27773018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch model\n",
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 512)\n",
    "        self.layer_2 = nn.Linear(512, 128)\n",
    "        self.layer_3 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(64, num_classes) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "82f5cc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# nvidia cuda 사용\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6b1d4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = MulticlassClassification(num_features=NUM_FEATURES, num_classes=NUM_CLASSES)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# multiclass classification loss\n",
    "# softmax 포함됨\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "# optimizer adam\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# learning rate decay\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9ecf70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 정확도 계산 함수\n",
    "def multi_accuracy(y_pred, y_target):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim=1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim=1)\n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_target).float()\n",
    "    accuracy = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    accuracy *= 100.0\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98996092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b12e4d8890b4fe7b3cc53a6c8b800a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001: | Train Loss: 1.9974 | Val Loss: 1.8482 | Train Acc: 29.93| Val Acc: 30.10\n",
      "Epoch 0002: | Train Loss: 1.7016 | Val Loss: 1.6958 | Train Acc: 29.65| Val Acc: 26.07\n",
      "Epoch 0003: | Train Loss: 1.5320 | Val Loss: 1.5631 | Train Acc: 30.19| Val Acc: 25.92\n",
      "Epoch 0004: | Train Loss: 1.4475 | Val Loss: 1.4730 | Train Acc: 30.70| Val Acc: 26.06\n",
      "Epoch 0005: | Train Loss: 1.3791 | Val Loss: 1.4080 | Train Acc: 31.18| Val Acc: 28.94\n",
      "Epoch 0006: | Train Loss: 1.2997 | Val Loss: 1.3689 | Train Acc: 32.58| Val Acc: 31.42\n",
      "Epoch 0007: | Train Loss: 1.2754 | Val Loss: 1.3621 | Train Acc: 34.90| Val Acc: 34.59\n",
      "Epoch 0008: | Train Loss: 1.1988 | Val Loss: 1.3732 | Train Acc: 36.54| Val Acc: 35.72\n",
      "Epoch 0009: | Train Loss: 1.1899 | Val Loss: 1.3930 | Train Acc: 38.08| Val Acc: 37.54\n",
      "Epoch 0010: | Train Loss: 1.1212 | Val Loss: 1.3635 | Train Acc: 37.27| Val Acc: 37.54\n",
      "Epoch 0011: | Train Loss: 1.0850 | Val Loss: 1.3541 | Train Acc: 39.05| Val Acc: 38.88\n",
      "Epoch 0012: | Train Loss: 1.0638 | Val Loss: 1.3419 | Train Acc: 38.88| Val Acc: 39.66\n",
      "Epoch 0013: | Train Loss: 1.0177 | Val Loss: 1.3596 | Train Acc: 40.67| Val Acc: 40.39\n",
      "Epoch 0014: | Train Loss: 1.0738 | Val Loss: 1.3180 | Train Acc: 41.69| Val Acc: 40.42\n",
      "Epoch 0015: | Train Loss: 0.9992 | Val Loss: 1.2435 | Train Acc: 40.09| Val Acc: 41.19\n",
      "Epoch 0016: | Train Loss: 0.9645 | Val Loss: 1.2736 | Train Acc: 41.01| Val Acc: 41.91\n",
      "Epoch 0017: | Train Loss: 0.9507 | Val Loss: 1.3779 | Train Acc: 41.25| Val Acc: 40.56\n",
      "Epoch 0018: | Train Loss: 0.9496 | Val Loss: 1.2884 | Train Acc: 42.91| Val Acc: 41.05\n",
      "Epoch 0019: | Train Loss: 0.9245 | Val Loss: 1.3349 | Train Acc: 41.99| Val Acc: 40.27\n",
      "Epoch 0020: | Train Loss: 0.9599 | Val Loss: 1.2765 | Train Acc: 40.93| Val Acc: 40.72\n",
      "Epoch 0021: | Train Loss: 0.8862 | Val Loss: 1.2222 | Train Acc: 42.76| Val Acc: 38.47\n",
      "Epoch 0022: | Train Loss: 0.8896 | Val Loss: 1.2771 | Train Acc: 43.24| Val Acc: 37.14\n",
      "Epoch 0023: | Train Loss: 0.8663 | Val Loss: 1.3778 | Train Acc: 41.44| Val Acc: 38.87\n",
      "Epoch 0024: | Train Loss: 0.8220 | Val Loss: 1.3635 | Train Acc: 42.82| Val Acc: 41.22\n",
      "Epoch 0025: | Train Loss: 0.8293 | Val Loss: 1.3205 | Train Acc: 43.88| Val Acc: 42.71\n",
      "Epoch 0026: | Train Loss: 0.8532 | Val Loss: 1.3650 | Train Acc: 44.59| Val Acc: 40.78\n",
      "Epoch 0027: | Train Loss: 0.8101 | Val Loss: 1.2858 | Train Acc: 44.55| Val Acc: 40.73\n",
      "Epoch 0028: | Train Loss: 0.7918 | Val Loss: 1.2079 | Train Acc: 45.38| Val Acc: 41.57\n",
      "Epoch 0029: | Train Loss: 0.8043 | Val Loss: 1.3290 | Train Acc: 44.94| Val Acc: 43.32\n",
      "Epoch 0030: | Train Loss: 0.7811 | Val Loss: 1.3848 | Train Acc: 45.43| Val Acc: 42.66\n",
      "Epoch 0031: | Train Loss: 0.7688 | Val Loss: 1.4819 | Train Acc: 46.52| Val Acc: 41.62\n",
      "Epoch 0032: | Train Loss: 0.7391 | Val Loss: 1.4667 | Train Acc: 45.36| Val Acc: 41.00\n",
      "Epoch 0033: | Train Loss: 0.7560 | Val Loss: 1.5677 | Train Acc: 46.85| Val Acc: 43.18\n",
      "Epoch 0034: | Train Loss: 0.7084 | Val Loss: 1.5651 | Train Acc: 47.63| Val Acc: 44.49\n",
      "Epoch 0035: | Train Loss: 0.7059 | Val Loss: 1.4763 | Train Acc: 48.17| Val Acc: 45.63\n",
      "Epoch 0036: | Train Loss: 0.7653 | Val Loss: 1.6573 | Train Acc: 48.17| Val Acc: 42.53\n",
      "Epoch 0037: | Train Loss: 0.7440 | Val Loss: 1.2153 | Train Acc: 47.18| Val Acc: 40.77\n",
      "Epoch 0038: | Train Loss: 0.7234 | Val Loss: 1.2873 | Train Acc: 46.81| Val Acc: 39.83\n",
      "Epoch 0039: | Train Loss: 0.6961 | Val Loss: 1.3593 | Train Acc: 48.59| Val Acc: 43.55\n",
      "Epoch 0040: | Train Loss: 0.7151 | Val Loss: 1.3744 | Train Acc: 48.77| Val Acc: 43.43\n",
      "Epoch 0041: | Train Loss: 0.6782 | Val Loss: 1.7231 | Train Acc: 49.69| Val Acc: 44.36\n",
      "Epoch 0042: | Train Loss: 0.7141 | Val Loss: 1.7526 | Train Acc: 47.08| Val Acc: 43.96\n",
      "Epoch 0043: | Train Loss: 0.6713 | Val Loss: 1.5733 | Train Acc: 49.60| Val Acc: 43.71\n",
      "Epoch 0044: | Train Loss: 0.6541 | Val Loss: 1.5295 | Train Acc: 50.36| Val Acc: 43.29\n",
      "Epoch 0045: | Train Loss: 0.6357 | Val Loss: 1.5081 | Train Acc: 50.45| Val Acc: 45.46\n",
      "Epoch 0046: | Train Loss: 0.6430 | Val Loss: 1.6869 | Train Acc: 52.23| Val Acc: 45.32\n",
      "Epoch 0047: | Train Loss: 0.6419 | Val Loss: 1.8347 | Train Acc: 52.26| Val Acc: 42.50\n",
      "Epoch 0048: | Train Loss: 0.7355 | Val Loss: 1.4979 | Train Acc: 51.56| Val Acc: 44.14\n",
      "Epoch 0049: | Train Loss: 0.6294 | Val Loss: 1.2531 | Train Acc: 51.41| Val Acc: 44.59\n",
      "Epoch 0050: | Train Loss: 0.6219 | Val Loss: 1.2904 | Train Acc: 52.85| Val Acc: 45.29\n",
      "Epoch 0051: | Train Loss: 0.6305 | Val Loss: 1.3912 | Train Acc: 51.97| Val Acc: 44.27\n",
      "Epoch 0052: | Train Loss: 0.6337 | Val Loss: 1.6125 | Train Acc: 52.95| Val Acc: 43.46\n",
      "Epoch 0053: | Train Loss: 0.6083 | Val Loss: 1.4866 | Train Acc: 52.40| Val Acc: 43.97\n",
      "Epoch 0054: | Train Loss: 0.6883 | Val Loss: 1.3779 | Train Acc: 51.68| Val Acc: 44.34\n",
      "Epoch 0055: | Train Loss: 0.6178 | Val Loss: 1.2558 | Train Acc: 51.28| Val Acc: 42.95\n",
      "Epoch 0056: | Train Loss: 0.6585 | Val Loss: 1.5376 | Train Acc: 49.86| Val Acc: 44.82\n",
      "Epoch 0057: | Train Loss: 0.6516 | Val Loss: 1.8016 | Train Acc: 50.83| Val Acc: 44.81\n",
      "Epoch 0058: | Train Loss: 0.6969 | Val Loss: 1.6848 | Train Acc: 51.25| Val Acc: 42.61\n",
      "Epoch 0059: | Train Loss: 0.6492 | Val Loss: 1.5451 | Train Acc: 51.70| Val Acc: 44.98\n",
      "Epoch 0060: | Train Loss: 0.6258 | Val Loss: 1.5021 | Train Acc: 51.28| Val Acc: 43.53\n",
      "Epoch 0061: | Train Loss: 0.6295 | Val Loss: 1.6423 | Train Acc: 51.19| Val Acc: 45.06\n",
      "Epoch 0062: | Train Loss: 0.5876 | Val Loss: 1.7181 | Train Acc: 53.12| Val Acc: 47.05\n",
      "Epoch 0063: | Train Loss: 0.5801 | Val Loss: 1.4293 | Train Acc: 53.46| Val Acc: 44.68\n",
      "Epoch 0064: | Train Loss: 0.5872 | Val Loss: 1.3595 | Train Acc: 53.39| Val Acc: 44.80\n",
      "Epoch 0065: | Train Loss: 0.5710 | Val Loss: 1.3312 | Train Acc: 53.62| Val Acc: 43.32\n",
      "Epoch 0066: | Train Loss: 0.5542 | Val Loss: 1.3887 | Train Acc: 53.67| Val Acc: 44.03\n",
      "Epoch 0067: | Train Loss: 0.5527 | Val Loss: 1.5038 | Train Acc: 55.04| Val Acc: 44.79\n",
      "Epoch 0068: | Train Loss: 0.5310 | Val Loss: 1.5737 | Train Acc: 54.94| Val Acc: 46.50\n",
      "Epoch 0069: | Train Loss: 0.5414 | Val Loss: 1.7940 | Train Acc: 57.40| Val Acc: 46.81\n",
      "Epoch 0070: | Train Loss: 0.5103 | Val Loss: 1.7703 | Train Acc: 56.96| Val Acc: 46.69\n",
      "Epoch 0071: | Train Loss: 0.5176 | Val Loss: 1.7336 | Train Acc: 57.06| Val Acc: 47.22\n",
      "Epoch 0072: | Train Loss: 0.5433 | Val Loss: 1.9989 | Train Acc: 56.75| Val Acc: 46.39\n",
      "Epoch 0073: | Train Loss: 0.4971 | Val Loss: 1.9824 | Train Acc: 58.07| Val Acc: 46.48\n",
      "Epoch 0074: | Train Loss: 0.5187 | Val Loss: 1.9504 | Train Acc: 58.33| Val Acc: 47.00\n",
      "Epoch 0075: | Train Loss: 0.5099 | Val Loss: 1.9475 | Train Acc: 57.51| Val Acc: 47.34\n",
      "Epoch 0076: | Train Loss: 0.5112 | Val Loss: 1.9096 | Train Acc: 58.63| Val Acc: 48.15\n",
      "Epoch 0077: | Train Loss: 0.5053 | Val Loss: 2.1296 | Train Acc: 58.92| Val Acc: 46.18\n",
      "Epoch 0078: | Train Loss: 0.4947 | Val Loss: 2.0247 | Train Acc: 57.50| Val Acc: 46.95\n",
      "Epoch 0079: | Train Loss: 0.4803 | Val Loss: 1.9172 | Train Acc: 58.79| Val Acc: 46.01\n",
      "Epoch 0080: | Train Loss: 0.4949 | Val Loss: 2.0467 | Train Acc: 58.01| Val Acc: 46.95\n",
      "Epoch 0081: | Train Loss: 0.4728 | Val Loss: 2.1770 | Train Acc: 59.67| Val Acc: 47.02\n",
      "Epoch 0082: | Train Loss: 0.4791 | Val Loss: 2.2387 | Train Acc: 59.13| Val Acc: 47.41\n",
      "Epoch 0083: | Train Loss: 0.4711 | Val Loss: 2.0554 | Train Acc: 59.58| Val Acc: 47.21\n",
      "Epoch 0084: | Train Loss: 0.4622 | Val Loss: 2.1020 | Train Acc: 60.94| Val Acc: 46.90\n",
      "Epoch 0085: | Train Loss: 0.4822 | Val Loss: 2.0477 | Train Acc: 60.15| Val Acc: 47.80\n",
      "Epoch 0086: | Train Loss: 0.4677 | Val Loss: 1.9194 | Train Acc: 59.79| Val Acc: 47.73\n",
      "Epoch 0087: | Train Loss: 0.4456 | Val Loss: 1.7035 | Train Acc: 60.17| Val Acc: 49.00\n",
      "Epoch 0088: | Train Loss: 0.4506 | Val Loss: 1.7514 | Train Acc: 61.20| Val Acc: 48.11\n",
      "Epoch 0089: | Train Loss: 0.4587 | Val Loss: 2.1202 | Train Acc: 60.53| Val Acc: 48.57\n",
      "Epoch 0090: | Train Loss: 0.4414 | Val Loss: 2.3602 | Train Acc: 60.99| Val Acc: 49.60\n",
      "Epoch 0091: | Train Loss: 0.4470 | Val Loss: 2.1320 | Train Acc: 60.35| Val Acc: 49.98\n",
      "Epoch 0092: | Train Loss: 0.4375 | Val Loss: 1.9502 | Train Acc: 61.92| Val Acc: 49.44\n",
      "Epoch 0093: | Train Loss: 0.4329 | Val Loss: 1.9034 | Train Acc: 62.74| Val Acc: 49.04\n",
      "Epoch 0094: | Train Loss: 0.4463 | Val Loss: 1.8833 | Train Acc: 62.15| Val Acc: 49.13\n",
      "Epoch 0095: | Train Loss: 0.4197 | Val Loss: 2.0774 | Train Acc: 63.34| Val Acc: 47.96\n",
      "Epoch 0096: | Train Loss: 0.4196 | Val Loss: 2.3303 | Train Acc: 62.31| Val Acc: 49.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0097: | Train Loss: 0.4153 | Val Loss: 2.3544 | Train Acc: 63.00| Val Acc: 50.02\n",
      "Epoch 0098: | Train Loss: 0.4072 | Val Loss: 2.3642 | Train Acc: 64.14| Val Acc: 50.36\n",
      "Epoch 0099: | Train Loss: 0.4285 | Val Loss: 2.6146 | Train Acc: 63.14| Val Acc: 51.41\n",
      "Epoch 0100: | Train Loss: 0.3930 | Val Loss: 2.6551 | Train Acc: 63.86| Val Acc: 50.92\n",
      "Epoch 0101: | Train Loss: 0.4034 | Val Loss: 2.5296 | Train Acc: 63.98| Val Acc: 48.87\n",
      "Epoch 0102: | Train Loss: 0.4093 | Val Loss: 2.2078 | Train Acc: 64.57| Val Acc: 47.62\n",
      "Epoch 0103: | Train Loss: 0.4070 | Val Loss: 2.1796 | Train Acc: 63.80| Val Acc: 49.84\n",
      "Epoch 0104: | Train Loss: 0.4135 | Val Loss: 2.1007 | Train Acc: 63.39| Val Acc: 50.01\n",
      "Epoch 0105: | Train Loss: 0.4098 | Val Loss: 2.4756 | Train Acc: 62.68| Val Acc: 50.73\n",
      "Epoch 0106: | Train Loss: 0.4025 | Val Loss: 2.7242 | Train Acc: 63.38| Val Acc: 50.42\n",
      "Epoch 0107: | Train Loss: 0.3988 | Val Loss: 2.6887 | Train Acc: 63.59| Val Acc: 49.30\n",
      "Epoch 0108: | Train Loss: 0.3921 | Val Loss: 2.5251 | Train Acc: 65.07| Val Acc: 49.48\n",
      "Epoch 0109: | Train Loss: 0.3817 | Val Loss: 2.4515 | Train Acc: 65.57| Val Acc: 50.51\n",
      "Epoch 0110: | Train Loss: 0.3897 | Val Loss: 2.3681 | Train Acc: 65.23| Val Acc: 49.40\n",
      "Epoch 0111: | Train Loss: 0.3851 | Val Loss: 2.3833 | Train Acc: 65.30| Val Acc: 49.39\n",
      "Epoch 0112: | Train Loss: 0.3843 | Val Loss: 2.4868 | Train Acc: 65.20| Val Acc: 50.79\n",
      "Epoch 0113: | Train Loss: 0.3655 | Val Loss: 2.7218 | Train Acc: 66.46| Val Acc: 52.07\n",
      "Epoch 0114: | Train Loss: 0.3670 | Val Loss: 2.5257 | Train Acc: 66.44| Val Acc: 48.73\n",
      "Epoch 0115: | Train Loss: 0.3669 | Val Loss: 2.3299 | Train Acc: 67.28| Val Acc: 49.57\n",
      "Epoch 0116: | Train Loss: 0.3579 | Val Loss: 2.4088 | Train Acc: 66.76| Val Acc: 51.20\n",
      "Epoch 0117: | Train Loss: 0.3583 | Val Loss: 2.3977 | Train Acc: 67.63| Val Acc: 51.50\n",
      "Epoch 0118: | Train Loss: 0.3614 | Val Loss: 2.5719 | Train Acc: 66.77| Val Acc: 51.31\n",
      "Epoch 0119: | Train Loss: 0.3559 | Val Loss: 2.4684 | Train Acc: 66.43| Val Acc: 53.03\n",
      "Epoch 0120: | Train Loss: 0.3445 | Val Loss: 2.5005 | Train Acc: 68.21| Val Acc: 52.53\n",
      "Epoch 0121: | Train Loss: 0.3429 | Val Loss: 2.4040 | Train Acc: 68.32| Val Acc: 51.77\n",
      "Epoch 0122: | Train Loss: 0.3505 | Val Loss: 2.5044 | Train Acc: 67.93| Val Acc: 52.61\n",
      "Epoch 0123: | Train Loss: 0.3337 | Val Loss: 2.6345 | Train Acc: 67.70| Val Acc: 52.90\n",
      "Epoch 0124: | Train Loss: 0.3577 | Val Loss: 2.7085 | Train Acc: 67.68| Val Acc: 52.04\n",
      "Epoch 0125: | Train Loss: 0.3546 | Val Loss: 2.7591 | Train Acc: 67.97| Val Acc: 52.06\n",
      "Epoch 0126: | Train Loss: 0.3665 | Val Loss: 2.8936 | Train Acc: 66.79| Val Acc: 52.74\n",
      "Epoch 0127: | Train Loss: 0.3449 | Val Loss: 2.6743 | Train Acc: 68.99| Val Acc: 53.54\n",
      "Epoch 0128: | Train Loss: 0.3348 | Val Loss: 2.6682 | Train Acc: 68.23| Val Acc: 54.85\n",
      "Epoch 0129: | Train Loss: 0.3260 | Val Loss: 2.8291 | Train Acc: 69.71| Val Acc: 53.52\n",
      "Epoch 0130: | Train Loss: 0.3348 | Val Loss: 2.6609 | Train Acc: 69.53| Val Acc: 53.73\n",
      "Epoch 0131: | Train Loss: 0.3297 | Val Loss: 3.0170 | Train Acc: 69.16| Val Acc: 53.22\n",
      "Epoch 0132: | Train Loss: 0.3180 | Val Loss: 3.3189 | Train Acc: 70.23| Val Acc: 51.36\n",
      "Epoch 0133: | Train Loss: 0.3229 | Val Loss: 2.9727 | Train Acc: 70.22| Val Acc: 51.80\n",
      "Epoch 0134: | Train Loss: 0.3499 | Val Loss: 2.9577 | Train Acc: 68.83| Val Acc: 52.25\n",
      "Epoch 0135: | Train Loss: 0.3253 | Val Loss: 2.5489 | Train Acc: 69.22| Val Acc: 51.98\n",
      "Epoch 0136: | Train Loss: 0.3588 | Val Loss: 2.6558 | Train Acc: 69.29| Val Acc: 51.18\n",
      "Epoch 0137: | Train Loss: 0.3390 | Val Loss: 2.6119 | Train Acc: 68.70| Val Acc: 50.31\n",
      "Epoch 0138: | Train Loss: 0.3521 | Val Loss: 2.5700 | Train Acc: 69.67| Val Acc: 50.57\n",
      "Epoch 0139: | Train Loss: 0.3389 | Val Loss: 2.7551 | Train Acc: 69.45| Val Acc: 51.99\n",
      "Epoch 0140: | Train Loss: 0.3386 | Val Loss: 2.7410 | Train Acc: 68.85| Val Acc: 55.14\n",
      "Epoch 0141: | Train Loss: 0.3269 | Val Loss: 2.7668 | Train Acc: 70.62| Val Acc: 52.46\n",
      "Epoch 0142: | Train Loss: 0.3167 | Val Loss: 2.5630 | Train Acc: 70.02| Val Acc: 51.83\n",
      "Epoch 0143: | Train Loss: 0.3339 | Val Loss: 2.3309 | Train Acc: 69.48| Val Acc: 54.46\n",
      "Epoch 0144: | Train Loss: 0.3346 | Val Loss: 2.0692 | Train Acc: 69.25| Val Acc: 52.96\n",
      "Epoch 0145: | Train Loss: 0.3546 | Val Loss: 2.2130 | Train Acc: 69.74| Val Acc: 51.15\n",
      "Epoch 0146: | Train Loss: 0.3574 | Val Loss: 2.6685 | Train Acc: 67.17| Val Acc: 52.44\n",
      "Epoch 0147: | Train Loss: 0.3572 | Val Loss: 2.9481 | Train Acc: 68.19| Val Acc: 51.62\n",
      "Epoch 0148: | Train Loss: 0.4093 | Val Loss: 2.0795 | Train Acc: 67.08| Val Acc: 51.63\n",
      "Epoch 0149: | Train Loss: 0.4315 | Val Loss: 2.1054 | Train Acc: 68.11| Val Acc: 51.93\n",
      "Epoch 0150: | Train Loss: 0.4101 | Val Loss: 2.2131 | Train Acc: 67.36| Val Acc: 52.66\n",
      "Epoch 0151: | Train Loss: 0.3831 | Val Loss: 2.3727 | Train Acc: 66.33| Val Acc: 51.46\n",
      "Epoch 0152: | Train Loss: 0.3490 | Val Loss: 2.3976 | Train Acc: 68.38| Val Acc: 51.85\n",
      "Epoch 0153: | Train Loss: 0.3557 | Val Loss: 2.4073 | Train Acc: 67.21| Val Acc: 52.26\n",
      "Epoch 0154: | Train Loss: 0.3314 | Val Loss: 2.5400 | Train Acc: 69.37| Val Acc: 52.05\n",
      "Epoch 0155: | Train Loss: 0.3332 | Val Loss: 2.4820 | Train Acc: 69.32| Val Acc: 52.79\n",
      "Epoch 0156: | Train Loss: 0.4242 | Val Loss: 2.1354 | Train Acc: 69.69| Val Acc: 51.46\n",
      "Epoch 0157: | Train Loss: 0.3444 | Val Loss: 2.0894 | Train Acc: 69.71| Val Acc: 54.60\n",
      "Epoch 0158: | Train Loss: 0.3592 | Val Loss: 2.0379 | Train Acc: 69.39| Val Acc: 53.64\n",
      "Epoch 0159: | Train Loss: 0.3225 | Val Loss: 2.1573 | Train Acc: 69.57| Val Acc: 52.36\n",
      "Epoch 0160: | Train Loss: 0.3318 | Val Loss: 2.3852 | Train Acc: 69.12| Val Acc: 52.61\n",
      "Epoch 0161: | Train Loss: 0.3281 | Val Loss: 2.6353 | Train Acc: 69.34| Val Acc: 52.75\n",
      "Epoch 0162: | Train Loss: 0.3447 | Val Loss: 2.2889 | Train Acc: 70.68| Val Acc: 52.13\n",
      "Epoch 0163: | Train Loss: 0.3759 | Val Loss: 2.3152 | Train Acc: 69.84| Val Acc: 52.96\n",
      "Epoch 0164: | Train Loss: 0.3573 | Val Loss: 2.1035 | Train Acc: 69.06| Val Acc: 54.43\n",
      "Epoch 0165: | Train Loss: 0.3387 | Val Loss: 2.2195 | Train Acc: 69.82| Val Acc: 53.03\n",
      "Epoch 0166: | Train Loss: 0.3392 | Val Loss: 2.3840 | Train Acc: 70.55| Val Acc: 52.34\n",
      "Epoch 0167: | Train Loss: 0.3183 | Val Loss: 2.2670 | Train Acc: 71.35| Val Acc: 54.12\n",
      "Epoch 0168: | Train Loss: 0.3176 | Val Loss: 2.2580 | Train Acc: 70.10| Val Acc: 53.31\n",
      "Epoch 0169: | Train Loss: 0.3089 | Val Loss: 2.3126 | Train Acc: 70.96| Val Acc: 55.33\n",
      "Epoch 0170: | Train Loss: 0.3085 | Val Loss: 2.5907 | Train Acc: 71.56| Val Acc: 56.22\n",
      "Epoch 0171: | Train Loss: 0.4692 | Val Loss: 2.5991 | Train Acc: 72.50| Val Acc: 53.05\n",
      "Epoch 0172: | Train Loss: 0.3839 | Val Loss: 1.9557 | Train Acc: 67.85| Val Acc: 47.73\n",
      "Epoch 0173: | Train Loss: 0.4447 | Val Loss: 1.8868 | Train Acc: 64.04| Val Acc: 50.43\n",
      "Epoch 0174: | Train Loss: 0.3876 | Val Loss: 2.1157 | Train Acc: 65.35| Val Acc: 52.29\n",
      "Epoch 0175: | Train Loss: 0.3956 | Val Loss: 2.2126 | Train Acc: 66.73| Val Acc: 51.89\n",
      "Epoch 0176: | Train Loss: 0.4004 | Val Loss: 2.0580 | Train Acc: 66.23| Val Acc: 52.70\n",
      "Epoch 0177: | Train Loss: 0.3813 | Val Loss: 1.8250 | Train Acc: 68.14| Val Acc: 51.49\n",
      "Epoch 0178: | Train Loss: 0.3881 | Val Loss: 1.9259 | Train Acc: 66.94| Val Acc: 50.69\n",
      "Epoch 0179: | Train Loss: 0.3780 | Val Loss: 2.0400 | Train Acc: 67.83| Val Acc: 51.11\n",
      "Epoch 0180: | Train Loss: 0.3683 | Val Loss: 2.2518 | Train Acc: 67.44| Val Acc: 54.83\n",
      "Epoch 0181: | Train Loss: 0.3690 | Val Loss: 2.3966 | Train Acc: 68.13| Val Acc: 53.01\n",
      "Epoch 0182: | Train Loss: 0.3446 | Val Loss: 2.3967 | Train Acc: 68.43| Val Acc: 54.35\n",
      "Epoch 0183: | Train Loss: 0.3333 | Val Loss: 2.3164 | Train Acc: 68.98| Val Acc: 54.15\n",
      "Epoch 0184: | Train Loss: 0.3227 | Val Loss: 2.2967 | Train Acc: 69.62| Val Acc: 53.12\n",
      "Epoch 0185: | Train Loss: 0.3045 | Val Loss: 2.2330 | Train Acc: 70.81| Val Acc: 55.26\n",
      "Epoch 0186: | Train Loss: 0.2856 | Val Loss: 2.2265 | Train Acc: 72.78| Val Acc: 54.89\n",
      "Epoch 0187: | Train Loss: 0.2869 | Val Loss: 2.3680 | Train Acc: 72.45| Val Acc: 56.76\n",
      "Epoch 0188: | Train Loss: 0.2867 | Val Loss: 2.4175 | Train Acc: 72.12| Val Acc: 53.44\n",
      "Epoch 0189: | Train Loss: 0.2658 | Val Loss: 2.4620 | Train Acc: 72.84| Val Acc: 54.36\n",
      "Epoch 0190: | Train Loss: 0.2662 | Val Loss: 2.5773 | Train Acc: 74.70| Val Acc: 56.22\n",
      "Epoch 0191: | Train Loss: 0.2623 | Val Loss: 2.6307 | Train Acc: 75.45| Val Acc: 55.60\n",
      "Epoch 0192: | Train Loss: 0.2593 | Val Loss: 2.5942 | Train Acc: 74.71| Val Acc: 54.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0193: | Train Loss: 0.2585 | Val Loss: 2.6599 | Train Acc: 74.89| Val Acc: 54.86\n",
      "Epoch 0194: | Train Loss: 0.2633 | Val Loss: 2.7438 | Train Acc: 74.86| Val Acc: 55.36\n",
      "Epoch 0195: | Train Loss: 0.2547 | Val Loss: 2.8930 | Train Acc: 75.83| Val Acc: 56.05\n",
      "Epoch 0196: | Train Loss: 0.2572 | Val Loss: 2.9361 | Train Acc: 75.01| Val Acc: 56.44\n",
      "Epoch 0197: | Train Loss: 0.2549 | Val Loss: 2.8091 | Train Acc: 75.64| Val Acc: 55.64\n",
      "Epoch 0198: | Train Loss: 0.2567 | Val Loss: 2.7092 | Train Acc: 74.79| Val Acc: 54.17\n",
      "Epoch 0199: | Train Loss: 0.2521 | Val Loss: 2.7575 | Train Acc: 75.93| Val Acc: 55.48\n",
      "Epoch 0200: | Train Loss: 0.2442 | Val Loss: 2.7911 | Train Acc: 76.30| Val Acc: 56.92\n",
      "Epoch 0201: | Train Loss: 0.2510 | Val Loss: 2.8942 | Train Acc: 76.34| Val Acc: 56.96\n",
      "Epoch 0202: | Train Loss: 0.2462 | Val Loss: 2.9851 | Train Acc: 76.47| Val Acc: 56.34\n",
      "Epoch 0203: | Train Loss: 0.2500 | Val Loss: 2.8775 | Train Acc: 75.28| Val Acc: 57.22\n",
      "Epoch 0204: | Train Loss: 0.2582 | Val Loss: 2.7374 | Train Acc: 76.69| Val Acc: 57.01\n",
      "Epoch 0205: | Train Loss: 0.2641 | Val Loss: 2.8758 | Train Acc: 75.63| Val Acc: 55.53\n",
      "Epoch 0206: | Train Loss: 0.2402 | Val Loss: 2.9390 | Train Acc: 76.11| Val Acc: 55.68\n",
      "Epoch 0207: | Train Loss: 0.2521 | Val Loss: 3.0346 | Train Acc: 76.36| Val Acc: 57.05\n",
      "Epoch 0208: | Train Loss: 0.2399 | Val Loss: 3.1667 | Train Acc: 76.55| Val Acc: 57.58\n",
      "Epoch 0209: | Train Loss: 0.2427 | Val Loss: 3.0684 | Train Acc: 77.17| Val Acc: 55.03\n",
      "Epoch 0210: | Train Loss: 0.2369 | Val Loss: 3.0613 | Train Acc: 77.18| Val Acc: 57.36\n",
      "Epoch 0211: | Train Loss: 0.2328 | Val Loss: 2.9829 | Train Acc: 76.76| Val Acc: 58.96\n",
      "Epoch 0212: | Train Loss: 0.2257 | Val Loss: 2.9529 | Train Acc: 78.31| Val Acc: 56.80\n",
      "Epoch 0213: | Train Loss: 0.2634 | Val Loss: 2.8599 | Train Acc: 76.31| Val Acc: 55.00\n",
      "Epoch 0214: | Train Loss: 0.2546 | Val Loss: 2.7601 | Train Acc: 76.07| Val Acc: 55.46\n",
      "Epoch 0215: | Train Loss: 0.2765 | Val Loss: 2.5943 | Train Acc: 74.05| Val Acc: 56.65\n",
      "Epoch 0216: | Train Loss: 0.2867 | Val Loss: 2.2459 | Train Acc: 72.67| Val Acc: 52.84\n",
      "Epoch 0217: | Train Loss: 0.2799 | Val Loss: 2.1735 | Train Acc: 72.29| Val Acc: 53.82\n",
      "Epoch 0218: | Train Loss: 0.2812 | Val Loss: 2.3171 | Train Acc: 74.40| Val Acc: 55.95\n",
      "Epoch 0219: | Train Loss: 0.2758 | Val Loss: 2.4836 | Train Acc: 74.64| Val Acc: 55.48\n",
      "Epoch 0220: | Train Loss: 0.2514 | Val Loss: 2.6823 | Train Acc: 76.05| Val Acc: 56.19\n",
      "Epoch 0221: | Train Loss: 0.2445 | Val Loss: 2.7506 | Train Acc: 75.46| Val Acc: 55.98\n",
      "Epoch 0222: | Train Loss: 0.2432 | Val Loss: 2.7807 | Train Acc: 76.09| Val Acc: 55.57\n",
      "Epoch 0223: | Train Loss: 0.2356 | Val Loss: 2.7796 | Train Acc: 77.21| Val Acc: 56.91\n",
      "Epoch 0224: | Train Loss: 0.2297 | Val Loss: 2.8441 | Train Acc: 78.56| Val Acc: 57.04\n",
      "Epoch 0225: | Train Loss: 0.2292 | Val Loss: 2.8695 | Train Acc: 77.98| Val Acc: 56.13\n",
      "Epoch 0226: | Train Loss: 0.2318 | Val Loss: 2.8517 | Train Acc: 78.57| Val Acc: 56.94\n",
      "Epoch 0227: | Train Loss: 0.2320 | Val Loss: 2.7131 | Train Acc: 78.22| Val Acc: 55.79\n",
      "Epoch 0228: | Train Loss: 0.2588 | Val Loss: 2.4973 | Train Acc: 77.43| Val Acc: 55.33\n",
      "Epoch 0229: | Train Loss: 0.2539 | Val Loss: 2.5905 | Train Acc: 75.29| Val Acc: 56.85\n",
      "Epoch 0230: | Train Loss: 0.2661 | Val Loss: 2.5454 | Train Acc: 76.10| Val Acc: 54.33\n",
      "Epoch 0231: | Train Loss: 0.2517 | Val Loss: 2.4794 | Train Acc: 77.13| Val Acc: 54.84\n",
      "Epoch 0232: | Train Loss: 0.2431 | Val Loss: 2.6714 | Train Acc: 77.17| Val Acc: 55.89\n",
      "Epoch 0233: | Train Loss: 0.2414 | Val Loss: 2.7754 | Train Acc: 77.37| Val Acc: 55.88\n",
      "Epoch 0234: | Train Loss: 0.2374 | Val Loss: 2.8157 | Train Acc: 77.31| Val Acc: 57.09\n",
      "Epoch 0235: | Train Loss: 0.2374 | Val Loss: 2.9828 | Train Acc: 77.24| Val Acc: 57.02\n",
      "Epoch 0236: | Train Loss: 0.2363 | Val Loss: 3.0234 | Train Acc: 78.19| Val Acc: 55.43\n",
      "Epoch 0237: | Train Loss: 0.2282 | Val Loss: 3.0778 | Train Acc: 78.83| Val Acc: 55.13\n",
      "Epoch 0238: | Train Loss: 0.2308 | Val Loss: 2.9298 | Train Acc: 78.00| Val Acc: 56.03\n",
      "Epoch 0239: | Train Loss: 0.2207 | Val Loss: 2.9553 | Train Acc: 78.77| Val Acc: 57.32\n",
      "Epoch 0240: | Train Loss: 0.2224 | Val Loss: 3.0150 | Train Acc: 78.64| Val Acc: 54.64\n",
      "Epoch 0241: | Train Loss: 0.2281 | Val Loss: 3.2369 | Train Acc: 78.78| Val Acc: 56.17\n",
      "Epoch 0242: | Train Loss: 0.2188 | Val Loss: 3.2400 | Train Acc: 79.36| Val Acc: 57.73\n",
      "Epoch 0243: | Train Loss: 0.2260 | Val Loss: 3.3147 | Train Acc: 79.63| Val Acc: 57.09\n",
      "Epoch 0244: | Train Loss: 0.2243 | Val Loss: 3.3806 | Train Acc: 79.07| Val Acc: 57.33\n",
      "Epoch 0245: | Train Loss: 0.2235 | Val Loss: 3.2428 | Train Acc: 78.53| Val Acc: 57.02\n",
      "Epoch 0246: | Train Loss: 0.2365 | Val Loss: 3.1849 | Train Acc: 79.31| Val Acc: 56.93\n",
      "Epoch 0247: | Train Loss: 0.2475 | Val Loss: 3.4394 | Train Acc: 77.69| Val Acc: 55.72\n",
      "Epoch 0248: | Train Loss: 0.2562 | Val Loss: 3.5155 | Train Acc: 77.00| Val Acc: 55.93\n",
      "Epoch 0249: | Train Loss: 0.2576 | Val Loss: 3.5322 | Train Acc: 76.47| Val Acc: 57.11\n",
      "Epoch 0250: | Train Loss: 0.2535 | Val Loss: 3.4623 | Train Acc: 76.67| Val Acc: 58.02\n",
      "Epoch 0251: | Train Loss: 0.3116 | Val Loss: 3.5937 | Train Acc: 75.95| Val Acc: 54.00\n",
      "Epoch 0252: | Train Loss: 0.3061 | Val Loss: 3.0258 | Train Acc: 73.16| Val Acc: 53.66\n",
      "Epoch 0253: | Train Loss: 0.2964 | Val Loss: 2.6845 | Train Acc: 73.93| Val Acc: 53.39\n",
      "Epoch 0254: | Train Loss: 0.2848 | Val Loss: 2.6940 | Train Acc: 74.90| Val Acc: 55.79\n",
      "Epoch 0255: | Train Loss: 0.2665 | Val Loss: 2.9102 | Train Acc: 74.24| Val Acc: 54.90\n",
      "Epoch 0256: | Train Loss: 0.2643 | Val Loss: 2.9902 | Train Acc: 75.86| Val Acc: 55.65\n",
      "Epoch 0257: | Train Loss: 0.2413 | Val Loss: 2.9195 | Train Acc: 77.93| Val Acc: 55.24\n",
      "Epoch 0258: | Train Loss: 0.2516 | Val Loss: 2.6765 | Train Acc: 77.15| Val Acc: 54.56\n",
      "Epoch 0259: | Train Loss: 0.3343 | Val Loss: 2.4261 | Train Acc: 76.90| Val Acc: 55.06\n",
      "Epoch 0260: | Train Loss: 0.2822 | Val Loss: 2.5656 | Train Acc: 73.77| Val Acc: 55.47\n",
      "Epoch 0261: | Train Loss: 0.3050 | Val Loss: 2.4779 | Train Acc: 73.52| Val Acc: 55.19\n",
      "Epoch 0262: | Train Loss: 0.2903 | Val Loss: 2.6345 | Train Acc: 73.59| Val Acc: 55.66\n",
      "Epoch 0263: | Train Loss: 0.2858 | Val Loss: 3.1399 | Train Acc: 74.04| Val Acc: 55.41\n",
      "Epoch 0264: | Train Loss: 0.2769 | Val Loss: 3.2630 | Train Acc: 73.55| Val Acc: 55.63\n",
      "Epoch 0265: | Train Loss: 0.2585 | Val Loss: 3.2973 | Train Acc: 75.73| Val Acc: 55.34\n",
      "Epoch 0266: | Train Loss: 0.2564 | Val Loss: 3.2631 | Train Acc: 76.30| Val Acc: 55.32\n",
      "Epoch 0267: | Train Loss: 0.2412 | Val Loss: 3.0597 | Train Acc: 77.64| Val Acc: 57.75\n",
      "Epoch 0268: | Train Loss: 0.2583 | Val Loss: 2.9021 | Train Acc: 76.32| Val Acc: 58.74\n",
      "Epoch 0269: | Train Loss: 0.2418 | Val Loss: 2.7913 | Train Acc: 78.61| Val Acc: 58.34\n",
      "Epoch 0270: | Train Loss: 0.2285 | Val Loss: 2.7427 | Train Acc: 78.62| Val Acc: 57.10\n",
      "Epoch 0271: | Train Loss: 0.2215 | Val Loss: 2.8248 | Train Acc: 79.08| Val Acc: 56.42\n",
      "Epoch 0272: | Train Loss: 0.2166 | Val Loss: 2.8814 | Train Acc: 79.34| Val Acc: 56.65\n",
      "Epoch 0273: | Train Loss: 0.2204 | Val Loss: 3.0588 | Train Acc: 79.38| Val Acc: 57.53\n",
      "Epoch 0274: | Train Loss: 0.2190 | Val Loss: 3.1208 | Train Acc: 79.53| Val Acc: 59.30\n",
      "Epoch 0275: | Train Loss: 0.2100 | Val Loss: 3.1610 | Train Acc: 79.81| Val Acc: 56.86\n",
      "Epoch 0276: | Train Loss: 0.2103 | Val Loss: 3.0779 | Train Acc: 79.08| Val Acc: 55.95\n",
      "Epoch 0277: | Train Loss: 0.2067 | Val Loss: 3.0995 | Train Acc: 80.69| Val Acc: 57.81\n",
      "Epoch 0278: | Train Loss: 0.1973 | Val Loss: 2.9922 | Train Acc: 80.53| Val Acc: 58.51\n",
      "Epoch 0279: | Train Loss: 0.2032 | Val Loss: 3.0411 | Train Acc: 81.18| Val Acc: 57.79\n",
      "Epoch 0280: | Train Loss: 0.1970 | Val Loss: 3.1735 | Train Acc: 81.03| Val Acc: 55.92\n",
      "Epoch 0281: | Train Loss: 0.1989 | Val Loss: 3.2306 | Train Acc: 80.67| Val Acc: 57.98\n",
      "Epoch 0282: | Train Loss: 0.1886 | Val Loss: 3.2635 | Train Acc: 82.41| Val Acc: 57.44\n",
      "Epoch 0283: | Train Loss: 0.1975 | Val Loss: 3.0924 | Train Acc: 81.68| Val Acc: 57.55\n",
      "Epoch 0284: | Train Loss: 0.1825 | Val Loss: 3.0321 | Train Acc: 82.78| Val Acc: 58.37\n",
      "Epoch 0285: | Train Loss: 0.1863 | Val Loss: 3.0887 | Train Acc: 82.02| Val Acc: 57.67\n",
      "Epoch 0286: | Train Loss: 0.1848 | Val Loss: 3.1381 | Train Acc: 81.38| Val Acc: 56.64\n",
      "Epoch 0287: | Train Loss: 0.1779 | Val Loss: 3.1458 | Train Acc: 82.40| Val Acc: 56.99\n",
      "Epoch 0288: | Train Loss: 0.1745 | Val Loss: 3.1406 | Train Acc: 82.94| Val Acc: 58.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0289: | Train Loss: 0.1616 | Val Loss: 3.3229 | Train Acc: 83.88| Val Acc: 59.36\n",
      "Epoch 0290: | Train Loss: 0.1783 | Val Loss: 3.2226 | Train Acc: 83.54| Val Acc: 59.20\n",
      "Epoch 0291: | Train Loss: 0.1675 | Val Loss: 2.9973 | Train Acc: 83.78| Val Acc: 58.38\n",
      "Epoch 0292: | Train Loss: 0.1612 | Val Loss: 2.8846 | Train Acc: 83.87| Val Acc: 58.63\n",
      "Epoch 0293: | Train Loss: 0.1792 | Val Loss: 2.9182 | Train Acc: 83.55| Val Acc: 57.98\n",
      "Epoch 0294: | Train Loss: 0.1717 | Val Loss: 2.9840 | Train Acc: 83.76| Val Acc: 59.23\n",
      "Epoch 0295: | Train Loss: 0.1719 | Val Loss: 3.0107 | Train Acc: 83.16| Val Acc: 60.02\n",
      "Epoch 0296: | Train Loss: 0.1774 | Val Loss: 3.2769 | Train Acc: 82.56| Val Acc: 58.80\n",
      "Epoch 0297: | Train Loss: 0.1652 | Val Loss: 3.4644 | Train Acc: 83.75| Val Acc: 58.38\n",
      "Epoch 0298: | Train Loss: 0.1707 | Val Loss: 3.4155 | Train Acc: 84.44| Val Acc: 59.15\n",
      "Epoch 0299: | Train Loss: 0.1715 | Val Loss: 3.3598 | Train Acc: 84.18| Val Acc: 58.70\n",
      "Epoch 0300: | Train Loss: 0.1659 | Val Loss: 3.5243 | Train Acc: 83.38| Val Acc: 56.53\n",
      "Epoch 0301: | Train Loss: 0.1682 | Val Loss: 3.5293 | Train Acc: 84.02| Val Acc: 58.46\n",
      "Epoch 0302: | Train Loss: 0.1648 | Val Loss: 3.6461 | Train Acc: 84.59| Val Acc: 57.80\n",
      "Epoch 0303: | Train Loss: 0.1558 | Val Loss: 3.7210 | Train Acc: 84.69| Val Acc: 58.61\n",
      "Epoch 0304: | Train Loss: 0.1604 | Val Loss: 3.6668 | Train Acc: 85.38| Val Acc: 58.72\n",
      "Epoch 0305: | Train Loss: 0.1554 | Val Loss: 3.5985 | Train Acc: 85.34| Val Acc: 60.12\n",
      "Epoch 0306: | Train Loss: 0.1560 | Val Loss: 3.6090 | Train Acc: 85.93| Val Acc: 59.57\n",
      "Epoch 0307: | Train Loss: 0.1508 | Val Loss: 3.5068 | Train Acc: 85.44| Val Acc: 59.88\n",
      "Epoch 0308: | Train Loss: 0.1510 | Val Loss: 3.4065 | Train Acc: 85.91| Val Acc: 59.91\n",
      "Epoch 0309: | Train Loss: 0.1549 | Val Loss: 3.3768 | Train Acc: 85.19| Val Acc: 60.14\n",
      "Epoch 0310: | Train Loss: 0.1467 | Val Loss: 3.4883 | Train Acc: 85.28| Val Acc: 59.93\n",
      "Epoch 0311: | Train Loss: 0.1449 | Val Loss: 3.5694 | Train Acc: 85.71| Val Acc: 59.63\n",
      "Epoch 0312: | Train Loss: 0.1510 | Val Loss: 3.4650 | Train Acc: 86.29| Val Acc: 59.96\n",
      "Epoch 0313: | Train Loss: 0.1487 | Val Loss: 3.5338 | Train Acc: 86.15| Val Acc: 59.30\n",
      "Epoch 0314: | Train Loss: 0.1450 | Val Loss: 3.4833 | Train Acc: 85.82| Val Acc: 59.65\n",
      "Epoch 0315: | Train Loss: 0.1477 | Val Loss: 3.5906 | Train Acc: 85.85| Val Acc: 58.89\n",
      "Epoch 0316: | Train Loss: 0.1408 | Val Loss: 3.6687 | Train Acc: 87.04| Val Acc: 59.96\n",
      "Epoch 0317: | Train Loss: 0.1446 | Val Loss: 3.4974 | Train Acc: 85.77| Val Acc: 60.64\n",
      "Epoch 0318: | Train Loss: 0.1365 | Val Loss: 3.3345 | Train Acc: 85.88| Val Acc: 58.63\n",
      "Epoch 0319: | Train Loss: 0.1437 | Val Loss: 3.3722 | Train Acc: 86.03| Val Acc: 59.46\n",
      "Epoch 0320: | Train Loss: 0.1384 | Val Loss: 3.4208 | Train Acc: 86.36| Val Acc: 60.07\n",
      "Epoch 0321: | Train Loss: 0.1354 | Val Loss: 3.5614 | Train Acc: 87.29| Val Acc: 59.65\n",
      "Epoch 0322: | Train Loss: 0.1343 | Val Loss: 3.6323 | Train Acc: 86.67| Val Acc: 61.08\n",
      "Epoch 0323: | Train Loss: 0.1453 | Val Loss: 3.5829 | Train Acc: 85.99| Val Acc: 60.85\n",
      "Epoch 0324: | Train Loss: 0.1402 | Val Loss: 3.4582 | Train Acc: 86.84| Val Acc: 60.57\n",
      "Epoch 0325: | Train Loss: 0.1407 | Val Loss: 3.4983 | Train Acc: 86.97| Val Acc: 59.17\n",
      "Epoch 0326: | Train Loss: 0.1350 | Val Loss: 3.5682 | Train Acc: 86.87| Val Acc: 59.03\n",
      "Epoch 0327: | Train Loss: 0.1372 | Val Loss: 3.6721 | Train Acc: 86.21| Val Acc: 60.63\n",
      "Epoch 0328: | Train Loss: 0.1343 | Val Loss: 3.6905 | Train Acc: 86.18| Val Acc: 61.12\n",
      "Epoch 0329: | Train Loss: 0.1293 | Val Loss: 3.7224 | Train Acc: 87.52| Val Acc: 60.41\n",
      "Epoch 0330: | Train Loss: 0.1233 | Val Loss: 3.8074 | Train Acc: 88.04| Val Acc: 59.53\n",
      "Epoch 0331: | Train Loss: 0.1326 | Val Loss: 3.8018 | Train Acc: 87.72| Val Acc: 60.98\n",
      "Epoch 0332: | Train Loss: 0.1317 | Val Loss: 3.8545 | Train Acc: 87.30| Val Acc: 59.14\n",
      "Epoch 0333: | Train Loss: 0.1314 | Val Loss: 3.7502 | Train Acc: 87.55| Val Acc: 58.91\n",
      "Epoch 0334: | Train Loss: 0.1354 | Val Loss: 3.7191 | Train Acc: 86.51| Val Acc: 60.80\n",
      "Epoch 0335: | Train Loss: 0.1311 | Val Loss: 3.5783 | Train Acc: 87.96| Val Acc: 59.78\n",
      "Epoch 0336: | Train Loss: 0.1296 | Val Loss: 3.5861 | Train Acc: 86.90| Val Acc: 60.05\n",
      "Epoch 0337: | Train Loss: 0.1526 | Val Loss: 3.6882 | Train Acc: 86.84| Val Acc: 61.18\n",
      "Epoch 0338: | Train Loss: 0.1864 | Val Loss: 4.1639 | Train Acc: 84.69| Val Acc: 59.50\n",
      "Epoch 0339: | Train Loss: 0.1660 | Val Loss: 3.9334 | Train Acc: 84.93| Val Acc: 58.26\n",
      "Epoch 0340: | Train Loss: 0.1684 | Val Loss: 4.4451 | Train Acc: 83.75| Val Acc: 60.05\n",
      "Epoch 0341: | Train Loss: 0.1675 | Val Loss: 4.3685 | Train Acc: 84.98| Val Acc: 60.06\n",
      "Epoch 0342: | Train Loss: 0.1658 | Val Loss: 4.0669 | Train Acc: 83.79| Val Acc: 59.25\n",
      "Epoch 0343: | Train Loss: 0.1657 | Val Loss: 4.1031 | Train Acc: 84.78| Val Acc: 60.54\n",
      "Epoch 0344: | Train Loss: 0.1610 | Val Loss: 4.3657 | Train Acc: 85.75| Val Acc: 59.96\n",
      "Epoch 0345: | Train Loss: 0.1565 | Val Loss: 4.2416 | Train Acc: 86.04| Val Acc: 59.63\n",
      "Epoch 0346: | Train Loss: 0.1451 | Val Loss: 3.8631 | Train Acc: 85.80| Val Acc: 58.89\n",
      "Epoch 0347: | Train Loss: 0.1475 | Val Loss: 3.9841 | Train Acc: 86.16| Val Acc: 58.28\n",
      "Epoch 0348: | Train Loss: 0.1384 | Val Loss: 4.0289 | Train Acc: 86.72| Val Acc: 59.44\n",
      "Epoch 0349: | Train Loss: 0.1371 | Val Loss: 3.8543 | Train Acc: 87.07| Val Acc: 58.28\n",
      "Epoch 0350: | Train Loss: 0.1553 | Val Loss: 3.8239 | Train Acc: 85.38| Val Acc: 59.18\n",
      "Epoch 0351: | Train Loss: 0.1525 | Val Loss: 4.1179 | Train Acc: 84.74| Val Acc: 59.24\n",
      "Epoch 0352: | Train Loss: 0.1369 | Val Loss: 4.3403 | Train Acc: 87.92| Val Acc: 59.73\n",
      "Epoch 0353: | Train Loss: 0.1407 | Val Loss: 4.3019 | Train Acc: 87.25| Val Acc: 59.82\n",
      "Epoch 0354: | Train Loss: 0.1273 | Val Loss: 4.3132 | Train Acc: 87.61| Val Acc: 59.55\n",
      "Epoch 0355: | Train Loss: 0.1365 | Val Loss: 4.2523 | Train Acc: 87.94| Val Acc: 60.74\n",
      "Epoch 0356: | Train Loss: 0.1377 | Val Loss: 4.0448 | Train Acc: 87.40| Val Acc: 62.00\n",
      "Epoch 0357: | Train Loss: 0.1322 | Val Loss: 3.9685 | Train Acc: 87.88| Val Acc: 61.69\n",
      "Epoch 0358: | Train Loss: 0.1179 | Val Loss: 4.0972 | Train Acc: 88.61| Val Acc: 59.59\n",
      "Epoch 0359: | Train Loss: 0.1256 | Val Loss: 4.0375 | Train Acc: 88.29| Val Acc: 59.56\n",
      "Epoch 0360: | Train Loss: 0.1307 | Val Loss: 3.7986 | Train Acc: 88.49| Val Acc: 59.02\n",
      "Epoch 0361: | Train Loss: 0.1621 | Val Loss: 3.7590 | Train Acc: 86.47| Val Acc: 58.85\n",
      "Epoch 0362: | Train Loss: 0.1583 | Val Loss: 3.7651 | Train Acc: 84.93| Val Acc: 61.70\n",
      "Epoch 0363: | Train Loss: 0.1460 | Val Loss: 4.0274 | Train Acc: 85.87| Val Acc: 61.03\n",
      "Epoch 0364: | Train Loss: 0.1692 | Val Loss: 4.2114 | Train Acc: 87.00| Val Acc: 59.52\n",
      "Epoch 0365: | Train Loss: 0.1641 | Val Loss: 4.1007 | Train Acc: 86.21| Val Acc: 60.08\n",
      "Epoch 0366: | Train Loss: 0.1528 | Val Loss: 4.0390 | Train Acc: 86.08| Val Acc: 60.73\n",
      "Epoch 0367: | Train Loss: 0.1645 | Val Loss: 3.8346 | Train Acc: 85.97| Val Acc: 59.77\n",
      "Epoch 0368: | Train Loss: 0.1515 | Val Loss: 3.8285 | Train Acc: 87.42| Val Acc: 58.50\n",
      "Epoch 0369: | Train Loss: 0.1544 | Val Loss: 4.0439 | Train Acc: 85.76| Val Acc: 58.13\n",
      "Epoch 0370: | Train Loss: 0.1626 | Val Loss: 4.1553 | Train Acc: 85.00| Val Acc: 58.45\n",
      "Epoch 0371: | Train Loss: 0.1623 | Val Loss: 4.1009 | Train Acc: 85.70| Val Acc: 58.40\n",
      "Epoch 0372: | Train Loss: 0.1463 | Val Loss: 4.3342 | Train Acc: 86.33| Val Acc: 60.02\n",
      "Epoch 0373: | Train Loss: 0.1486 | Val Loss: 4.1461 | Train Acc: 87.38| Val Acc: 60.36\n",
      "Epoch 0374: | Train Loss: 0.1464 | Val Loss: 4.1109 | Train Acc: 87.10| Val Acc: 59.43\n",
      "Epoch 0375: | Train Loss: 0.1441 | Val Loss: 4.2910 | Train Acc: 86.75| Val Acc: 60.03\n",
      "Epoch 0376: | Train Loss: 0.1381 | Val Loss: 4.4639 | Train Acc: 86.94| Val Acc: 60.37\n",
      "Epoch 0377: | Train Loss: 0.1277 | Val Loss: 4.1439 | Train Acc: 88.07| Val Acc: 60.29\n",
      "Epoch 0378: | Train Loss: 0.1270 | Val Loss: 3.8421 | Train Acc: 87.76| Val Acc: 60.33\n",
      "Epoch 0379: | Train Loss: 0.1309 | Val Loss: 3.8347 | Train Acc: 88.26| Val Acc: 60.07\n",
      "Epoch 0380: | Train Loss: 0.1240 | Val Loss: 3.9977 | Train Acc: 87.81| Val Acc: 60.95\n",
      "Epoch 0381: | Train Loss: 0.1319 | Val Loss: 4.3018 | Train Acc: 87.67| Val Acc: 61.63\n",
      "Epoch 0382: | Train Loss: 0.1304 | Val Loss: 4.4308 | Train Acc: 88.05| Val Acc: 59.03\n",
      "Epoch 0383: | Train Loss: 0.1271 | Val Loss: 4.3989 | Train Acc: 88.80| Val Acc: 60.37\n",
      "Epoch 0384: | Train Loss: 0.1303 | Val Loss: 4.5653 | Train Acc: 88.18| Val Acc: 59.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0385: | Train Loss: 0.1201 | Val Loss: 4.7216 | Train Acc: 88.45| Val Acc: 61.04\n",
      "Epoch 0386: | Train Loss: 0.1159 | Val Loss: 4.6609 | Train Acc: 89.70| Val Acc: 62.20\n",
      "Epoch 0387: | Train Loss: 0.1219 | Val Loss: 4.3713 | Train Acc: 88.79| Val Acc: 61.41\n",
      "Epoch 0388: | Train Loss: 0.1093 | Val Loss: 4.4122 | Train Acc: 88.82| Val Acc: 61.32\n",
      "Epoch 0389: | Train Loss: 0.1198 | Val Loss: 4.3723 | Train Acc: 89.46| Val Acc: 60.61\n",
      "Epoch 0390: | Train Loss: 0.1219 | Val Loss: 4.2020 | Train Acc: 88.80| Val Acc: 60.59\n",
      "Epoch 0391: | Train Loss: 0.1159 | Val Loss: 4.2119 | Train Acc: 88.45| Val Acc: 60.38\n",
      "Epoch 0392: | Train Loss: 0.1127 | Val Loss: 4.3571 | Train Acc: 88.82| Val Acc: 59.93\n",
      "Epoch 0393: | Train Loss: 0.1089 | Val Loss: 4.3766 | Train Acc: 90.20| Val Acc: 60.38\n",
      "Epoch 0394: | Train Loss: 0.1017 | Val Loss: 4.2271 | Train Acc: 90.62| Val Acc: 60.31\n",
      "Epoch 0395: | Train Loss: 0.1016 | Val Loss: 4.2794 | Train Acc: 90.09| Val Acc: 61.16\n",
      "Epoch 0396: | Train Loss: 0.1037 | Val Loss: 4.3472 | Train Acc: 90.81| Val Acc: 60.53\n",
      "Epoch 0397: | Train Loss: 0.1041 | Val Loss: 4.3031 | Train Acc: 90.34| Val Acc: 60.14\n",
      "Epoch 0398: | Train Loss: 0.1044 | Val Loss: 4.2587 | Train Acc: 89.96| Val Acc: 60.55\n",
      "Epoch 0399: | Train Loss: 0.0972 | Val Loss: 4.5513 | Train Acc: 90.89| Val Acc: 60.92\n",
      "Epoch 0400: | Train Loss: 0.0985 | Val Loss: 4.4108 | Train Acc: 91.06| Val Acc: 61.87\n",
      "Epoch 0401: | Train Loss: 0.1171 | Val Loss: 4.1886 | Train Acc: 90.72| Val Acc: 59.75\n",
      "Epoch 0402: | Train Loss: 0.1125 | Val Loss: 3.9643 | Train Acc: 89.78| Val Acc: 59.43\n",
      "Epoch 0403: | Train Loss: 0.1218 | Val Loss: 4.0556 | Train Acc: 88.73| Val Acc: 60.49\n",
      "Epoch 0404: | Train Loss: 0.1234 | Val Loss: 4.2443 | Train Acc: 88.94| Val Acc: 62.48\n",
      "Epoch 0405: | Train Loss: 0.1136 | Val Loss: 4.3998 | Train Acc: 88.50| Val Acc: 62.70\n",
      "Epoch 0406: | Train Loss: 0.1134 | Val Loss: 4.4668 | Train Acc: 88.63| Val Acc: 62.00\n",
      "Epoch 0407: | Train Loss: 0.1039 | Val Loss: 4.4602 | Train Acc: 89.94| Val Acc: 61.67\n",
      "Epoch 0408: | Train Loss: 0.1000 | Val Loss: 4.3451 | Train Acc: 90.89| Val Acc: 61.57\n",
      "Epoch 0409: | Train Loss: 0.1032 | Val Loss: 4.1972 | Train Acc: 90.75| Val Acc: 60.34\n",
      "Epoch 0410: | Train Loss: 0.0959 | Val Loss: 4.2139 | Train Acc: 91.57| Val Acc: 60.95\n",
      "Epoch 0411: | Train Loss: 0.0988 | Val Loss: 4.1196 | Train Acc: 90.57| Val Acc: 61.28\n",
      "Epoch 0412: | Train Loss: 0.1128 | Val Loss: 4.2894 | Train Acc: 89.53| Val Acc: 61.11\n",
      "Epoch 0413: | Train Loss: 0.1065 | Val Loss: 4.3008 | Train Acc: 90.06| Val Acc: 61.92\n",
      "Epoch 0414: | Train Loss: 0.1031 | Val Loss: 4.2061 | Train Acc: 89.92| Val Acc: 62.14\n",
      "Epoch 0415: | Train Loss: 0.0973 | Val Loss: 4.2504 | Train Acc: 91.24| Val Acc: 61.67\n",
      "Epoch 0416: | Train Loss: 0.0929 | Val Loss: 4.1771 | Train Acc: 91.49| Val Acc: 61.58\n",
      "Epoch 0417: | Train Loss: 0.0963 | Val Loss: 4.0768 | Train Acc: 91.76| Val Acc: 60.97\n",
      "Epoch 0418: | Train Loss: 0.0976 | Val Loss: 4.1999 | Train Acc: 91.54| Val Acc: 61.79\n",
      "Epoch 0419: | Train Loss: 0.1047 | Val Loss: 4.4713 | Train Acc: 91.18| Val Acc: 62.31\n",
      "Epoch 0420: | Train Loss: 0.0992 | Val Loss: 4.4956 | Train Acc: 90.14| Val Acc: 61.08\n",
      "Epoch 0421: | Train Loss: 0.0957 | Val Loss: 4.4520 | Train Acc: 90.82| Val Acc: 60.45\n",
      "Epoch 0422: | Train Loss: 0.1005 | Val Loss: 4.4715 | Train Acc: 90.95| Val Acc: 62.54\n",
      "Epoch 0423: | Train Loss: 0.0960 | Val Loss: 4.5425 | Train Acc: 91.35| Val Acc: 62.00\n",
      "Epoch 0424: | Train Loss: 0.0933 | Val Loss: 4.5289 | Train Acc: 91.82| Val Acc: 62.00\n",
      "Epoch 0425: | Train Loss: 0.0880 | Val Loss: 4.3372 | Train Acc: 91.19| Val Acc: 61.53\n",
      "Epoch 0426: | Train Loss: 0.1075 | Val Loss: 4.2132 | Train Acc: 91.31| Val Acc: 61.20\n",
      "Epoch 0427: | Train Loss: 0.1187 | Val Loss: 4.3259 | Train Acc: 89.99| Val Acc: 61.53\n",
      "Epoch 0428: | Train Loss: 0.1225 | Val Loss: 3.9941 | Train Acc: 89.12| Val Acc: 62.20\n",
      "Epoch 0429: | Train Loss: 0.1266 | Val Loss: 3.8464 | Train Acc: 89.55| Val Acc: 61.89\n",
      "Epoch 0430: | Train Loss: 0.1335 | Val Loss: 3.8549 | Train Acc: 88.37| Val Acc: 60.87\n",
      "Epoch 0431: | Train Loss: 0.1317 | Val Loss: 4.1307 | Train Acc: 87.41| Val Acc: 61.69\n",
      "Epoch 0432: | Train Loss: 0.1316 | Val Loss: 4.1060 | Train Acc: 87.76| Val Acc: 61.35\n",
      "Epoch 0433: | Train Loss: 0.1273 | Val Loss: 4.1504 | Train Acc: 89.22| Val Acc: 61.83\n",
      "Epoch 0434: | Train Loss: 0.1144 | Val Loss: 4.2071 | Train Acc: 90.09| Val Acc: 61.93\n",
      "Epoch 0435: | Train Loss: 0.1218 | Val Loss: 4.2113 | Train Acc: 89.36| Val Acc: 61.94\n",
      "Epoch 0436: | Train Loss: 0.1192 | Val Loss: 4.1630 | Train Acc: 88.62| Val Acc: 61.91\n",
      "Epoch 0437: | Train Loss: 0.1175 | Val Loss: 3.9669 | Train Acc: 90.02| Val Acc: 61.30\n",
      "Epoch 0438: | Train Loss: 0.1086 | Val Loss: 4.0326 | Train Acc: 90.05| Val Acc: 61.47\n",
      "Epoch 0439: | Train Loss: 0.1142 | Val Loss: 3.9787 | Train Acc: 89.50| Val Acc: 61.33\n",
      "Epoch 0440: | Train Loss: 0.1093 | Val Loss: 3.8304 | Train Acc: 89.91| Val Acc: 60.65\n",
      "Epoch 0441: | Train Loss: 0.1104 | Val Loss: 3.6884 | Train Acc: 90.62| Val Acc: 61.04\n",
      "Epoch 0442: | Train Loss: 0.1039 | Val Loss: 3.8122 | Train Acc: 90.42| Val Acc: 61.10\n",
      "Epoch 0443: | Train Loss: 0.1023 | Val Loss: 3.9806 | Train Acc: 90.60| Val Acc: 61.77\n",
      "Epoch 0444: | Train Loss: 0.1001 | Val Loss: 4.2030 | Train Acc: 90.41| Val Acc: 62.00\n",
      "Epoch 0445: | Train Loss: 0.0935 | Val Loss: 4.4599 | Train Acc: 91.67| Val Acc: 62.11\n",
      "Epoch 0446: | Train Loss: 0.0919 | Val Loss: 4.4953 | Train Acc: 91.63| Val Acc: 62.29\n",
      "Epoch 0447: | Train Loss: 0.0958 | Val Loss: 4.4262 | Train Acc: 91.85| Val Acc: 60.93\n",
      "Epoch 0448: | Train Loss: 0.1076 | Val Loss: 4.7099 | Train Acc: 89.98| Val Acc: 61.47\n",
      "Epoch 0449: | Train Loss: 0.0993 | Val Loss: 4.4119 | Train Acc: 90.77| Val Acc: 61.77\n",
      "Epoch 0450: | Train Loss: 0.0953 | Val Loss: 4.0863 | Train Acc: 91.85| Val Acc: 62.98\n",
      "Epoch 0451: | Train Loss: 0.0842 | Val Loss: 3.9669 | Train Acc: 92.41| Val Acc: 62.30\n",
      "Epoch 0452: | Train Loss: 0.0841 | Val Loss: 4.2398 | Train Acc: 91.86| Val Acc: 61.85\n",
      "Epoch 0453: | Train Loss: 0.0800 | Val Loss: 4.2342 | Train Acc: 92.24| Val Acc: 63.50\n",
      "Epoch 0454: | Train Loss: 0.0844 | Val Loss: 4.2927 | Train Acc: 92.54| Val Acc: 62.86\n",
      "Epoch 0455: | Train Loss: 0.0802 | Val Loss: 4.3121 | Train Acc: 93.36| Val Acc: 62.10\n",
      "Epoch 0456: | Train Loss: 0.0842 | Val Loss: 4.3360 | Train Acc: 92.39| Val Acc: 61.41\n",
      "Epoch 0457: | Train Loss: 0.0772 | Val Loss: 4.5196 | Train Acc: 92.38| Val Acc: 61.67\n",
      "Epoch 0458: | Train Loss: 0.0842 | Val Loss: 4.5139 | Train Acc: 91.98| Val Acc: 61.18\n",
      "Epoch 0459: | Train Loss: 0.0780 | Val Loss: 4.6654 | Train Acc: 93.08| Val Acc: 62.68\n",
      "Epoch 0460: | Train Loss: 0.0754 | Val Loss: 4.6562 | Train Acc: 92.78| Val Acc: 61.78\n",
      "Epoch 0461: | Train Loss: 0.0784 | Val Loss: 4.7577 | Train Acc: 93.07| Val Acc: 61.87\n",
      "Epoch 0462: | Train Loss: 0.0715 | Val Loss: 4.6554 | Train Acc: 93.54| Val Acc: 62.18\n",
      "Epoch 0463: | Train Loss: 0.0695 | Val Loss: 4.6582 | Train Acc: 93.66| Val Acc: 62.39\n",
      "Epoch 0464: | Train Loss: 0.0735 | Val Loss: 4.7271 | Train Acc: 93.05| Val Acc: 62.39\n",
      "Epoch 0465: | Train Loss: 0.0759 | Val Loss: 4.5991 | Train Acc: 93.24| Val Acc: 62.39\n",
      "Epoch 0466: | Train Loss: 0.0741 | Val Loss: 4.4514 | Train Acc: 93.62| Val Acc: 62.51\n",
      "Epoch 0467: | Train Loss: 0.0770 | Val Loss: 4.4766 | Train Acc: 92.59| Val Acc: 61.69\n",
      "Epoch 0468: | Train Loss: 0.0722 | Val Loss: 4.5024 | Train Acc: 93.57| Val Acc: 61.92\n",
      "Epoch 0469: | Train Loss: 0.0817 | Val Loss: 4.6464 | Train Acc: 92.82| Val Acc: 61.15\n",
      "Epoch 0470: | Train Loss: 0.0807 | Val Loss: 4.7769 | Train Acc: 92.83| Val Acc: 61.52\n",
      "Epoch 0471: | Train Loss: 0.0835 | Val Loss: 4.7973 | Train Acc: 92.27| Val Acc: 61.38\n",
      "Epoch 0472: | Train Loss: 0.0800 | Val Loss: 4.5346 | Train Acc: 92.52| Val Acc: 61.60\n",
      "Epoch 0473: | Train Loss: 0.0816 | Val Loss: 4.6189 | Train Acc: 92.85| Val Acc: 62.60\n",
      "Epoch 0474: | Train Loss: 0.0743 | Val Loss: 4.5538 | Train Acc: 93.04| Val Acc: 61.67\n",
      "Epoch 0475: | Train Loss: 0.0703 | Val Loss: 4.5200 | Train Acc: 94.09| Val Acc: 62.18\n",
      "Epoch 0476: | Train Loss: 0.0786 | Val Loss: 4.4757 | Train Acc: 92.73| Val Acc: 61.99\n",
      "Epoch 0477: | Train Loss: 0.1407 | Val Loss: 4.5420 | Train Acc: 92.64| Val Acc: 60.60\n",
      "Epoch 0478: | Train Loss: 0.1185 | Val Loss: 4.2279 | Train Acc: 90.75| Val Acc: 61.40\n",
      "Epoch 0479: | Train Loss: 0.1165 | Val Loss: 4.0401 | Train Acc: 90.40| Val Acc: 61.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0480: | Train Loss: 0.1191 | Val Loss: 4.1461 | Train Acc: 90.70| Val Acc: 60.75\n",
      "Epoch 0481: | Train Loss: 0.1625 | Val Loss: 4.8689 | Train Acc: 88.88| Val Acc: 60.50\n",
      "Epoch 0482: | Train Loss: 0.2196 | Val Loss: 4.7077 | Train Acc: 87.25| Val Acc: 59.47\n",
      "Epoch 0483: | Train Loss: 0.1990 | Val Loss: 4.1390 | Train Acc: 86.57| Val Acc: 59.53\n",
      "Epoch 0484: | Train Loss: 0.1793 | Val Loss: 4.0007 | Train Acc: 85.14| Val Acc: 58.70\n",
      "Epoch 0485: | Train Loss: 0.1809 | Val Loss: 4.1761 | Train Acc: 85.90| Val Acc: 56.78\n",
      "Epoch 0486: | Train Loss: 0.1718 | Val Loss: 4.5216 | Train Acc: 84.91| Val Acc: 60.14\n",
      "Epoch 0487: | Train Loss: 0.1778 | Val Loss: 4.1809 | Train Acc: 86.52| Val Acc: 59.48\n",
      "Epoch 0488: | Train Loss: 0.2054 | Val Loss: 4.2850 | Train Acc: 87.03| Val Acc: 60.76\n",
      "Epoch 0489: | Train Loss: 0.2281 | Val Loss: 4.3677 | Train Acc: 85.57| Val Acc: 60.19\n",
      "Epoch 0490: | Train Loss: 0.2218 | Val Loss: 3.8604 | Train Acc: 85.39| Val Acc: 57.65\n",
      "Epoch 0491: | Train Loss: 0.2460 | Val Loss: 3.0984 | Train Acc: 82.44| Val Acc: 58.33\n",
      "Epoch 0492: | Train Loss: 0.2619 | Val Loss: 2.9057 | Train Acc: 81.43| Val Acc: 56.38\n",
      "Epoch 0493: | Train Loss: 0.2376 | Val Loss: 3.0649 | Train Acc: 81.67| Val Acc: 57.65\n",
      "Epoch 0494: | Train Loss: 0.2031 | Val Loss: 3.3098 | Train Acc: 81.39| Val Acc: 58.36\n",
      "Epoch 0495: | Train Loss: 0.2042 | Val Loss: 3.7380 | Train Acc: 84.59| Val Acc: 58.22\n",
      "Epoch 0496: | Train Loss: 0.1965 | Val Loss: 3.8586 | Train Acc: 83.18| Val Acc: 58.45\n",
      "Epoch 0497: | Train Loss: 0.1642 | Val Loss: 3.9416 | Train Acc: 85.93| Val Acc: 60.24\n",
      "Epoch 0498: | Train Loss: 0.1500 | Val Loss: 4.0276 | Train Acc: 86.47| Val Acc: 59.97\n",
      "Epoch 0499: | Train Loss: 0.1659 | Val Loss: 3.8088 | Train Acc: 85.69| Val Acc: 59.66\n",
      "Epoch 0500: | Train Loss: 0.1576 | Val Loss: 3.4750 | Train Acc: 86.61| Val Acc: 60.82\n",
      "Epoch 0501: | Train Loss: 0.1536 | Val Loss: 3.9286 | Train Acc: 87.17| Val Acc: 61.34\n",
      "Epoch 0502: | Train Loss: 0.1531 | Val Loss: 4.3027 | Train Acc: 86.62| Val Acc: 61.21\n",
      "Epoch 0503: | Train Loss: 0.1484 | Val Loss: 4.1872 | Train Acc: 86.99| Val Acc: 60.75\n",
      "Epoch 0504: | Train Loss: 0.1272 | Val Loss: 4.1242 | Train Acc: 88.76| Val Acc: 60.48\n",
      "Epoch 0505: | Train Loss: 0.1205 | Val Loss: 4.2709 | Train Acc: 88.88| Val Acc: 60.35\n",
      "Epoch 0506: | Train Loss: 0.1225 | Val Loss: 4.1508 | Train Acc: 89.14| Val Acc: 60.58\n",
      "Epoch 0507: | Train Loss: 0.1119 | Val Loss: 4.0336 | Train Acc: 89.81| Val Acc: 60.87\n",
      "Epoch 0508: | Train Loss: 0.1176 | Val Loss: 4.0386 | Train Acc: 90.15| Val Acc: 61.56\n",
      "Epoch 0509: | Train Loss: 0.1163 | Val Loss: 3.8164 | Train Acc: 89.38| Val Acc: 59.54\n",
      "Epoch 0510: | Train Loss: 0.1257 | Val Loss: 3.7381 | Train Acc: 89.41| Val Acc: 60.26\n",
      "Epoch 0511: | Train Loss: 0.1129 | Val Loss: 3.7542 | Train Acc: 89.14| Val Acc: 62.02\n",
      "Epoch 0512: | Train Loss: 0.1068 | Val Loss: 3.7822 | Train Acc: 90.39| Val Acc: 60.87\n",
      "Epoch 0513: | Train Loss: 0.1037 | Val Loss: 3.8857 | Train Acc: 90.54| Val Acc: 61.93\n",
      "Epoch 0514: | Train Loss: 0.0968 | Val Loss: 3.8409 | Train Acc: 91.47| Val Acc: 62.11\n",
      "Epoch 0515: | Train Loss: 0.0873 | Val Loss: 3.9449 | Train Acc: 92.11| Val Acc: 62.25\n",
      "Epoch 0516: | Train Loss: 0.1018 | Val Loss: 4.0940 | Train Acc: 90.58| Val Acc: 61.12\n",
      "Epoch 0517: | Train Loss: 0.0960 | Val Loss: 4.1924 | Train Acc: 91.31| Val Acc: 60.59\n",
      "Epoch 0518: | Train Loss: 0.0964 | Val Loss: 4.1544 | Train Acc: 90.87| Val Acc: 61.65\n",
      "Epoch 0519: | Train Loss: 0.1386 | Val Loss: 4.1636 | Train Acc: 91.86| Val Acc: 61.89\n",
      "Epoch 0520: | Train Loss: 0.1120 | Val Loss: 4.2385 | Train Acc: 91.12| Val Acc: 60.48\n",
      "Epoch 0521: | Train Loss: 0.1030 | Val Loss: 4.4083 | Train Acc: 90.59| Val Acc: 60.66\n",
      "Epoch 0522: | Train Loss: 0.0990 | Val Loss: 4.7092 | Train Acc: 90.83| Val Acc: 59.95\n",
      "Epoch 0523: | Train Loss: 0.1068 | Val Loss: 4.7887 | Train Acc: 90.79| Val Acc: 61.39\n",
      "Epoch 0524: | Train Loss: 0.0985 | Val Loss: 4.4971 | Train Acc: 91.69| Val Acc: 61.80\n",
      "Epoch 0525: | Train Loss: 0.0949 | Val Loss: 4.3195 | Train Acc: 91.71| Val Acc: 60.67\n",
      "Epoch 0526: | Train Loss: 0.0932 | Val Loss: 4.2698 | Train Acc: 90.76| Val Acc: 60.47\n",
      "Epoch 0527: | Train Loss: 0.0854 | Val Loss: 4.2770 | Train Acc: 91.65| Val Acc: 60.56\n",
      "Epoch 0528: | Train Loss: 0.0831 | Val Loss: 4.3688 | Train Acc: 92.48| Val Acc: 60.86\n",
      "Epoch 0529: | Train Loss: 0.0805 | Val Loss: 4.3501 | Train Acc: 92.38| Val Acc: 61.02\n",
      "Epoch 0530: | Train Loss: 0.0881 | Val Loss: 4.3746 | Train Acc: 92.11| Val Acc: 61.93\n",
      "Epoch 0531: | Train Loss: 0.0831 | Val Loss: 4.4255 | Train Acc: 93.11| Val Acc: 62.17\n",
      "Epoch 0532: | Train Loss: 0.0841 | Val Loss: 4.4522 | Train Acc: 92.06| Val Acc: 62.28\n",
      "Epoch 0533: | Train Loss: 0.0899 | Val Loss: 4.3264 | Train Acc: 91.38| Val Acc: 61.09\n",
      "Epoch 0534: | Train Loss: 0.0835 | Val Loss: 4.2900 | Train Acc: 92.11| Val Acc: 61.01\n",
      "Epoch 0535: | Train Loss: 0.0891 | Val Loss: 4.4395 | Train Acc: 92.46| Val Acc: 60.31\n",
      "Epoch 0536: | Train Loss: 0.0814 | Val Loss: 4.5669 | Train Acc: 92.47| Val Acc: 60.95\n",
      "Epoch 0537: | Train Loss: 0.0811 | Val Loss: 4.5889 | Train Acc: 92.77| Val Acc: 61.70\n",
      "Epoch 0538: | Train Loss: 0.0821 | Val Loss: 4.5837 | Train Acc: 92.98| Val Acc: 61.34\n",
      "Epoch 0539: | Train Loss: 0.0800 | Val Loss: 4.4654 | Train Acc: 92.64| Val Acc: 61.99\n",
      "Epoch 0540: | Train Loss: 0.0796 | Val Loss: 4.4698 | Train Acc: 93.53| Val Acc: 61.49\n",
      "Epoch 0541: | Train Loss: 0.0724 | Val Loss: 4.5680 | Train Acc: 93.04| Val Acc: 60.86\n",
      "Epoch 0542: | Train Loss: 0.0757 | Val Loss: 4.5859 | Train Acc: 93.68| Val Acc: 62.53\n",
      "Epoch 0543: | Train Loss: 0.0716 | Val Loss: 4.4876 | Train Acc: 93.44| Val Acc: 63.03\n",
      "Epoch 0544: | Train Loss: 0.0723 | Val Loss: 4.4705 | Train Acc: 94.12| Val Acc: 62.30\n",
      "Epoch 0545: | Train Loss: 0.0723 | Val Loss: 4.4154 | Train Acc: 93.84| Val Acc: 61.60\n",
      "Epoch 0546: | Train Loss: 0.0629 | Val Loss: 4.4944 | Train Acc: 94.33| Val Acc: 62.07\n",
      "Epoch 0547: | Train Loss: 0.0674 | Val Loss: 4.5455 | Train Acc: 94.17| Val Acc: 61.37\n",
      "Epoch 0548: | Train Loss: 0.0659 | Val Loss: 4.4850 | Train Acc: 94.12| Val Acc: 60.65\n",
      "Epoch 0549: | Train Loss: 0.0687 | Val Loss: 4.5251 | Train Acc: 93.88| Val Acc: 61.88\n",
      "Epoch 0550: | Train Loss: 0.0590 | Val Loss: 4.6798 | Train Acc: 94.80| Val Acc: 61.49\n",
      "Epoch 0551: | Train Loss: 0.0665 | Val Loss: 4.7089 | Train Acc: 94.18| Val Acc: 61.24\n",
      "Epoch 0552: | Train Loss: 0.0649 | Val Loss: 4.7867 | Train Acc: 94.27| Val Acc: 61.07\n",
      "Epoch 0553: | Train Loss: 0.0641 | Val Loss: 4.8334 | Train Acc: 94.72| Val Acc: 61.85\n",
      "Epoch 0554: | Train Loss: 0.0643 | Val Loss: 4.8593 | Train Acc: 94.21| Val Acc: 61.97\n",
      "Epoch 0555: | Train Loss: 0.0667 | Val Loss: 4.8740 | Train Acc: 93.99| Val Acc: 61.90\n",
      "Epoch 0556: | Train Loss: 0.0622 | Val Loss: 4.7960 | Train Acc: 94.50| Val Acc: 62.09\n",
      "Epoch 0557: | Train Loss: 0.0641 | Val Loss: 4.8446 | Train Acc: 93.88| Val Acc: 61.78\n",
      "Epoch 0558: | Train Loss: 0.0677 | Val Loss: 4.8131 | Train Acc: 93.84| Val Acc: 61.31\n",
      "Epoch 0559: | Train Loss: 0.0581 | Val Loss: 4.7641 | Train Acc: 95.29| Val Acc: 61.71\n",
      "Epoch 0560: | Train Loss: 0.0661 | Val Loss: 4.8956 | Train Acc: 94.09| Val Acc: 61.41\n",
      "Epoch 0561: | Train Loss: 0.0629 | Val Loss: 4.8957 | Train Acc: 94.64| Val Acc: 61.51\n",
      "Epoch 0562: | Train Loss: 0.0677 | Val Loss: 4.8325 | Train Acc: 94.24| Val Acc: 62.04\n",
      "Epoch 0563: | Train Loss: 0.0759 | Val Loss: 4.7546 | Train Acc: 93.54| Val Acc: 61.31\n",
      "Epoch 0564: | Train Loss: 0.0722 | Val Loss: 4.7199 | Train Acc: 93.32| Val Acc: 61.89\n",
      "Epoch 0565: | Train Loss: 0.0629 | Val Loss: 4.7852 | Train Acc: 94.29| Val Acc: 60.75\n",
      "Epoch 0566: | Train Loss: 0.0620 | Val Loss: 4.8269 | Train Acc: 94.81| Val Acc: 60.91\n",
      "Epoch 0567: | Train Loss: 0.0633 | Val Loss: 4.7771 | Train Acc: 94.05| Val Acc: 60.80\n",
      "Epoch 0568: | Train Loss: 0.0619 | Val Loss: 4.5930 | Train Acc: 94.97| Val Acc: 62.39\n",
      "Epoch 0569: | Train Loss: 0.0648 | Val Loss: 4.6713 | Train Acc: 94.31| Val Acc: 63.00\n",
      "Epoch 0570: | Train Loss: 0.0595 | Val Loss: 4.8387 | Train Acc: 94.62| Val Acc: 62.59\n",
      "Epoch 0571: | Train Loss: 0.0560 | Val Loss: 4.9813 | Train Acc: 94.69| Val Acc: 61.99\n",
      "Epoch 0572: | Train Loss: 0.0668 | Val Loss: 5.0292 | Train Acc: 95.16| Val Acc: 61.86\n",
      "Epoch 0573: | Train Loss: 0.0579 | Val Loss: 4.8904 | Train Acc: 94.63| Val Acc: 61.77\n",
      "Epoch 0574: | Train Loss: 0.0581 | Val Loss: 4.7531 | Train Acc: 94.59| Val Acc: 61.06\n",
      "Epoch 0575: | Train Loss: 0.0634 | Val Loss: 4.8130 | Train Acc: 94.37| Val Acc: 61.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0576: | Train Loss: 0.0565 | Val Loss: 4.8652 | Train Acc: 95.03| Val Acc: 61.68\n",
      "Epoch 0577: | Train Loss: 0.0606 | Val Loss: 4.8807 | Train Acc: 94.53| Val Acc: 61.90\n",
      "Epoch 0578: | Train Loss: 0.0612 | Val Loss: 4.6482 | Train Acc: 95.64| Val Acc: 61.72\n",
      "Epoch 0579: | Train Loss: 0.0558 | Val Loss: 4.6109 | Train Acc: 94.55| Val Acc: 62.11\n",
      "Epoch 0580: | Train Loss: 0.0555 | Val Loss: 4.7712 | Train Acc: 95.23| Val Acc: 61.69\n",
      "Epoch 0581: | Train Loss: 0.0637 | Val Loss: 4.8903 | Train Acc: 95.03| Val Acc: 61.32\n",
      "Epoch 0582: | Train Loss: 0.0686 | Val Loss: 4.9249 | Train Acc: 93.86| Val Acc: 61.84\n",
      "Epoch 0583: | Train Loss: 0.0671 | Val Loss: 4.9791 | Train Acc: 94.04| Val Acc: 61.81\n",
      "Epoch 0584: | Train Loss: 0.0695 | Val Loss: 5.0476 | Train Acc: 94.08| Val Acc: 61.76\n",
      "Epoch 0585: | Train Loss: 0.0661 | Val Loss: 5.0317 | Train Acc: 93.94| Val Acc: 61.96\n",
      "Epoch 0586: | Train Loss: 0.0648 | Val Loss: 4.9846 | Train Acc: 94.57| Val Acc: 61.30\n",
      "Epoch 0587: | Train Loss: 0.0603 | Val Loss: 4.8062 | Train Acc: 94.43| Val Acc: 60.96\n",
      "Epoch 0588: | Train Loss: 0.0590 | Val Loss: 4.8044 | Train Acc: 94.40| Val Acc: 61.78\n",
      "Epoch 0589: | Train Loss: 0.0578 | Val Loss: 4.8324 | Train Acc: 94.53| Val Acc: 62.62\n",
      "Epoch 0590: | Train Loss: 0.0520 | Val Loss: 4.7525 | Train Acc: 95.80| Val Acc: 62.92\n",
      "Epoch 0591: | Train Loss: 0.0523 | Val Loss: 4.6542 | Train Acc: 95.54| Val Acc: 61.92\n",
      "Epoch 0592: | Train Loss: 0.0569 | Val Loss: 4.7403 | Train Acc: 95.16| Val Acc: 61.81\n",
      "Epoch 0593: | Train Loss: 0.0565 | Val Loss: 4.8598 | Train Acc: 95.34| Val Acc: 61.78\n",
      "Epoch 0594: | Train Loss: 0.0561 | Val Loss: 4.9166 | Train Acc: 95.29| Val Acc: 62.73\n",
      "Epoch 0595: | Train Loss: 0.0557 | Val Loss: 4.8507 | Train Acc: 95.58| Val Acc: 62.21\n",
      "Epoch 0596: | Train Loss: 0.0562 | Val Loss: 4.7704 | Train Acc: 95.24| Val Acc: 61.98\n",
      "Epoch 0597: | Train Loss: 0.0765 | Val Loss: 5.4176 | Train Acc: 95.04| Val Acc: 61.53\n",
      "Epoch 0598: | Train Loss: 0.0859 | Val Loss: 5.2517 | Train Acc: 92.97| Val Acc: 62.29\n",
      "Epoch 0599: | Train Loss: 0.0913 | Val Loss: 5.0329 | Train Acc: 93.42| Val Acc: 61.26\n",
      "Epoch 0600: | Train Loss: 0.0835 | Val Loss: 5.0224 | Train Acc: 92.44| Val Acc: 60.69\n",
      "Epoch 0601: | Train Loss: 0.0681 | Val Loss: 4.9797 | Train Acc: 94.12| Val Acc: 61.27\n",
      "Epoch 0602: | Train Loss: 0.0759 | Val Loss: 5.0016 | Train Acc: 92.80| Val Acc: 63.13\n",
      "Epoch 0603: | Train Loss: 0.0735 | Val Loss: 5.1975 | Train Acc: 92.54| Val Acc: 63.26\n",
      "Epoch 0604: | Train Loss: 0.0799 | Val Loss: 5.3138 | Train Acc: 93.13| Val Acc: 62.16\n",
      "Epoch 0605: | Train Loss: 0.0668 | Val Loss: 5.0374 | Train Acc: 94.01| Val Acc: 62.27\n",
      "Epoch 0606: | Train Loss: 0.0695 | Val Loss: 4.9372 | Train Acc: 93.54| Val Acc: 62.00\n",
      "Epoch 0607: | Train Loss: 0.0694 | Val Loss: 4.8747 | Train Acc: 94.38| Val Acc: 62.02\n",
      "Epoch 0608: | Train Loss: 0.0623 | Val Loss: 4.9366 | Train Acc: 94.11| Val Acc: 62.32\n",
      "Epoch 0609: | Train Loss: 0.0634 | Val Loss: 4.9975 | Train Acc: 94.63| Val Acc: 61.67\n",
      "Epoch 0610: | Train Loss: 0.0585 | Val Loss: 4.9951 | Train Acc: 94.50| Val Acc: 62.17\n",
      "Epoch 0611: | Train Loss: 0.0578 | Val Loss: 5.1357 | Train Acc: 94.94| Val Acc: 62.69\n",
      "Epoch 0612: | Train Loss: 0.0590 | Val Loss: 5.0787 | Train Acc: 94.61| Val Acc: 61.90\n",
      "Epoch 0613: | Train Loss: 0.0596 | Val Loss: 5.0036 | Train Acc: 95.15| Val Acc: 62.30\n",
      "Epoch 0614: | Train Loss: 0.0622 | Val Loss: 5.0117 | Train Acc: 95.00| Val Acc: 62.61\n",
      "Epoch 0615: | Train Loss: 0.0543 | Val Loss: 5.1339 | Train Acc: 95.01| Val Acc: 63.44\n",
      "Epoch 0616: | Train Loss: 0.0643 | Val Loss: 5.2390 | Train Acc: 94.34| Val Acc: 62.92\n",
      "Epoch 0617: | Train Loss: 0.0635 | Val Loss: 5.1559 | Train Acc: 93.80| Val Acc: 62.81\n",
      "Epoch 0618: | Train Loss: 0.0567 | Val Loss: 5.0867 | Train Acc: 94.86| Val Acc: 64.06\n",
      "Epoch 0619: | Train Loss: 0.0523 | Val Loss: 5.0405 | Train Acc: 95.40| Val Acc: 63.14\n",
      "Epoch 0620: | Train Loss: 0.0504 | Val Loss: 5.0941 | Train Acc: 95.75| Val Acc: 63.07\n",
      "Epoch 0621: | Train Loss: 0.0528 | Val Loss: 5.2347 | Train Acc: 95.15| Val Acc: 63.85\n",
      "Epoch 0622: | Train Loss: 0.0520 | Val Loss: 5.3316 | Train Acc: 95.60| Val Acc: 63.32\n",
      "Epoch 0623: | Train Loss: 0.0495 | Val Loss: 5.3128 | Train Acc: 96.11| Val Acc: 62.63\n",
      "Epoch 0624: | Train Loss: 0.0572 | Val Loss: 5.2382 | Train Acc: 95.49| Val Acc: 63.80\n",
      "Epoch 0625: | Train Loss: 0.0595 | Val Loss: 5.1357 | Train Acc: 94.81| Val Acc: 62.98\n",
      "Epoch 0626: | Train Loss: 0.0588 | Val Loss: 5.0182 | Train Acc: 94.83| Val Acc: 63.06\n",
      "Epoch 0627: | Train Loss: 0.0552 | Val Loss: 5.0394 | Train Acc: 95.28| Val Acc: 62.55\n",
      "Epoch 0628: | Train Loss: 0.0539 | Val Loss: 5.0484 | Train Acc: 95.24| Val Acc: 62.46\n",
      "Epoch 0629: | Train Loss: 0.0655 | Val Loss: 4.7987 | Train Acc: 95.08| Val Acc: 61.60\n",
      "Epoch 0630: | Train Loss: 0.0654 | Val Loss: 4.6551 | Train Acc: 93.88| Val Acc: 62.23\n",
      "Epoch 0631: | Train Loss: 0.0643 | Val Loss: 4.7884 | Train Acc: 94.34| Val Acc: 62.73\n",
      "Epoch 0632: | Train Loss: 0.0610 | Val Loss: 4.8453 | Train Acc: 94.68| Val Acc: 62.75\n",
      "Epoch 0633: | Train Loss: 0.0593 | Val Loss: 4.7908 | Train Acc: 93.93| Val Acc: 62.65\n",
      "Epoch 0634: | Train Loss: 0.0562 | Val Loss: 4.7507 | Train Acc: 94.80| Val Acc: 62.38\n",
      "Epoch 0635: | Train Loss: 0.0569 | Val Loss: 4.8725 | Train Acc: 95.20| Val Acc: 61.82\n",
      "Epoch 0636: | Train Loss: 0.0550 | Val Loss: 4.7862 | Train Acc: 95.12| Val Acc: 62.11\n",
      "Epoch 0637: | Train Loss: 0.0511 | Val Loss: 4.6955 | Train Acc: 95.64| Val Acc: 62.05\n",
      "Epoch 0638: | Train Loss: 0.0469 | Val Loss: 4.5528 | Train Acc: 95.94| Val Acc: 62.50\n",
      "Epoch 0639: | Train Loss: 0.0442 | Val Loss: 4.5737 | Train Acc: 96.21| Val Acc: 62.45\n",
      "Epoch 0640: | Train Loss: 0.0496 | Val Loss: 4.5767 | Train Acc: 95.54| Val Acc: 62.75\n",
      "Epoch 0641: | Train Loss: 0.0623 | Val Loss: 4.5958 | Train Acc: 95.10| Val Acc: 62.40\n",
      "Epoch 0642: | Train Loss: 0.0508 | Val Loss: 4.7888 | Train Acc: 95.66| Val Acc: 62.12\n",
      "Epoch 0643: | Train Loss: 0.0581 | Val Loss: 5.3055 | Train Acc: 94.96| Val Acc: 62.63\n",
      "Epoch 0644: | Train Loss: 0.0566 | Val Loss: 5.3301 | Train Acc: 95.33| Val Acc: 62.16\n",
      "Epoch 0645: | Train Loss: 0.0518 | Val Loss: 4.9374 | Train Acc: 95.64| Val Acc: 60.77\n",
      "Epoch 0646: | Train Loss: 0.0539 | Val Loss: 4.8043 | Train Acc: 94.89| Val Acc: 61.44\n",
      "Epoch 0647: | Train Loss: 0.0516 | Val Loss: 4.9563 | Train Acc: 95.19| Val Acc: 62.20\n",
      "Epoch 0648: | Train Loss: 0.0508 | Val Loss: 4.9408 | Train Acc: 95.66| Val Acc: 62.30\n",
      "Epoch 0649: | Train Loss: 0.0490 | Val Loss: 4.8747 | Train Acc: 95.86| Val Acc: 61.96\n",
      "Epoch 0650: | Train Loss: 0.0479 | Val Loss: 4.7436 | Train Acc: 95.46| Val Acc: 61.51\n",
      "Epoch 0651: | Train Loss: 0.0453 | Val Loss: 4.7333 | Train Acc: 95.90| Val Acc: 62.48\n",
      "Epoch 0652: | Train Loss: 0.0459 | Val Loss: 4.8310 | Train Acc: 96.30| Val Acc: 62.79\n",
      "Epoch 0653: | Train Loss: 0.0460 | Val Loss: 4.8676 | Train Acc: 96.24| Val Acc: 62.71\n",
      "Epoch 0654: | Train Loss: 0.0474 | Val Loss: 4.9716 | Train Acc: 95.75| Val Acc: 63.01\n",
      "Epoch 0655: | Train Loss: 0.0422 | Val Loss: 5.0588 | Train Acc: 96.11| Val Acc: 62.71\n",
      "Epoch 0656: | Train Loss: 0.0405 | Val Loss: 5.1636 | Train Acc: 96.28| Val Acc: 62.95\n",
      "Epoch 0657: | Train Loss: 0.0395 | Val Loss: 5.1650 | Train Acc: 96.61| Val Acc: 62.68\n",
      "Epoch 0658: | Train Loss: 0.0406 | Val Loss: 5.0009 | Train Acc: 96.22| Val Acc: 61.55\n",
      "Epoch 0659: | Train Loss: 0.0376 | Val Loss: 4.9070 | Train Acc: 96.99| Val Acc: 61.99\n",
      "Epoch 0660: | Train Loss: 0.0456 | Val Loss: 4.9292 | Train Acc: 96.26| Val Acc: 62.11\n",
      "Epoch 0661: | Train Loss: 0.0371 | Val Loss: 4.9615 | Train Acc: 96.91| Val Acc: 62.44\n",
      "Epoch 0662: | Train Loss: 0.0427 | Val Loss: 4.9219 | Train Acc: 96.80| Val Acc: 61.68\n",
      "Epoch 0663: | Train Loss: 0.0382 | Val Loss: 5.1398 | Train Acc: 96.60| Val Acc: 61.80\n",
      "Epoch 0664: | Train Loss: 0.0395 | Val Loss: 5.4741 | Train Acc: 96.51| Val Acc: 62.39\n",
      "Epoch 0665: | Train Loss: 0.0485 | Val Loss: 5.5025 | Train Acc: 95.96| Val Acc: 62.47\n",
      "Epoch 0666: | Train Loss: 0.0434 | Val Loss: 5.5559 | Train Acc: 96.50| Val Acc: 61.91\n",
      "Epoch 0667: | Train Loss: 0.0420 | Val Loss: 5.4653 | Train Acc: 96.48| Val Acc: 61.90\n",
      "Epoch 0668: | Train Loss: 0.0405 | Val Loss: 5.3746 | Train Acc: 96.76| Val Acc: 61.11\n",
      "Epoch 0669: | Train Loss: 0.0423 | Val Loss: 5.3192 | Train Acc: 96.16| Val Acc: 61.20\n",
      "Epoch 0670: | Train Loss: 0.0426 | Val Loss: 5.2878 | Train Acc: 96.48| Val Acc: 61.27\n",
      "Epoch 0671: | Train Loss: 0.0420 | Val Loss: 5.2937 | Train Acc: 96.01| Val Acc: 61.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0672: | Train Loss: 0.0421 | Val Loss: 5.3179 | Train Acc: 96.87| Val Acc: 61.51\n",
      "Epoch 0673: | Train Loss: 0.0409 | Val Loss: 5.3596 | Train Acc: 96.48| Val Acc: 60.77\n",
      "Epoch 0674: | Train Loss: 0.0416 | Val Loss: 5.3266 | Train Acc: 96.48| Val Acc: 61.76\n",
      "Epoch 0675: | Train Loss: 0.0424 | Val Loss: 5.4779 | Train Acc: 95.90| Val Acc: 61.32\n",
      "Epoch 0676: | Train Loss: 0.0425 | Val Loss: 5.4637 | Train Acc: 95.99| Val Acc: 61.75\n",
      "Epoch 0677: | Train Loss: 0.0388 | Val Loss: 5.3628 | Train Acc: 96.36| Val Acc: 61.99\n",
      "Epoch 0678: | Train Loss: 0.0397 | Val Loss: 5.3374 | Train Acc: 96.74| Val Acc: 62.18\n",
      "Epoch 0679: | Train Loss: 0.0343 | Val Loss: 5.3562 | Train Acc: 96.96| Val Acc: 62.07\n",
      "Epoch 0680: | Train Loss: 0.0466 | Val Loss: 5.4479 | Train Acc: 96.10| Val Acc: 62.26\n",
      "Epoch 0681: | Train Loss: 0.0447 | Val Loss: 5.3079 | Train Acc: 96.53| Val Acc: 62.77\n",
      "Epoch 0682: | Train Loss: 0.0485 | Val Loss: 5.4287 | Train Acc: 96.08| Val Acc: 63.50\n",
      "Epoch 0683: | Train Loss: 0.0437 | Val Loss: 5.3180 | Train Acc: 95.83| Val Acc: 62.51\n",
      "Epoch 0684: | Train Loss: 0.0425 | Val Loss: 5.1347 | Train Acc: 96.40| Val Acc: 61.74\n",
      "Epoch 0685: | Train Loss: 0.0455 | Val Loss: 5.0656 | Train Acc: 96.39| Val Acc: 61.77\n",
      "Epoch 0686: | Train Loss: 0.0442 | Val Loss: 5.1446 | Train Acc: 96.53| Val Acc: 62.40\n",
      "Epoch 0687: | Train Loss: 0.0485 | Val Loss: 5.1468 | Train Acc: 96.11| Val Acc: 61.80\n",
      "Epoch 0688: | Train Loss: 0.0493 | Val Loss: 5.2430 | Train Acc: 95.54| Val Acc: 61.68\n",
      "Epoch 0689: | Train Loss: 0.0473 | Val Loss: 5.3540 | Train Acc: 95.49| Val Acc: 62.72\n",
      "Epoch 0690: | Train Loss: 0.0471 | Val Loss: 5.2095 | Train Acc: 95.89| Val Acc: 62.31\n",
      "Epoch 0691: | Train Loss: 0.0383 | Val Loss: 5.0688 | Train Acc: 96.57| Val Acc: 62.29\n",
      "Epoch 0692: | Train Loss: 0.0436 | Val Loss: 5.1216 | Train Acc: 96.31| Val Acc: 62.40\n",
      "Epoch 0693: | Train Loss: 0.0383 | Val Loss: 5.2014 | Train Acc: 96.87| Val Acc: 61.99\n",
      "Epoch 0694: | Train Loss: 0.0404 | Val Loss: 5.3530 | Train Acc: 96.86| Val Acc: 62.39\n",
      "Epoch 0695: | Train Loss: 0.0395 | Val Loss: 5.5607 | Train Acc: 96.01| Val Acc: 62.54\n",
      "Epoch 0696: | Train Loss: 0.0419 | Val Loss: 5.5003 | Train Acc: 96.62| Val Acc: 62.80\n",
      "Epoch 0697: | Train Loss: 0.0460 | Val Loss: 5.4614 | Train Acc: 96.41| Val Acc: 62.71\n",
      "Epoch 0698: | Train Loss: 0.0542 | Val Loss: 5.4731 | Train Acc: 96.27| Val Acc: 62.74\n",
      "Epoch 0699: | Train Loss: 0.0512 | Val Loss: 5.2983 | Train Acc: 95.65| Val Acc: 62.43\n",
      "Epoch 0700: | Train Loss: 0.0525 | Val Loss: 5.1060 | Train Acc: 95.81| Val Acc: 62.10\n",
      "Epoch 0701: | Train Loss: 0.0520 | Val Loss: 4.8961 | Train Acc: 95.72| Val Acc: 62.20\n",
      "Epoch 0702: | Train Loss: 0.0510 | Val Loss: 5.0042 | Train Acc: 95.59| Val Acc: 61.98\n",
      "Epoch 0703: | Train Loss: 0.0458 | Val Loss: 5.0624 | Train Acc: 95.97| Val Acc: 62.92\n",
      "Epoch 0704: | Train Loss: 0.0476 | Val Loss: 4.9568 | Train Acc: 96.32| Val Acc: 61.98\n",
      "Epoch 0705: | Train Loss: 0.0512 | Val Loss: 4.9109 | Train Acc: 95.25| Val Acc: 60.85\n",
      "Epoch 0706: | Train Loss: 0.0467 | Val Loss: 5.0315 | Train Acc: 95.77| Val Acc: 61.16\n",
      "Epoch 0707: | Train Loss: 0.0444 | Val Loss: 5.0324 | Train Acc: 96.60| Val Acc: 61.37\n",
      "Epoch 0708: | Train Loss: 0.0447 | Val Loss: 5.0997 | Train Acc: 96.21| Val Acc: 61.50\n",
      "Epoch 0709: | Train Loss: 0.0393 | Val Loss: 5.2582 | Train Acc: 96.85| Val Acc: 62.07\n",
      "Epoch 0710: | Train Loss: 0.0423 | Val Loss: 5.3185 | Train Acc: 96.01| Val Acc: 62.28\n",
      "Epoch 0711: | Train Loss: 0.0406 | Val Loss: 5.3919 | Train Acc: 96.28| Val Acc: 62.09\n",
      "Epoch 0712: | Train Loss: 0.0452 | Val Loss: 5.4097 | Train Acc: 96.38| Val Acc: 62.10\n",
      "Epoch 0713: | Train Loss: 0.0411 | Val Loss: 5.4227 | Train Acc: 96.45| Val Acc: 61.51\n",
      "Epoch 0714: | Train Loss: 0.0425 | Val Loss: 5.4333 | Train Acc: 96.49| Val Acc: 61.99\n",
      "Epoch 0715: | Train Loss: 0.0435 | Val Loss: 5.2628 | Train Acc: 96.31| Val Acc: 63.12\n",
      "Epoch 0716: | Train Loss: 0.0424 | Val Loss: 5.3458 | Train Acc: 96.29| Val Acc: 63.08\n",
      "Epoch 0717: | Train Loss: 0.2663 | Val Loss: 6.9311 | Train Acc: 95.46| Val Acc: 61.55\n",
      "Epoch 0718: | Train Loss: 0.1002 | Val Loss: 6.6861 | Train Acc: 92.60| Val Acc: 62.11\n",
      "Epoch 0719: | Train Loss: 0.1005 | Val Loss: 6.1140 | Train Acc: 90.93| Val Acc: 61.26\n",
      "Epoch 0720: | Train Loss: 0.0852 | Val Loss: 5.5021 | Train Acc: 92.71| Val Acc: 62.32\n",
      "Epoch 0721: | Train Loss: 0.0789 | Val Loss: 5.1213 | Train Acc: 92.85| Val Acc: 60.62\n",
      "Epoch 0722: | Train Loss: 0.0795 | Val Loss: 4.9111 | Train Acc: 92.91| Val Acc: 60.85\n",
      "Epoch 0723: | Train Loss: 0.0697 | Val Loss: 5.0150 | Train Acc: 93.38| Val Acc: 61.43\n",
      "Epoch 0724: | Train Loss: 0.0637 | Val Loss: 5.2026 | Train Acc: 94.25| Val Acc: 61.64\n",
      "Epoch 0725: | Train Loss: 0.0603 | Val Loss: 5.2822 | Train Acc: 95.27| Val Acc: 61.21\n",
      "Epoch 0726: | Train Loss: 0.0549 | Val Loss: 5.3841 | Train Acc: 94.67| Val Acc: 62.06\n",
      "Epoch 0727: | Train Loss: 0.0624 | Val Loss: 5.2921 | Train Acc: 95.05| Val Acc: 62.89\n",
      "Epoch 0728: | Train Loss: 0.0556 | Val Loss: 5.2386 | Train Acc: 95.13| Val Acc: 61.92\n",
      "Epoch 0729: | Train Loss: 0.1237 | Val Loss: 5.2162 | Train Acc: 94.30| Val Acc: 62.49\n",
      "Epoch 0730: | Train Loss: 0.0811 | Val Loss: 5.4174 | Train Acc: 93.96| Val Acc: 62.29\n",
      "Epoch 0731: | Train Loss: 0.0836 | Val Loss: 5.7720 | Train Acc: 93.49| Val Acc: 62.77\n",
      "Epoch 0732: | Train Loss: 0.0846 | Val Loss: 5.6581 | Train Acc: 93.28| Val Acc: 62.60\n",
      "Epoch 0733: | Train Loss: 0.0883 | Val Loss: 5.5357 | Train Acc: 92.73| Val Acc: 63.28\n",
      "Epoch 0734: | Train Loss: 0.0767 | Val Loss: 5.2988 | Train Acc: 93.37| Val Acc: 63.34\n",
      "Epoch 0735: | Train Loss: 0.0823 | Val Loss: 5.3633 | Train Acc: 93.11| Val Acc: 63.63\n",
      "Epoch 0736: | Train Loss: 0.0729 | Val Loss: 5.2007 | Train Acc: 93.61| Val Acc: 63.31\n",
      "Epoch 0737: | Train Loss: 0.0689 | Val Loss: 5.0156 | Train Acc: 94.32| Val Acc: 63.02\n",
      "Epoch 0738: | Train Loss: 0.0604 | Val Loss: 5.0216 | Train Acc: 94.66| Val Acc: 62.15\n",
      "Epoch 0739: | Train Loss: 0.0817 | Val Loss: 5.0135 | Train Acc: 94.04| Val Acc: 61.97\n",
      "Epoch 0740: | Train Loss: 0.1016 | Val Loss: 5.3857 | Train Acc: 94.53| Val Acc: 60.33\n",
      "Epoch 0741: | Train Loss: 0.0819 | Val Loss: 5.5617 | Train Acc: 93.25| Val Acc: 62.16\n",
      "Epoch 0742: | Train Loss: 0.1007 | Val Loss: 5.1561 | Train Acc: 92.97| Val Acc: 61.66\n",
      "Epoch 0743: | Train Loss: 0.1064 | Val Loss: 5.2570 | Train Acc: 92.24| Val Acc: 60.85\n",
      "Epoch 0744: | Train Loss: 0.1325 | Val Loss: 6.3751 | Train Acc: 90.46| Val Acc: 60.92\n",
      "Epoch 0745: | Train Loss: 0.1233 | Val Loss: 6.7556 | Train Acc: 90.83| Val Acc: 61.97\n",
      "Epoch 0746: | Train Loss: 0.0996 | Val Loss: 6.9274 | Train Acc: 91.33| Val Acc: 62.18\n",
      "Epoch 0747: | Train Loss: 0.0914 | Val Loss: 7.0972 | Train Acc: 92.79| Val Acc: 61.16\n",
      "Epoch 0748: | Train Loss: 0.1000 | Val Loss: 6.4824 | Train Acc: 92.82| Val Acc: 60.06\n",
      "Epoch 0749: | Train Loss: 0.1053 | Val Loss: 6.1450 | Train Acc: 92.48| Val Acc: 60.13\n",
      "Epoch 0750: | Train Loss: 0.1204 | Val Loss: 5.8023 | Train Acc: 91.26| Val Acc: 60.14\n",
      "Epoch 0751: | Train Loss: 0.1168 | Val Loss: 5.7785 | Train Acc: 91.82| Val Acc: 62.71\n",
      "Epoch 0752: | Train Loss: 0.1032 | Val Loss: 5.9156 | Train Acc: 91.35| Val Acc: 61.23\n",
      "Epoch 0753: | Train Loss: 0.0897 | Val Loss: 5.9642 | Train Acc: 92.53| Val Acc: 60.63\n",
      "Epoch 0754: | Train Loss: 0.0856 | Val Loss: 5.8730 | Train Acc: 92.47| Val Acc: 61.13\n",
      "Epoch 0755: | Train Loss: 0.0991 | Val Loss: 5.6145 | Train Acc: 92.94| Val Acc: 62.26\n",
      "Epoch 0756: | Train Loss: 0.0878 | Val Loss: 5.6093 | Train Acc: 93.39| Val Acc: 62.46\n",
      "Epoch 0757: | Train Loss: 0.0852 | Val Loss: 5.4376 | Train Acc: 93.55| Val Acc: 61.55\n",
      "Epoch 0758: | Train Loss: 0.1326 | Val Loss: 5.7030 | Train Acc: 92.80| Val Acc: 61.85\n",
      "Epoch 0759: | Train Loss: 0.1658 | Val Loss: 5.3711 | Train Acc: 91.75| Val Acc: 61.44\n",
      "Epoch 0760: | Train Loss: 0.1933 | Val Loss: 4.7784 | Train Acc: 90.65| Val Acc: 62.00\n",
      "Epoch 0761: | Train Loss: 0.1679 | Val Loss: 4.7382 | Train Acc: 90.78| Val Acc: 59.77\n",
      "Epoch 0762: | Train Loss: 0.2058 | Val Loss: 5.3186 | Train Acc: 89.33| Val Acc: 58.74\n",
      "Epoch 0763: | Train Loss: 0.2185 | Val Loss: 5.3902 | Train Acc: 86.89| Val Acc: 57.96\n",
      "Epoch 0764: | Train Loss: 0.2132 | Val Loss: 4.9217 | Train Acc: 86.36| Val Acc: 58.97\n",
      "Epoch 0765: | Train Loss: 0.1839 | Val Loss: 4.6070 | Train Acc: 87.23| Val Acc: 59.97\n",
      "Epoch 0766: | Train Loss: 0.2126 | Val Loss: 4.7525 | Train Acc: 87.38| Val Acc: 60.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0767: | Train Loss: 0.1860 | Val Loss: 4.7011 | Train Acc: 86.90| Val Acc: 59.87\n",
      "Epoch 0768: | Train Loss: 0.1447 | Val Loss: 4.5796 | Train Acc: 87.86| Val Acc: 59.61\n",
      "Epoch 0769: | Train Loss: 0.1379 | Val Loss: 4.2826 | Train Acc: 89.35| Val Acc: 59.87\n",
      "Epoch 0770: | Train Loss: 0.1512 | Val Loss: 4.2547 | Train Acc: 88.94| Val Acc: 60.17\n",
      "Epoch 0771: | Train Loss: 0.1225 | Val Loss: 4.4756 | Train Acc: 89.29| Val Acc: 61.62\n",
      "Epoch 0772: | Train Loss: 0.1043 | Val Loss: 4.8106 | Train Acc: 91.30| Val Acc: 61.50\n",
      "Epoch 0773: | Train Loss: 0.0958 | Val Loss: 4.9909 | Train Acc: 91.58| Val Acc: 61.08\n",
      "Epoch 0774: | Train Loss: 0.0883 | Val Loss: 4.9771 | Train Acc: 92.35| Val Acc: 61.35\n",
      "Epoch 0775: | Train Loss: 0.0749 | Val Loss: 4.9738 | Train Acc: 93.37| Val Acc: 61.68\n",
      "Epoch 0776: | Train Loss: 0.0793 | Val Loss: 5.0892 | Train Acc: 93.48| Val Acc: 61.18\n",
      "Epoch 0777: | Train Loss: 0.0846 | Val Loss: 5.1503 | Train Acc: 93.48| Val Acc: 61.02\n",
      "Epoch 0778: | Train Loss: 0.0803 | Val Loss: 5.2808 | Train Acc: 93.45| Val Acc: 61.65\n",
      "Epoch 0779: | Train Loss: 0.0860 | Val Loss: 5.2296 | Train Acc: 93.20| Val Acc: 61.92\n",
      "Epoch 0780: | Train Loss: 0.0739 | Val Loss: 5.2839 | Train Acc: 93.92| Val Acc: 62.62\n",
      "Epoch 0781: | Train Loss: 0.0849 | Val Loss: 5.2025 | Train Acc: 93.26| Val Acc: 62.65\n",
      "Epoch 0782: | Train Loss: 0.0688 | Val Loss: 5.1732 | Train Acc: 94.83| Val Acc: 63.44\n",
      "Epoch 0783: | Train Loss: 0.0686 | Val Loss: 5.3477 | Train Acc: 94.24| Val Acc: 62.00\n",
      "Epoch 0784: | Train Loss: 0.0696 | Val Loss: 5.5197 | Train Acc: 94.04| Val Acc: 62.48\n",
      "Epoch 0785: | Train Loss: 0.0704 | Val Loss: 5.4694 | Train Acc: 94.92| Val Acc: 62.59\n",
      "Epoch 0786: | Train Loss: 0.0584 | Val Loss: 5.3447 | Train Acc: 95.15| Val Acc: 61.99\n",
      "Epoch 0787: | Train Loss: 0.0560 | Val Loss: 5.3299 | Train Acc: 95.27| Val Acc: 61.41\n",
      "Epoch 0788: | Train Loss: 0.0887 | Val Loss: 5.3780 | Train Acc: 94.81| Val Acc: 61.20\n",
      "Epoch 0789: | Train Loss: 0.0882 | Val Loss: 5.3461 | Train Acc: 93.81| Val Acc: 60.24\n",
      "Epoch 0790: | Train Loss: 0.1238 | Val Loss: 5.1468 | Train Acc: 93.23| Val Acc: 60.65\n",
      "Epoch 0791: | Train Loss: 0.0824 | Val Loss: 5.1785 | Train Acc: 94.29| Val Acc: 61.16\n",
      "Epoch 0792: | Train Loss: 0.0654 | Val Loss: 5.1559 | Train Acc: 93.99| Val Acc: 61.48\n",
      "Epoch 0793: | Train Loss: 0.0664 | Val Loss: 5.0020 | Train Acc: 94.40| Val Acc: 62.14\n",
      "Epoch 0794: | Train Loss: 0.0656 | Val Loss: 4.9492 | Train Acc: 94.34| Val Acc: 62.62\n",
      "Epoch 0795: | Train Loss: 0.0680 | Val Loss: 5.0282 | Train Acc: 94.62| Val Acc: 62.62\n",
      "Epoch 0796: | Train Loss: 0.0608 | Val Loss: 5.1648 | Train Acc: 95.34| Val Acc: 61.77\n",
      "Epoch 0797: | Train Loss: 0.0605 | Val Loss: 5.2689 | Train Acc: 95.01| Val Acc: 61.86\n",
      "Epoch 0798: | Train Loss: 0.0580 | Val Loss: 5.2241 | Train Acc: 94.67| Val Acc: 60.86\n",
      "Epoch 0799: | Train Loss: 0.0545 | Val Loss: 5.2228 | Train Acc: 94.97| Val Acc: 62.09\n",
      "Epoch 0800: | Train Loss: 0.0536 | Val Loss: 5.1791 | Train Acc: 95.33| Val Acc: 61.67\n",
      "Epoch 0801: | Train Loss: 0.0507 | Val Loss: 5.1506 | Train Acc: 95.97| Val Acc: 61.44\n",
      "Epoch 0802: | Train Loss: 0.0456 | Val Loss: 5.2001 | Train Acc: 95.63| Val Acc: 61.54\n",
      "Epoch 0803: | Train Loss: 0.0449 | Val Loss: 5.3192 | Train Acc: 96.26| Val Acc: 61.54\n",
      "Epoch 0804: | Train Loss: 0.0472 | Val Loss: 5.3289 | Train Acc: 95.89| Val Acc: 61.89\n",
      "Epoch 0805: | Train Loss: 0.0443 | Val Loss: 5.2624 | Train Acc: 96.11| Val Acc: 62.07\n",
      "Epoch 0806: | Train Loss: 0.0511 | Val Loss: 5.2812 | Train Acc: 95.84| Val Acc: 62.39\n",
      "Epoch 0807: | Train Loss: 0.0472 | Val Loss: 5.3237 | Train Acc: 95.90| Val Acc: 62.52\n",
      "Epoch 0808: | Train Loss: 0.0462 | Val Loss: 5.3447 | Train Acc: 96.31| Val Acc: 62.81\n",
      "Epoch 0809: | Train Loss: 0.0438 | Val Loss: 5.4146 | Train Acc: 96.03| Val Acc: 62.79\n",
      "Epoch 0810: | Train Loss: 0.0421 | Val Loss: 5.6027 | Train Acc: 96.27| Val Acc: 61.99\n",
      "Epoch 0811: | Train Loss: 0.0474 | Val Loss: 5.6955 | Train Acc: 95.54| Val Acc: 61.35\n",
      "Epoch 0812: | Train Loss: 0.0453 | Val Loss: 5.7096 | Train Acc: 96.51| Val Acc: 61.15\n",
      "Epoch 0813: | Train Loss: 0.0400 | Val Loss: 5.6949 | Train Acc: 96.69| Val Acc: 61.78\n",
      "Epoch 0814: | Train Loss: 0.0461 | Val Loss: 5.7888 | Train Acc: 96.25| Val Acc: 61.96\n",
      "Epoch 0815: | Train Loss: 0.0365 | Val Loss: 5.7715 | Train Acc: 96.99| Val Acc: 61.65\n",
      "Epoch 0816: | Train Loss: 0.0403 | Val Loss: 5.7498 | Train Acc: 96.42| Val Acc: 61.84\n",
      "Epoch 0817: | Train Loss: 0.0441 | Val Loss: 5.7415 | Train Acc: 96.39| Val Acc: 61.91\n",
      "Epoch 0818: | Train Loss: 0.0427 | Val Loss: 5.8060 | Train Acc: 96.35| Val Acc: 61.41\n",
      "Epoch 0819: | Train Loss: 0.0410 | Val Loss: 5.7413 | Train Acc: 96.72| Val Acc: 62.04\n",
      "Epoch 0820: | Train Loss: 0.0411 | Val Loss: 5.7217 | Train Acc: 96.73| Val Acc: 61.20\n",
      "Epoch 0821: | Train Loss: 0.0373 | Val Loss: 5.6702 | Train Acc: 97.14| Val Acc: 61.66\n",
      "Epoch 0822: | Train Loss: 0.0402 | Val Loss: 5.6317 | Train Acc: 96.74| Val Acc: 62.00\n",
      "Epoch 0823: | Train Loss: 0.0414 | Val Loss: 5.8274 | Train Acc: 97.11| Val Acc: 61.98\n",
      "Epoch 0824: | Train Loss: 0.0520 | Val Loss: 5.7405 | Train Acc: 95.48| Val Acc: 61.57\n",
      "Epoch 0825: | Train Loss: 0.0520 | Val Loss: 5.6117 | Train Acc: 95.36| Val Acc: 61.76\n",
      "Epoch 0826: | Train Loss: 0.0507 | Val Loss: 5.5777 | Train Acc: 95.86| Val Acc: 61.83\n",
      "Epoch 0827: | Train Loss: 0.0531 | Val Loss: 5.7044 | Train Acc: 95.50| Val Acc: 61.45\n",
      "Epoch 0828: | Train Loss: 0.0404 | Val Loss: 5.7058 | Train Acc: 96.59| Val Acc: 60.74\n",
      "Epoch 0829: | Train Loss: 0.0460 | Val Loss: 5.6020 | Train Acc: 95.89| Val Acc: 61.04\n",
      "Epoch 0830: | Train Loss: 0.0415 | Val Loss: 5.6430 | Train Acc: 96.24| Val Acc: 61.08\n",
      "Epoch 0831: | Train Loss: 0.0379 | Val Loss: 5.6236 | Train Acc: 96.88| Val Acc: 61.56\n",
      "Epoch 0832: | Train Loss: 0.0399 | Val Loss: 5.7563 | Train Acc: 96.44| Val Acc: 62.66\n",
      "Epoch 0833: | Train Loss: 0.0407 | Val Loss: 6.0071 | Train Acc: 96.63| Val Acc: 61.95\n",
      "Epoch 0834: | Train Loss: 0.0360 | Val Loss: 6.1237 | Train Acc: 97.21| Val Acc: 61.32\n",
      "Epoch 0835: | Train Loss: 0.0365 | Val Loss: 6.1097 | Train Acc: 96.69| Val Acc: 61.74\n",
      "Epoch 0836: | Train Loss: 0.0409 | Val Loss: 5.9158 | Train Acc: 97.04| Val Acc: 61.11\n",
      "Epoch 0837: | Train Loss: 0.0353 | Val Loss: 5.7047 | Train Acc: 97.41| Val Acc: 61.47\n",
      "Epoch 0838: | Train Loss: 0.0327 | Val Loss: 5.6855 | Train Acc: 97.63| Val Acc: 62.19\n",
      "Epoch 0839: | Train Loss: 0.0376 | Val Loss: 5.7830 | Train Acc: 96.51| Val Acc: 61.14\n",
      "Epoch 0840: | Train Loss: 0.0329 | Val Loss: 5.9332 | Train Acc: 97.07| Val Acc: 61.05\n",
      "Epoch 0841: | Train Loss: 0.0323 | Val Loss: 5.9910 | Train Acc: 97.17| Val Acc: 61.64\n",
      "Epoch 0842: | Train Loss: 0.0390 | Val Loss: 6.0860 | Train Acc: 97.33| Val Acc: 61.64\n",
      "Epoch 0843: | Train Loss: 0.0379 | Val Loss: 5.9777 | Train Acc: 97.24| Val Acc: 62.37\n",
      "Epoch 0844: | Train Loss: 0.0309 | Val Loss: 5.8761 | Train Acc: 97.48| Val Acc: 62.58\n",
      "Epoch 0845: | Train Loss: 0.0382 | Val Loss: 5.7545 | Train Acc: 97.12| Val Acc: 61.88\n",
      "Epoch 0846: | Train Loss: 0.0400 | Val Loss: 5.7279 | Train Acc: 96.92| Val Acc: 62.21\n",
      "Epoch 0847: | Train Loss: 0.0352 | Val Loss: 5.8269 | Train Acc: 96.95| Val Acc: 62.30\n",
      "Epoch 0848: | Train Loss: 0.0359 | Val Loss: 5.8113 | Train Acc: 97.64| Val Acc: 62.07\n",
      "Epoch 0849: | Train Loss: 0.0433 | Val Loss: 5.8256 | Train Acc: 97.29| Val Acc: 62.38\n",
      "Epoch 0850: | Train Loss: 0.0366 | Val Loss: 5.8135 | Train Acc: 96.82| Val Acc: 63.11\n",
      "Epoch 0851: | Train Loss: 0.0417 | Val Loss: 5.7451 | Train Acc: 96.81| Val Acc: 61.53\n",
      "Epoch 0852: | Train Loss: 0.0414 | Val Loss: 5.7868 | Train Acc: 96.66| Val Acc: 61.18\n",
      "Epoch 0853: | Train Loss: 0.0420 | Val Loss: 5.8306 | Train Acc: 96.48| Val Acc: 61.85\n",
      "Epoch 0854: | Train Loss: 0.0378 | Val Loss: 5.9472 | Train Acc: 96.83| Val Acc: 61.65\n",
      "Epoch 0855: | Train Loss: 0.0402 | Val Loss: 5.8444 | Train Acc: 96.45| Val Acc: 61.78\n",
      "Epoch 0856: | Train Loss: 0.0331 | Val Loss: 5.6039 | Train Acc: 97.50| Val Acc: 61.98\n",
      "Epoch 0857: | Train Loss: 0.0758 | Val Loss: 4.8252 | Train Acc: 95.59| Val Acc: 62.83\n",
      "Epoch 0858: | Train Loss: 0.0902 | Val Loss: 4.7831 | Train Acc: 95.10| Val Acc: 59.95\n",
      "Epoch 0859: | Train Loss: 0.0750 | Val Loss: 4.7711 | Train Acc: 93.83| Val Acc: 60.55\n",
      "Epoch 0860: | Train Loss: 0.0831 | Val Loss: 4.8619 | Train Acc: 93.76| Val Acc: 60.26\n",
      "Epoch 0861: | Train Loss: 0.0692 | Val Loss: 4.7106 | Train Acc: 94.52| Val Acc: 60.06\n",
      "Epoch 0862: | Train Loss: 0.0787 | Val Loss: 4.8464 | Train Acc: 94.15| Val Acc: 60.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0863: | Train Loss: 0.0741 | Val Loss: 5.1202 | Train Acc: 94.12| Val Acc: 61.45\n",
      "Epoch 0864: | Train Loss: 0.0724 | Val Loss: 5.3723 | Train Acc: 93.87| Val Acc: 61.56\n",
      "Epoch 0865: | Train Loss: 0.0765 | Val Loss: 5.3076 | Train Acc: 94.53| Val Acc: 60.83\n",
      "Epoch 0866: | Train Loss: 0.0660 | Val Loss: 5.2676 | Train Acc: 93.99| Val Acc: 62.09\n",
      "Epoch 0867: | Train Loss: 0.0609 | Val Loss: 5.1611 | Train Acc: 94.01| Val Acc: 62.39\n",
      "Epoch 0868: | Train Loss: 0.0518 | Val Loss: 5.1967 | Train Acc: 95.52| Val Acc: 62.00\n",
      "Epoch 0869: | Train Loss: 0.0525 | Val Loss: 5.1814 | Train Acc: 95.69| Val Acc: 61.89\n",
      "Epoch 0870: | Train Loss: 0.0522 | Val Loss: 5.2100 | Train Acc: 95.42| Val Acc: 62.57\n",
      "Epoch 0871: | Train Loss: 0.0449 | Val Loss: 5.3046 | Train Acc: 96.28| Val Acc: 61.76\n",
      "Epoch 0872: | Train Loss: 0.0439 | Val Loss: 5.3881 | Train Acc: 96.32| Val Acc: 61.94\n",
      "Epoch 0873: | Train Loss: 0.0497 | Val Loss: 5.4015 | Train Acc: 95.89| Val Acc: 60.94\n",
      "Epoch 0874: | Train Loss: 0.0496 | Val Loss: 5.4430 | Train Acc: 95.74| Val Acc: 60.75\n",
      "Epoch 0875: | Train Loss: 0.0464 | Val Loss: 5.5402 | Train Acc: 95.92| Val Acc: 61.45\n",
      "Epoch 0876: | Train Loss: 0.0375 | Val Loss: 5.5731 | Train Acc: 96.37| Val Acc: 61.86\n",
      "Epoch 0877: | Train Loss: 0.0424 | Val Loss: 5.6086 | Train Acc: 96.36| Val Acc: 61.58\n",
      "Epoch 0878: | Train Loss: 0.0455 | Val Loss: 5.7293 | Train Acc: 96.69| Val Acc: 62.14\n",
      "Epoch 0879: | Train Loss: 0.0421 | Val Loss: 5.7903 | Train Acc: 96.60| Val Acc: 62.36\n",
      "Epoch 0880: | Train Loss: 0.0463 | Val Loss: 5.5894 | Train Acc: 96.39| Val Acc: 61.27\n",
      "Epoch 0881: | Train Loss: 0.0424 | Val Loss: 5.5280 | Train Acc: 96.31| Val Acc: 61.39\n",
      "Epoch 0882: | Train Loss: 0.0483 | Val Loss: 5.5165 | Train Acc: 96.59| Val Acc: 62.09\n",
      "Epoch 0883: | Train Loss: 0.0354 | Val Loss: 5.4850 | Train Acc: 96.70| Val Acc: 62.26\n",
      "Epoch 0884: | Train Loss: 0.0382 | Val Loss: 5.4547 | Train Acc: 96.47| Val Acc: 61.64\n",
      "Epoch 0885: | Train Loss: 0.0370 | Val Loss: 5.4859 | Train Acc: 96.48| Val Acc: 61.15\n",
      "Epoch 0886: | Train Loss: 0.0396 | Val Loss: 5.4703 | Train Acc: 96.72| Val Acc: 61.90\n",
      "Epoch 0887: | Train Loss: 0.0375 | Val Loss: 5.4363 | Train Acc: 96.62| Val Acc: 61.59\n",
      "Epoch 0888: | Train Loss: 0.0408 | Val Loss: 5.4405 | Train Acc: 96.45| Val Acc: 62.57\n",
      "Epoch 0889: | Train Loss: 0.0360 | Val Loss: 5.4158 | Train Acc: 96.74| Val Acc: 62.14\n",
      "Epoch 0890: | Train Loss: 0.0384 | Val Loss: 5.3762 | Train Acc: 96.18| Val Acc: 62.25\n",
      "Epoch 0891: | Train Loss: 0.0340 | Val Loss: 5.4035 | Train Acc: 96.68| Val Acc: 62.48\n",
      "Epoch 0892: | Train Loss: 0.0344 | Val Loss: 5.4051 | Train Acc: 96.74| Val Acc: 62.60\n",
      "Epoch 0893: | Train Loss: 0.0312 | Val Loss: 5.3425 | Train Acc: 97.12| Val Acc: 62.06\n",
      "Epoch 0894: | Train Loss: 0.0312 | Val Loss: 5.3242 | Train Acc: 97.28| Val Acc: 61.35\n",
      "Epoch 0895: | Train Loss: 0.0317 | Val Loss: 5.4686 | Train Acc: 97.43| Val Acc: 61.98\n",
      "Epoch 0896: | Train Loss: 0.0322 | Val Loss: 5.5688 | Train Acc: 97.38| Val Acc: 62.08\n",
      "Epoch 0897: | Train Loss: 0.0344 | Val Loss: 5.5981 | Train Acc: 97.14| Val Acc: 61.60\n",
      "Epoch 0898: | Train Loss: 0.0296 | Val Loss: 5.5358 | Train Acc: 97.73| Val Acc: 62.31\n",
      "Epoch 0899: | Train Loss: 0.0318 | Val Loss: 5.4357 | Train Acc: 97.09| Val Acc: 62.60\n",
      "Epoch 0900: | Train Loss: 0.0315 | Val Loss: 5.5233 | Train Acc: 97.43| Val Acc: 62.92\n",
      "Epoch 0901: | Train Loss: 0.0307 | Val Loss: 5.5214 | Train Acc: 97.77| Val Acc: 62.38\n",
      "Epoch 0902: | Train Loss: 0.0286 | Val Loss: 5.5524 | Train Acc: 97.47| Val Acc: 61.66\n",
      "Epoch 0903: | Train Loss: 0.0301 | Val Loss: 5.5744 | Train Acc: 97.57| Val Acc: 61.55\n",
      "Epoch 0904: | Train Loss: 0.0269 | Val Loss: 5.5888 | Train Acc: 98.04| Val Acc: 62.90\n",
      "Epoch 0905: | Train Loss: 0.0360 | Val Loss: 5.6145 | Train Acc: 97.30| Val Acc: 62.37\n",
      "Epoch 0906: | Train Loss: 0.0330 | Val Loss: 5.6597 | Train Acc: 97.32| Val Acc: 62.68\n",
      "Epoch 0907: | Train Loss: 0.0326 | Val Loss: 5.6201 | Train Acc: 97.14| Val Acc: 62.80\n",
      "Epoch 0908: | Train Loss: 0.0277 | Val Loss: 5.6412 | Train Acc: 97.75| Val Acc: 62.18\n",
      "Epoch 0909: | Train Loss: 0.0307 | Val Loss: 5.7369 | Train Acc: 97.24| Val Acc: 61.07\n",
      "Epoch 0910: | Train Loss: 0.0336 | Val Loss: 5.7505 | Train Acc: 96.95| Val Acc: 61.27\n",
      "Epoch 0911: | Train Loss: 0.0339 | Val Loss: 5.7898 | Train Acc: 97.27| Val Acc: 62.07\n",
      "Epoch 0912: | Train Loss: 0.0288 | Val Loss: 5.7928 | Train Acc: 97.60| Val Acc: 62.59\n",
      "Epoch 0913: | Train Loss: 0.0245 | Val Loss: 5.6907 | Train Acc: 98.00| Val Acc: 62.38\n",
      "Epoch 0914: | Train Loss: 0.0347 | Val Loss: 5.6999 | Train Acc: 97.65| Val Acc: 62.26\n",
      "Epoch 0915: | Train Loss: 0.0283 | Val Loss: 5.7810 | Train Acc: 97.47| Val Acc: 62.86\n",
      "Epoch 0916: | Train Loss: 0.0279 | Val Loss: 5.7867 | Train Acc: 97.44| Val Acc: 61.97\n",
      "Epoch 0917: | Train Loss: 0.0266 | Val Loss: 5.8186 | Train Acc: 97.70| Val Acc: 61.80\n",
      "Epoch 0918: | Train Loss: 0.0453 | Val Loss: 5.7292 | Train Acc: 97.06| Val Acc: 61.87\n",
      "Epoch 0919: | Train Loss: 0.0343 | Val Loss: 5.6414 | Train Acc: 97.27| Val Acc: 61.55\n",
      "Epoch 0920: | Train Loss: 0.0284 | Val Loss: 5.6524 | Train Acc: 97.77| Val Acc: 62.18\n",
      "Epoch 0921: | Train Loss: 0.0301 | Val Loss: 5.5026 | Train Acc: 97.36| Val Acc: 61.75\n",
      "Epoch 0922: | Train Loss: 0.0355 | Val Loss: 5.4923 | Train Acc: 97.29| Val Acc: 61.28\n",
      "Epoch 0923: | Train Loss: 0.0316 | Val Loss: 5.7113 | Train Acc: 97.35| Val Acc: 62.27\n",
      "Epoch 0924: | Train Loss: 0.0344 | Val Loss: 5.7236 | Train Acc: 97.38| Val Acc: 62.68\n",
      "Epoch 0925: | Train Loss: 0.0318 | Val Loss: 5.6582 | Train Acc: 97.53| Val Acc: 63.19\n",
      "Epoch 0926: | Train Loss: 0.0337 | Val Loss: 5.6990 | Train Acc: 97.03| Val Acc: 63.19\n",
      "Epoch 0927: | Train Loss: 0.0322 | Val Loss: 5.5770 | Train Acc: 97.00| Val Acc: 62.51\n",
      "Epoch 0928: | Train Loss: 0.0269 | Val Loss: 5.5037 | Train Acc: 97.46| Val Acc: 61.57\n",
      "Epoch 0929: | Train Loss: 0.0254 | Val Loss: 5.4957 | Train Acc: 97.79| Val Acc: 61.35\n",
      "Epoch 0930: | Train Loss: 0.0476 | Val Loss: 5.5307 | Train Acc: 97.42| Val Acc: 61.60\n",
      "Epoch 0931: | Train Loss: 0.0382 | Val Loss: 5.5114 | Train Acc: 97.03| Val Acc: 61.66\n",
      "Epoch 0932: | Train Loss: 0.0496 | Val Loss: 5.4420 | Train Acc: 96.36| Val Acc: 61.02\n",
      "Epoch 0933: | Train Loss: 0.0472 | Val Loss: 5.3856 | Train Acc: 95.95| Val Acc: 61.04\n",
      "Epoch 0934: | Train Loss: 0.0462 | Val Loss: 5.5511 | Train Acc: 96.36| Val Acc: 62.07\n",
      "Epoch 0935: | Train Loss: 0.0451 | Val Loss: 5.5880 | Train Acc: 95.76| Val Acc: 62.31\n",
      "Epoch 0936: | Train Loss: 0.0478 | Val Loss: 5.4887 | Train Acc: 95.97| Val Acc: 62.39\n",
      "Epoch 0937: | Train Loss: 0.0458 | Val Loss: 5.5474 | Train Acc: 96.48| Val Acc: 61.38\n",
      "Epoch 0938: | Train Loss: 0.0397 | Val Loss: 5.6520 | Train Acc: 96.73| Val Acc: 61.17\n",
      "Epoch 0939: | Train Loss: 0.0391 | Val Loss: 5.5860 | Train Acc: 96.65| Val Acc: 61.28\n",
      "Epoch 0940: | Train Loss: 0.0450 | Val Loss: 5.6997 | Train Acc: 96.65| Val Acc: 62.42\n",
      "Epoch 0941: | Train Loss: 0.0395 | Val Loss: 5.6064 | Train Acc: 96.86| Val Acc: 62.01\n",
      "Epoch 0942: | Train Loss: 0.0429 | Val Loss: 5.6549 | Train Acc: 96.24| Val Acc: 61.39\n",
      "Epoch 0943: | Train Loss: 0.0420 | Val Loss: 5.7670 | Train Acc: 96.42| Val Acc: 60.76\n",
      "Epoch 0944: | Train Loss: 0.0381 | Val Loss: 5.7141 | Train Acc: 96.62| Val Acc: 61.58\n",
      "Epoch 0945: | Train Loss: 0.0359 | Val Loss: 5.7622 | Train Acc: 96.79| Val Acc: 62.20\n",
      "Epoch 0946: | Train Loss: 0.0409 | Val Loss: 5.9163 | Train Acc: 97.09| Val Acc: 61.39\n",
      "Epoch 0947: | Train Loss: 0.0365 | Val Loss: 5.9796 | Train Acc: 96.86| Val Acc: 61.18\n",
      "Epoch 0948: | Train Loss: 0.0314 | Val Loss: 5.8736 | Train Acc: 97.50| Val Acc: 62.40\n",
      "Epoch 0949: | Train Loss: 0.0305 | Val Loss: 5.7690 | Train Acc: 97.29| Val Acc: 62.59\n",
      "Epoch 0950: | Train Loss: 0.0319 | Val Loss: 5.7605 | Train Acc: 97.16| Val Acc: 62.49\n",
      "Epoch 0951: | Train Loss: 0.0301 | Val Loss: 5.7835 | Train Acc: 97.51| Val Acc: 62.19\n",
      "Epoch 0952: | Train Loss: 0.0297 | Val Loss: 5.8721 | Train Acc: 97.72| Val Acc: 61.39\n",
      "Epoch 0953: | Train Loss: 0.0287 | Val Loss: 5.8552 | Train Acc: 97.78| Val Acc: 61.70\n",
      "Epoch 0954: | Train Loss: 0.0293 | Val Loss: 5.9104 | Train Acc: 97.68| Val Acc: 61.79\n",
      "Epoch 0955: | Train Loss: 0.0296 | Val Loss: 6.0117 | Train Acc: 97.80| Val Acc: 61.69\n",
      "Epoch 0956: | Train Loss: 0.0319 | Val Loss: 5.9085 | Train Acc: 97.10| Val Acc: 61.36\n",
      "Epoch 0957: | Train Loss: 0.0295 | Val Loss: 5.9454 | Train Acc: 97.44| Val Acc: 61.29\n",
      "Epoch 0958: | Train Loss: 0.0235 | Val Loss: 5.9260 | Train Acc: 97.97| Val Acc: 61.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0959: | Train Loss: 0.0279 | Val Loss: 5.9404 | Train Acc: 97.73| Val Acc: 61.60\n",
      "Epoch 0960: | Train Loss: 0.0272 | Val Loss: 5.9627 | Train Acc: 97.90| Val Acc: 61.70\n",
      "Epoch 0961: | Train Loss: 0.0245 | Val Loss: 6.0996 | Train Acc: 97.77| Val Acc: 61.71\n",
      "Epoch 0962: | Train Loss: 0.0264 | Val Loss: 6.1552 | Train Acc: 97.71| Val Acc: 61.79\n",
      "Epoch 0963: | Train Loss: 0.0327 | Val Loss: 6.0837 | Train Acc: 97.37| Val Acc: 61.67\n",
      "Epoch 0964: | Train Loss: 0.0290 | Val Loss: 6.0522 | Train Acc: 98.02| Val Acc: 62.16\n",
      "Epoch 0965: | Train Loss: 0.0282 | Val Loss: 6.1495 | Train Acc: 97.83| Val Acc: 61.38\n",
      "Epoch 0966: | Train Loss: 0.0279 | Val Loss: 6.1732 | Train Acc: 97.16| Val Acc: 60.87\n",
      "Epoch 0967: | Train Loss: 0.0287 | Val Loss: 6.2300 | Train Acc: 97.88| Val Acc: 61.48\n",
      "Epoch 0968: | Train Loss: 0.0295 | Val Loss: 6.1523 | Train Acc: 97.81| Val Acc: 61.19\n",
      "Epoch 0969: | Train Loss: 0.0247 | Val Loss: 6.0978 | Train Acc: 98.21| Val Acc: 60.76\n",
      "Epoch 0970: | Train Loss: 0.0264 | Val Loss: 6.1343 | Train Acc: 98.10| Val Acc: 61.26\n",
      "Epoch 0971: | Train Loss: 0.0279 | Val Loss: 6.0928 | Train Acc: 97.67| Val Acc: 61.33\n",
      "Epoch 0972: | Train Loss: 0.0242 | Val Loss: 6.0852 | Train Acc: 97.71| Val Acc: 61.65\n",
      "Epoch 0973: | Train Loss: 0.0264 | Val Loss: 6.1191 | Train Acc: 97.74| Val Acc: 61.88\n",
      "Epoch 0974: | Train Loss: 0.0267 | Val Loss: 6.0656 | Train Acc: 97.56| Val Acc: 61.94\n",
      "Epoch 0975: | Train Loss: 0.0289 | Val Loss: 6.0069 | Train Acc: 97.75| Val Acc: 61.98\n",
      "Epoch 0976: | Train Loss: 0.0248 | Val Loss: 6.0720 | Train Acc: 97.88| Val Acc: 60.94\n",
      "Epoch 0977: | Train Loss: 0.0256 | Val Loss: 6.1428 | Train Acc: 97.95| Val Acc: 61.05\n",
      "Epoch 0978: | Train Loss: 0.0274 | Val Loss: 6.0327 | Train Acc: 97.53| Val Acc: 61.90\n",
      "Epoch 0979: | Train Loss: 0.0323 | Val Loss: 5.7945 | Train Acc: 97.70| Val Acc: 62.00\n",
      "Epoch 0980: | Train Loss: 0.0283 | Val Loss: 5.6670 | Train Acc: 97.34| Val Acc: 60.97\n",
      "Epoch 0981: | Train Loss: 0.0246 | Val Loss: 5.7960 | Train Acc: 98.27| Val Acc: 61.29\n",
      "Epoch 0982: | Train Loss: 0.0312 | Val Loss: 5.8629 | Train Acc: 97.53| Val Acc: 61.28\n",
      "Epoch 0983: | Train Loss: 0.0259 | Val Loss: 5.8964 | Train Acc: 97.92| Val Acc: 62.11\n",
      "Epoch 0984: | Train Loss: 0.0264 | Val Loss: 5.9457 | Train Acc: 97.71| Val Acc: 62.21\n",
      "Epoch 0985: | Train Loss: 0.0260 | Val Loss: 5.9523 | Train Acc: 97.85| Val Acc: 62.61\n",
      "Epoch 0986: | Train Loss: 0.0250 | Val Loss: 5.9795 | Train Acc: 97.73| Val Acc: 62.70\n",
      "Epoch 0987: | Train Loss: 0.0254 | Val Loss: 6.0184 | Train Acc: 97.92| Val Acc: 62.06\n",
      "Epoch 0988: | Train Loss: 0.0262 | Val Loss: 5.9294 | Train Acc: 97.61| Val Acc: 61.74\n",
      "Epoch 0989: | Train Loss: 0.0277 | Val Loss: 5.8830 | Train Acc: 97.75| Val Acc: 62.11\n",
      "Epoch 0990: | Train Loss: 0.0253 | Val Loss: 5.9816 | Train Acc: 98.31| Val Acc: 62.09\n",
      "Epoch 0991: | Train Loss: 0.0247 | Val Loss: 6.1042 | Train Acc: 97.99| Val Acc: 60.89\n",
      "Epoch 0992: | Train Loss: 0.0255 | Val Loss: 6.2774 | Train Acc: 97.38| Val Acc: 60.86\n",
      "Epoch 0993: | Train Loss: 0.0271 | Val Loss: 6.1696 | Train Acc: 98.08| Val Acc: 60.74\n",
      "Epoch 0994: | Train Loss: 0.0292 | Val Loss: 6.0958 | Train Acc: 97.74| Val Acc: 60.74\n",
      "Epoch 0995: | Train Loss: 0.0225 | Val Loss: 6.1067 | Train Acc: 98.03| Val Acc: 61.66\n",
      "Epoch 0996: | Train Loss: 0.0236 | Val Loss: 6.0519 | Train Acc: 97.96| Val Acc: 61.55\n",
      "Epoch 0997: | Train Loss: 0.0275 | Val Loss: 5.9658 | Train Acc: 97.76| Val Acc: 61.45\n",
      "Epoch 0998: | Train Loss: 0.0258 | Val Loss: 5.9615 | Train Acc: 97.92| Val Acc: 61.35\n",
      "Epoch 0999: | Train Loss: 0.0233 | Val Loss: 5.9646 | Train Acc: 97.76| Val Acc: 61.59\n",
      "Epoch 1000: | Train Loss: 0.0233 | Val Loss: 6.1436 | Train Acc: 98.20| Val Acc: 61.89\n",
      "Epoch 1001: | Train Loss: 0.0274 | Val Loss: 6.1195 | Train Acc: 97.65| Val Acc: 61.18\n",
      "Epoch 1002: | Train Loss: 0.0236 | Val Loss: 6.1503 | Train Acc: 98.19| Val Acc: 61.25\n",
      "Epoch 1003: | Train Loss: 0.0228 | Val Loss: 6.2660 | Train Acc: 97.85| Val Acc: 60.73\n",
      "Epoch 1004: | Train Loss: 0.0226 | Val Loss: 6.1612 | Train Acc: 97.92| Val Acc: 61.58\n",
      "Epoch 1005: | Train Loss: 0.0240 | Val Loss: 6.0820 | Train Acc: 98.18| Val Acc: 61.58\n",
      "Epoch 1006: | Train Loss: 0.0254 | Val Loss: 6.1589 | Train Acc: 98.07| Val Acc: 61.67\n",
      "Epoch 1007: | Train Loss: 0.0258 | Val Loss: 6.2487 | Train Acc: 98.22| Val Acc: 61.67\n",
      "Epoch 1008: | Train Loss: 0.0220 | Val Loss: 6.2104 | Train Acc: 97.92| Val Acc: 61.28\n",
      "Epoch 1009: | Train Loss: 0.0239 | Val Loss: 6.2487 | Train Acc: 97.96| Val Acc: 61.80\n",
      "Epoch 1010: | Train Loss: 0.0227 | Val Loss: 6.3070 | Train Acc: 98.12| Val Acc: 61.45\n",
      "Epoch 1011: | Train Loss: 0.0250 | Val Loss: 6.2703 | Train Acc: 97.86| Val Acc: 61.74\n",
      "Epoch 1012: | Train Loss: 0.0215 | Val Loss: 6.2175 | Train Acc: 98.17| Val Acc: 62.06\n",
      "Epoch 1013: | Train Loss: 0.0258 | Val Loss: 6.1501 | Train Acc: 97.76| Val Acc: 62.58\n",
      "Epoch 1014: | Train Loss: 0.0246 | Val Loss: 6.2403 | Train Acc: 98.08| Val Acc: 62.56\n",
      "Epoch 1015: | Train Loss: 0.0226 | Val Loss: 6.1882 | Train Acc: 98.26| Val Acc: 61.85\n",
      "Epoch 1016: | Train Loss: 0.0247 | Val Loss: 6.1022 | Train Acc: 97.68| Val Acc: 61.67\n",
      "Epoch 1017: | Train Loss: 0.0211 | Val Loss: 6.1064 | Train Acc: 98.39| Val Acc: 62.18\n",
      "Epoch 1018: | Train Loss: 0.0802 | Val Loss: 6.3138 | Train Acc: 97.82| Val Acc: 62.20\n",
      "Epoch 1019: | Train Loss: 0.0279 | Val Loss: 6.2367 | Train Acc: 97.71| Val Acc: 62.38\n",
      "Epoch 1020: | Train Loss: 0.0357 | Val Loss: 6.1308 | Train Acc: 97.29| Val Acc: 62.89\n",
      "Epoch 1021: | Train Loss: 0.0287 | Val Loss: 6.1072 | Train Acc: 97.50| Val Acc: 62.69\n",
      "Epoch 1022: | Train Loss: 0.0294 | Val Loss: 5.9991 | Train Acc: 97.64| Val Acc: 62.27\n",
      "Epoch 1023: | Train Loss: 0.0267 | Val Loss: 6.0210 | Train Acc: 97.97| Val Acc: 62.71\n",
      "Epoch 1024: | Train Loss: 0.0297 | Val Loss: 6.1048 | Train Acc: 98.09| Val Acc: 62.11\n",
      "Epoch 1025: | Train Loss: 0.0269 | Val Loss: 6.0804 | Train Acc: 97.60| Val Acc: 62.43\n",
      "Epoch 1026: | Train Loss: 0.0296 | Val Loss: 5.8718 | Train Acc: 97.14| Val Acc: 61.79\n",
      "Epoch 1027: | Train Loss: 0.0274 | Val Loss: 5.7912 | Train Acc: 97.28| Val Acc: 62.39\n",
      "Epoch 1028: | Train Loss: 0.0307 | Val Loss: 5.8822 | Train Acc: 97.68| Val Acc: 62.61\n",
      "Epoch 1029: | Train Loss: 0.0262 | Val Loss: 5.9995 | Train Acc: 98.06| Val Acc: 61.79\n",
      "Epoch 1030: | Train Loss: 0.0241 | Val Loss: 6.0326 | Train Acc: 97.70| Val Acc: 61.27\n",
      "Epoch 1031: | Train Loss: 0.0280 | Val Loss: 6.1650 | Train Acc: 97.89| Val Acc: 61.68\n",
      "Epoch 1032: | Train Loss: 0.0259 | Val Loss: 6.2340 | Train Acc: 97.75| Val Acc: 62.27\n",
      "Epoch 1033: | Train Loss: 0.0236 | Val Loss: 6.1662 | Train Acc: 97.99| Val Acc: 62.38\n",
      "Epoch 1034: | Train Loss: 0.0249 | Val Loss: 6.1853 | Train Acc: 97.83| Val Acc: 62.39\n",
      "Epoch 1035: | Train Loss: 0.0228 | Val Loss: 6.2670 | Train Acc: 98.20| Val Acc: 62.49\n",
      "Epoch 1036: | Train Loss: 0.0219 | Val Loss: 6.2466 | Train Acc: 98.19| Val Acc: 62.08\n",
      "Epoch 1037: | Train Loss: 0.0228 | Val Loss: 6.2668 | Train Acc: 98.05| Val Acc: 62.50\n",
      "Epoch 1038: | Train Loss: 0.0289 | Val Loss: 6.4191 | Train Acc: 97.84| Val Acc: 62.40\n",
      "Epoch 1039: | Train Loss: 0.0293 | Val Loss: 6.4490 | Train Acc: 98.26| Val Acc: 61.78\n",
      "Epoch 1040: | Train Loss: 0.0334 | Val Loss: 6.1907 | Train Acc: 97.26| Val Acc: 61.59\n",
      "Epoch 1041: | Train Loss: 0.0248 | Val Loss: 6.1650 | Train Acc: 97.50| Val Acc: 62.38\n",
      "Epoch 1042: | Train Loss: 0.0282 | Val Loss: 6.1840 | Train Acc: 97.46| Val Acc: 62.89\n",
      "Epoch 1043: | Train Loss: 0.0294 | Val Loss: 6.1771 | Train Acc: 97.61| Val Acc: 62.48\n",
      "Epoch 1044: | Train Loss: 0.0274 | Val Loss: 6.3075 | Train Acc: 97.53| Val Acc: 62.90\n",
      "Epoch 1045: | Train Loss: 0.0249 | Val Loss: 6.2485 | Train Acc: 97.80| Val Acc: 62.52\n",
      "Epoch 1046: | Train Loss: 0.0236 | Val Loss: 6.1047 | Train Acc: 98.12| Val Acc: 62.58\n",
      "Epoch 1047: | Train Loss: 0.0280 | Val Loss: 6.1106 | Train Acc: 97.52| Val Acc: 62.48\n",
      "Epoch 1048: | Train Loss: 0.0289 | Val Loss: 6.1197 | Train Acc: 97.68| Val Acc: 62.46\n",
      "Epoch 1049: | Train Loss: 0.0248 | Val Loss: 5.8789 | Train Acc: 97.85| Val Acc: 61.98\n",
      "Epoch 1050: | Train Loss: 0.0201 | Val Loss: 5.8505 | Train Acc: 98.60| Val Acc: 62.29\n",
      "Epoch 1051: | Train Loss: 0.0232 | Val Loss: 5.9870 | Train Acc: 98.04| Val Acc: 62.58\n",
      "Epoch 1052: | Train Loss: 0.0249 | Val Loss: 6.1815 | Train Acc: 97.90| Val Acc: 61.86\n",
      "Epoch 1053: | Train Loss: 0.0204 | Val Loss: 6.3473 | Train Acc: 98.31| Val Acc: 62.61\n",
      "Epoch 1054: | Train Loss: 0.0260 | Val Loss: 6.2395 | Train Acc: 97.98| Val Acc: 62.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1055: | Train Loss: 0.0207 | Val Loss: 6.2481 | Train Acc: 98.22| Val Acc: 62.47\n",
      "Epoch 1056: | Train Loss: 0.0222 | Val Loss: 6.3439 | Train Acc: 97.90| Val Acc: 62.26\n",
      "Epoch 1057: | Train Loss: 0.0221 | Val Loss: 6.3226 | Train Acc: 98.10| Val Acc: 62.36\n",
      "Epoch 1058: | Train Loss: 0.0207 | Val Loss: 6.2432 | Train Acc: 97.86| Val Acc: 62.06\n",
      "Epoch 1059: | Train Loss: 0.0218 | Val Loss: 6.2291 | Train Acc: 98.04| Val Acc: 61.86\n",
      "Epoch 1060: | Train Loss: 0.0218 | Val Loss: 6.3307 | Train Acc: 98.40| Val Acc: 62.58\n",
      "Epoch 1061: | Train Loss: 0.0256 | Val Loss: 6.3082 | Train Acc: 97.65| Val Acc: 62.19\n",
      "Epoch 1062: | Train Loss: 0.0222 | Val Loss: 6.2985 | Train Acc: 98.00| Val Acc: 62.22\n",
      "Epoch 1063: | Train Loss: 0.0204 | Val Loss: 6.3545 | Train Acc: 98.12| Val Acc: 63.12\n",
      "Epoch 1064: | Train Loss: 0.0202 | Val Loss: 6.3529 | Train Acc: 98.40| Val Acc: 63.09\n",
      "Epoch 1065: | Train Loss: 0.0195 | Val Loss: 6.3519 | Train Acc: 98.58| Val Acc: 62.17\n",
      "Epoch 1066: | Train Loss: 0.0184 | Val Loss: 6.2943 | Train Acc: 98.37| Val Acc: 62.28\n",
      "Epoch 1067: | Train Loss: 0.0187 | Val Loss: 6.2128 | Train Acc: 98.39| Val Acc: 62.19\n",
      "Epoch 1068: | Train Loss: 0.0185 | Val Loss: 6.1787 | Train Acc: 98.70| Val Acc: 62.49\n",
      "Epoch 1069: | Train Loss: 0.0211 | Val Loss: 6.2349 | Train Acc: 98.22| Val Acc: 62.60\n",
      "Epoch 1070: | Train Loss: 0.0211 | Val Loss: 6.2497 | Train Acc: 98.36| Val Acc: 62.81\n",
      "Epoch 1071: | Train Loss: 0.0209 | Val Loss: 6.2764 | Train Acc: 98.50| Val Acc: 62.93\n",
      "Epoch 1072: | Train Loss: 0.0219 | Val Loss: 6.3240 | Train Acc: 98.54| Val Acc: 62.08\n",
      "Epoch 1073: | Train Loss: 0.0194 | Val Loss: 6.3061 | Train Acc: 98.41| Val Acc: 62.50\n",
      "Epoch 1074: | Train Loss: 0.0231 | Val Loss: 6.3909 | Train Acc: 98.09| Val Acc: 62.39\n",
      "Epoch 1075: | Train Loss: 0.0224 | Val Loss: 6.4664 | Train Acc: 98.04| Val Acc: 62.70\n",
      "Epoch 1076: | Train Loss: 0.0210 | Val Loss: 6.4521 | Train Acc: 98.30| Val Acc: 62.27\n",
      "Epoch 1077: | Train Loss: 0.0204 | Val Loss: 6.3581 | Train Acc: 98.25| Val Acc: 62.00\n",
      "Epoch 1078: | Train Loss: 0.0583 | Val Loss: 6.4220 | Train Acc: 98.25| Val Acc: 62.69\n",
      "Epoch 1079: | Train Loss: 0.0340 | Val Loss: 6.4723 | Train Acc: 97.86| Val Acc: 62.31\n",
      "Epoch 1080: | Train Loss: 0.0260 | Val Loss: 6.4498 | Train Acc: 97.77| Val Acc: 62.08\n",
      "Epoch 1081: | Train Loss: 0.0350 | Val Loss: 6.4755 | Train Acc: 96.95| Val Acc: 63.00\n",
      "Epoch 1082: | Train Loss: 0.0258 | Val Loss: 6.6447 | Train Acc: 97.84| Val Acc: 62.88\n",
      "Epoch 1083: | Train Loss: 0.0305 | Val Loss: 6.5778 | Train Acc: 97.48| Val Acc: 62.97\n",
      "Epoch 1084: | Train Loss: 0.0262 | Val Loss: 6.4832 | Train Acc: 97.68| Val Acc: 62.70\n",
      "Epoch 1085: | Train Loss: 0.0258 | Val Loss: 6.5347 | Train Acc: 97.95| Val Acc: 61.97\n",
      "Epoch 1086: | Train Loss: 0.0252 | Val Loss: 6.5450 | Train Acc: 97.78| Val Acc: 62.78\n",
      "Epoch 1087: | Train Loss: 0.0271 | Val Loss: 6.2677 | Train Acc: 97.77| Val Acc: 61.85\n",
      "Epoch 1088: | Train Loss: 0.0248 | Val Loss: 6.2719 | Train Acc: 97.77| Val Acc: 62.06\n",
      "Epoch 1089: | Train Loss: 0.0256 | Val Loss: 6.4137 | Train Acc: 98.01| Val Acc: 62.07\n",
      "Epoch 1090: | Train Loss: 0.0229 | Val Loss: 6.5471 | Train Acc: 97.79| Val Acc: 62.58\n",
      "Epoch 1091: | Train Loss: 0.0272 | Val Loss: 6.5706 | Train Acc: 97.85| Val Acc: 62.28\n",
      "Epoch 1092: | Train Loss: 0.0204 | Val Loss: 6.5499 | Train Acc: 98.38| Val Acc: 61.26\n",
      "Epoch 1093: | Train Loss: 0.0232 | Val Loss: 6.5575 | Train Acc: 97.97| Val Acc: 61.98\n",
      "Epoch 1094: | Train Loss: 0.0242 | Val Loss: 6.5996 | Train Acc: 97.91| Val Acc: 62.78\n",
      "Epoch 1095: | Train Loss: 0.0218 | Val Loss: 6.6454 | Train Acc: 98.35| Val Acc: 62.39\n",
      "Epoch 1096: | Train Loss: 0.0283 | Val Loss: 6.6243 | Train Acc: 97.85| Val Acc: 62.46\n",
      "Epoch 1097: | Train Loss: 0.0242 | Val Loss: 6.5499 | Train Acc: 97.97| Val Acc: 62.78\n",
      "Epoch 1098: | Train Loss: 0.0231 | Val Loss: 6.5069 | Train Acc: 98.10| Val Acc: 63.50\n",
      "Epoch 1099: | Train Loss: 0.0248 | Val Loss: 6.4210 | Train Acc: 97.70| Val Acc: 62.50\n",
      "Epoch 1100: | Train Loss: 0.0273 | Val Loss: 6.3722 | Train Acc: 97.84| Val Acc: 62.50\n",
      "Epoch 1101: | Train Loss: 0.0240 | Val Loss: 6.4604 | Train Acc: 98.22| Val Acc: 62.17\n",
      "Epoch 1102: | Train Loss: 0.0207 | Val Loss: 6.6382 | Train Acc: 98.27| Val Acc: 61.89\n",
      "Epoch 1103: | Train Loss: 0.0229 | Val Loss: 6.6579 | Train Acc: 98.17| Val Acc: 61.38\n",
      "Epoch 1104: | Train Loss: 0.0229 | Val Loss: 6.6297 | Train Acc: 98.36| Val Acc: 62.08\n",
      "Epoch 1105: | Train Loss: 0.0254 | Val Loss: 6.5718 | Train Acc: 97.94| Val Acc: 62.10\n",
      "Epoch 1106: | Train Loss: 0.0207 | Val Loss: 6.5523 | Train Acc: 98.17| Val Acc: 62.51\n",
      "Epoch 1107: | Train Loss: 0.0255 | Val Loss: 6.4907 | Train Acc: 98.04| Val Acc: 62.48\n",
      "Epoch 1108: | Train Loss: 0.0214 | Val Loss: 6.5790 | Train Acc: 98.48| Val Acc: 61.86\n",
      "Epoch 1109: | Train Loss: 0.0222 | Val Loss: 6.5714 | Train Acc: 98.18| Val Acc: 62.43\n",
      "Epoch 1110: | Train Loss: 0.0212 | Val Loss: 6.4871 | Train Acc: 98.42| Val Acc: 62.25\n",
      "Epoch 1111: | Train Loss: 0.0237 | Val Loss: 6.4813 | Train Acc: 97.90| Val Acc: 61.75\n",
      "Epoch 1112: | Train Loss: 0.0237 | Val Loss: 6.4895 | Train Acc: 98.38| Val Acc: 62.46\n",
      "Epoch 1113: | Train Loss: 0.0242 | Val Loss: 6.6231 | Train Acc: 97.88| Val Acc: 62.56\n",
      "Epoch 1114: | Train Loss: 0.0197 | Val Loss: 6.6925 | Train Acc: 98.39| Val Acc: 62.55\n",
      "Epoch 1115: | Train Loss: 0.0184 | Val Loss: 6.7236 | Train Acc: 98.46| Val Acc: 61.86\n",
      "Epoch 1116: | Train Loss: 0.0193 | Val Loss: 6.7128 | Train Acc: 98.19| Val Acc: 62.66\n",
      "Epoch 1117: | Train Loss: 0.0217 | Val Loss: 6.7731 | Train Acc: 98.13| Val Acc: 62.69\n",
      "Epoch 1118: | Train Loss: 0.0178 | Val Loss: 6.8388 | Train Acc: 98.59| Val Acc: 62.18\n",
      "Epoch 1119: | Train Loss: 0.0191 | Val Loss: 6.8183 | Train Acc: 98.45| Val Acc: 61.96\n",
      "Epoch 1120: | Train Loss: 0.0184 | Val Loss: 6.8156 | Train Acc: 98.49| Val Acc: 62.14\n",
      "Epoch 1121: | Train Loss: 0.0170 | Val Loss: 6.7092 | Train Acc: 98.72| Val Acc: 62.73\n",
      "Epoch 1122: | Train Loss: 0.0186 | Val Loss: 6.6236 | Train Acc: 98.48| Val Acc: 62.46\n",
      "Epoch 1123: | Train Loss: 0.0191 | Val Loss: 6.7092 | Train Acc: 98.29| Val Acc: 62.66\n",
      "Epoch 1124: | Train Loss: 0.0177 | Val Loss: 6.8262 | Train Acc: 98.25| Val Acc: 62.75\n",
      "Epoch 1125: | Train Loss: 0.0162 | Val Loss: 6.8205 | Train Acc: 98.77| Val Acc: 63.57\n",
      "Epoch 1126: | Train Loss: 0.0176 | Val Loss: 6.7926 | Train Acc: 98.42| Val Acc: 62.98\n",
      "Epoch 1127: | Train Loss: 0.0183 | Val Loss: 6.7656 | Train Acc: 98.52| Val Acc: 63.49\n",
      "Epoch 1128: | Train Loss: 0.0174 | Val Loss: 6.7805 | Train Acc: 98.52| Val Acc: 63.68\n",
      "Epoch 1129: | Train Loss: 0.0191 | Val Loss: 6.7790 | Train Acc: 98.35| Val Acc: 63.38\n",
      "Epoch 1130: | Train Loss: 0.0160 | Val Loss: 6.7194 | Train Acc: 98.49| Val Acc: 63.05\n",
      "Epoch 1131: | Train Loss: 0.0202 | Val Loss: 6.6445 | Train Acc: 98.79| Val Acc: 62.95\n",
      "Epoch 1132: | Train Loss: 0.0157 | Val Loss: 6.6660 | Train Acc: 99.05| Val Acc: 63.18\n",
      "Epoch 1133: | Train Loss: 0.0162 | Val Loss: 6.7407 | Train Acc: 98.50| Val Acc: 62.97\n",
      "Epoch 1134: | Train Loss: 0.0216 | Val Loss: 6.8630 | Train Acc: 98.27| Val Acc: 63.27\n",
      "Epoch 1135: | Train Loss: 0.0302 | Val Loss: 6.8453 | Train Acc: 98.34| Val Acc: 62.08\n",
      "Epoch 1136: | Train Loss: 0.0210 | Val Loss: 6.6799 | Train Acc: 98.27| Val Acc: 61.17\n",
      "Epoch 1137: | Train Loss: 0.0281 | Val Loss: 6.7488 | Train Acc: 97.81| Val Acc: 62.39\n",
      "Epoch 1138: | Train Loss: 0.0200 | Val Loss: 6.8308 | Train Acc: 98.40| Val Acc: 61.91\n",
      "Epoch 1139: | Train Loss: 0.0219 | Val Loss: 6.7506 | Train Acc: 98.12| Val Acc: 61.80\n",
      "Epoch 1140: | Train Loss: 0.0230 | Val Loss: 6.7476 | Train Acc: 98.03| Val Acc: 62.37\n",
      "Epoch 1141: | Train Loss: 0.0239 | Val Loss: 6.8058 | Train Acc: 97.88| Val Acc: 62.49\n",
      "Epoch 1142: | Train Loss: 0.0250 | Val Loss: 6.7084 | Train Acc: 97.85| Val Acc: 62.07\n",
      "Epoch 1143: | Train Loss: 0.0336 | Val Loss: 6.9347 | Train Acc: 97.75| Val Acc: 62.30\n",
      "Epoch 1144: | Train Loss: 0.0247 | Val Loss: 7.1419 | Train Acc: 98.05| Val Acc: 61.97\n",
      "Epoch 1145: | Train Loss: 0.0325 | Val Loss: 7.2152 | Train Acc: 97.64| Val Acc: 62.08\n",
      "Epoch 1146: | Train Loss: 0.0267 | Val Loss: 6.9939 | Train Acc: 97.70| Val Acc: 62.27\n",
      "Epoch 1147: | Train Loss: 0.0260 | Val Loss: 6.7336 | Train Acc: 98.21| Val Acc: 61.27\n",
      "Epoch 1148: | Train Loss: 0.0256 | Val Loss: 6.7262 | Train Acc: 97.74| Val Acc: 61.97\n",
      "Epoch 1149: | Train Loss: 0.0210 | Val Loss: 6.7631 | Train Acc: 97.94| Val Acc: 61.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1150: | Train Loss: 0.0210 | Val Loss: 6.7450 | Train Acc: 98.16| Val Acc: 62.18\n",
      "Epoch 1151: | Train Loss: 0.0225 | Val Loss: 6.6884 | Train Acc: 97.91| Val Acc: 61.59\n",
      "Epoch 1152: | Train Loss: 0.0192 | Val Loss: 6.7713 | Train Acc: 98.08| Val Acc: 62.00\n",
      "Epoch 1153: | Train Loss: 0.0220 | Val Loss: 6.8155 | Train Acc: 98.11| Val Acc: 61.76\n",
      "Epoch 1154: | Train Loss: 0.0225 | Val Loss: 6.6281 | Train Acc: 98.41| Val Acc: 61.56\n",
      "Epoch 1155: | Train Loss: 0.0307 | Val Loss: 6.4707 | Train Acc: 97.42| Val Acc: 61.41\n",
      "Epoch 1156: | Train Loss: 0.0253 | Val Loss: 6.4568 | Train Acc: 97.65| Val Acc: 61.75\n",
      "Epoch 1157: | Train Loss: 0.0215 | Val Loss: 6.5419 | Train Acc: 98.34| Val Acc: 61.38\n",
      "Epoch 1158: | Train Loss: 0.0229 | Val Loss: 6.6949 | Train Acc: 98.00| Val Acc: 62.39\n",
      "Epoch 1159: | Train Loss: 0.0167 | Val Loss: 6.7677 | Train Acc: 98.98| Val Acc: 62.20\n",
      "Epoch 1160: | Train Loss: 0.0207 | Val Loss: 6.6569 | Train Acc: 98.30| Val Acc: 62.70\n",
      "Epoch 1161: | Train Loss: 0.0200 | Val Loss: 6.5446 | Train Acc: 98.36| Val Acc: 63.00\n",
      "Epoch 1162: | Train Loss: 0.0242 | Val Loss: 6.5085 | Train Acc: 97.93| Val Acc: 63.13\n",
      "Epoch 1163: | Train Loss: 0.0162 | Val Loss: 6.4682 | Train Acc: 98.66| Val Acc: 62.42\n",
      "Epoch 1164: | Train Loss: 0.0194 | Val Loss: 6.3839 | Train Acc: 98.44| Val Acc: 62.31\n",
      "Epoch 1165: | Train Loss: 0.0198 | Val Loss: 6.3483 | Train Acc: 98.31| Val Acc: 62.41\n",
      "Epoch 1166: | Train Loss: 0.0222 | Val Loss: 6.2958 | Train Acc: 97.77| Val Acc: 62.19\n",
      "Epoch 1167: | Train Loss: 0.0210 | Val Loss: 6.3344 | Train Acc: 98.47| Val Acc: 62.40\n",
      "Epoch 1168: | Train Loss: 0.0194 | Val Loss: 6.2696 | Train Acc: 98.55| Val Acc: 62.31\n",
      "Epoch 1169: | Train Loss: 0.0240 | Val Loss: 6.2921 | Train Acc: 98.20| Val Acc: 62.19\n",
      "Epoch 1170: | Train Loss: 0.0257 | Val Loss: 6.4029 | Train Acc: 98.22| Val Acc: 61.58\n",
      "Epoch 1171: | Train Loss: 0.0284 | Val Loss: 6.4446 | Train Acc: 97.75| Val Acc: 61.88\n",
      "Epoch 1172: | Train Loss: 0.0246 | Val Loss: 6.4662 | Train Acc: 98.23| Val Acc: 62.09\n",
      "Epoch 1173: | Train Loss: 0.0218 | Val Loss: 6.4259 | Train Acc: 97.82| Val Acc: 63.00\n",
      "Epoch 1174: | Train Loss: 0.0219 | Val Loss: 6.3339 | Train Acc: 98.12| Val Acc: 62.92\n",
      "Epoch 1175: | Train Loss: 0.0199 | Val Loss: 6.2803 | Train Acc: 98.03| Val Acc: 62.57\n",
      "Epoch 1176: | Train Loss: 0.0227 | Val Loss: 6.3058 | Train Acc: 98.28| Val Acc: 62.52\n",
      "Epoch 1177: | Train Loss: 0.0223 | Val Loss: 6.3650 | Train Acc: 98.00| Val Acc: 62.43\n",
      "Epoch 1178: | Train Loss: 0.0203 | Val Loss: 6.4604 | Train Acc: 98.41| Val Acc: 61.98\n",
      "Epoch 1179: | Train Loss: 0.0202 | Val Loss: 6.4975 | Train Acc: 98.39| Val Acc: 61.27\n",
      "Epoch 1180: | Train Loss: 0.0231 | Val Loss: 6.5801 | Train Acc: 98.22| Val Acc: 62.11\n",
      "Epoch 1181: | Train Loss: 0.0243 | Val Loss: 6.7041 | Train Acc: 97.96| Val Acc: 62.21\n",
      "Epoch 1182: | Train Loss: 0.0200 | Val Loss: 6.5633 | Train Acc: 98.52| Val Acc: 61.46\n",
      "Epoch 1183: | Train Loss: 0.0189 | Val Loss: 6.5763 | Train Acc: 98.39| Val Acc: 61.54\n",
      "Epoch 1184: | Train Loss: 0.0221 | Val Loss: 6.6777 | Train Acc: 97.90| Val Acc: 61.87\n",
      "Epoch 1185: | Train Loss: 0.0201 | Val Loss: 6.6190 | Train Acc: 98.60| Val Acc: 62.41\n",
      "Epoch 1186: | Train Loss: 0.0205 | Val Loss: 6.5246 | Train Acc: 98.47| Val Acc: 61.48\n",
      "Epoch 1187: | Train Loss: 0.0169 | Val Loss: 6.5634 | Train Acc: 98.74| Val Acc: 61.49\n",
      "Epoch 1188: | Train Loss: 0.0197 | Val Loss: 6.6642 | Train Acc: 98.11| Val Acc: 61.77\n",
      "Epoch 1189: | Train Loss: 0.0175 | Val Loss: 6.6475 | Train Acc: 98.62| Val Acc: 62.07\n",
      "Epoch 1190: | Train Loss: 0.0169 | Val Loss: 6.5927 | Train Acc: 98.47| Val Acc: 61.66\n",
      "Epoch 1191: | Train Loss: 0.0221 | Val Loss: 6.5354 | Train Acc: 98.19| Val Acc: 62.16\n",
      "Epoch 1192: | Train Loss: 0.0214 | Val Loss: 6.6523 | Train Acc: 97.98| Val Acc: 62.07\n",
      "Epoch 1193: | Train Loss: 0.0185 | Val Loss: 6.7008 | Train Acc: 98.56| Val Acc: 62.15\n",
      "Epoch 1194: | Train Loss: 0.0194 | Val Loss: 6.7479 | Train Acc: 98.51| Val Acc: 61.85\n",
      "Epoch 1195: | Train Loss: 0.0184 | Val Loss: 6.8651 | Train Acc: 98.32| Val Acc: 62.07\n",
      "Epoch 1196: | Train Loss: 0.0167 | Val Loss: 6.8962 | Train Acc: 98.49| Val Acc: 62.08\n",
      "Epoch 1197: | Train Loss: 0.0232 | Val Loss: 6.9241 | Train Acc: 98.21| Val Acc: 61.58\n",
      "Epoch 1198: | Train Loss: 0.0178 | Val Loss: 6.8424 | Train Acc: 98.52| Val Acc: 62.08\n",
      "Epoch 1199: | Train Loss: 0.0172 | Val Loss: 6.7818 | Train Acc: 98.63| Val Acc: 61.89\n",
      "Epoch 1200: | Train Loss: 0.0171 | Val Loss: 6.7792 | Train Acc: 98.58| Val Acc: 61.77\n",
      "Epoch 1201: | Train Loss: 0.0154 | Val Loss: 6.7340 | Train Acc: 98.75| Val Acc: 62.28\n",
      "Epoch 1202: | Train Loss: 0.0169 | Val Loss: 6.7092 | Train Acc: 98.44| Val Acc: 63.10\n",
      "Epoch 1203: | Train Loss: 0.0162 | Val Loss: 6.7192 | Train Acc: 98.73| Val Acc: 63.02\n",
      "Epoch 1204: | Train Loss: 0.0199 | Val Loss: 6.6886 | Train Acc: 98.65| Val Acc: 62.36\n",
      "Epoch 1205: | Train Loss: 0.0141 | Val Loss: 6.6207 | Train Acc: 98.99| Val Acc: 62.14\n",
      "Epoch 1206: | Train Loss: 0.0167 | Val Loss: 6.5849 | Train Acc: 98.65| Val Acc: 62.59\n",
      "Epoch 1207: | Train Loss: 0.0167 | Val Loss: 6.6432 | Train Acc: 98.51| Val Acc: 62.50\n",
      "Epoch 1208: | Train Loss: 0.0152 | Val Loss: 6.7197 | Train Acc: 98.64| Val Acc: 62.19\n",
      "Epoch 1209: | Train Loss: 0.0179 | Val Loss: 6.8517 | Train Acc: 98.37| Val Acc: 62.19\n",
      "Epoch 1210: | Train Loss: 0.0211 | Val Loss: 6.9684 | Train Acc: 98.28| Val Acc: 62.08\n",
      "Epoch 1211: | Train Loss: 0.0203 | Val Loss: 6.9614 | Train Acc: 98.81| Val Acc: 62.58\n",
      "Epoch 1212: | Train Loss: 0.0162 | Val Loss: 6.8523 | Train Acc: 98.62| Val Acc: 62.79\n",
      "Epoch 1213: | Train Loss: 0.0201 | Val Loss: 6.7215 | Train Acc: 98.62| Val Acc: 62.07\n",
      "Epoch 1214: | Train Loss: 0.0155 | Val Loss: 6.6166 | Train Acc: 98.36| Val Acc: 61.99\n",
      "Epoch 1215: | Train Loss: 0.0216 | Val Loss: 6.6631 | Train Acc: 98.67| Val Acc: 62.39\n",
      "Epoch 1216: | Train Loss: 0.0306 | Val Loss: 6.9064 | Train Acc: 98.25| Val Acc: 60.74\n",
      "Epoch 1217: | Train Loss: 0.0328 | Val Loss: 7.1767 | Train Acc: 97.00| Val Acc: 62.18\n",
      "Epoch 1218: | Train Loss: 0.0428 | Val Loss: 6.7610 | Train Acc: 96.59| Val Acc: 61.69\n",
      "Epoch 1219: | Train Loss: 0.0292 | Val Loss: 6.5200 | Train Acc: 97.52| Val Acc: 62.39\n",
      "Epoch 1220: | Train Loss: 0.0391 | Val Loss: 6.3442 | Train Acc: 97.28| Val Acc: 62.77\n",
      "Epoch 1221: | Train Loss: 0.0305 | Val Loss: 6.3123 | Train Acc: 97.30| Val Acc: 62.18\n",
      "Epoch 1222: | Train Loss: 0.0292 | Val Loss: 6.2587 | Train Acc: 97.47| Val Acc: 62.68\n",
      "Epoch 1223: | Train Loss: 0.0298 | Val Loss: 6.4345 | Train Acc: 97.55| Val Acc: 61.90\n",
      "Epoch 1224: | Train Loss: 0.0300 | Val Loss: 6.5148 | Train Acc: 97.68| Val Acc: 62.45\n",
      "Epoch 1225: | Train Loss: 0.0217 | Val Loss: 6.4899 | Train Acc: 98.20| Val Acc: 63.46\n",
      "Epoch 1226: | Train Loss: 0.0288 | Val Loss: 6.4951 | Train Acc: 97.47| Val Acc: 62.35\n",
      "Epoch 1227: | Train Loss: 0.0292 | Val Loss: 6.4984 | Train Acc: 97.44| Val Acc: 62.70\n",
      "Epoch 1228: | Train Loss: 0.0255 | Val Loss: 6.5310 | Train Acc: 97.64| Val Acc: 62.19\n",
      "Epoch 1229: | Train Loss: 0.0223 | Val Loss: 6.5476 | Train Acc: 98.23| Val Acc: 61.99\n",
      "Epoch 1230: | Train Loss: 0.0229 | Val Loss: 6.6364 | Train Acc: 98.11| Val Acc: 61.67\n",
      "Epoch 1231: | Train Loss: 0.0224 | Val Loss: 6.7716 | Train Acc: 97.97| Val Acc: 62.07\n",
      "Epoch 1232: | Train Loss: 0.0217 | Val Loss: 6.8211 | Train Acc: 98.12| Val Acc: 61.38\n",
      "Epoch 1233: | Train Loss: 0.0200 | Val Loss: 6.8051 | Train Acc: 98.49| Val Acc: 61.38\n",
      "Epoch 1234: | Train Loss: 0.0219 | Val Loss: 6.7587 | Train Acc: 98.13| Val Acc: 61.19\n",
      "Epoch 1235: | Train Loss: 0.0186 | Val Loss: 6.7405 | Train Acc: 98.55| Val Acc: 61.15\n",
      "Epoch 1236: | Train Loss: 0.0206 | Val Loss: 6.7176 | Train Acc: 98.54| Val Acc: 61.07\n",
      "Epoch 1237: | Train Loss: 0.0174 | Val Loss: 6.6908 | Train Acc: 98.66| Val Acc: 61.27\n",
      "Epoch 1238: | Train Loss: 0.0152 | Val Loss: 6.7506 | Train Acc: 98.64| Val Acc: 61.67\n",
      "Epoch 1239: | Train Loss: 0.0242 | Val Loss: 6.8256 | Train Acc: 98.48| Val Acc: 61.57\n",
      "Epoch 1240: | Train Loss: 0.0178 | Val Loss: 6.9375 | Train Acc: 98.41| Val Acc: 61.54\n",
      "Epoch 1241: | Train Loss: 0.0274 | Val Loss: 6.9845 | Train Acc: 98.27| Val Acc: 61.85\n",
      "Epoch 1242: | Train Loss: 0.0202 | Val Loss: 6.8873 | Train Acc: 98.45| Val Acc: 61.97\n",
      "Epoch 1243: | Train Loss: 0.0190 | Val Loss: 6.8203 | Train Acc: 98.27| Val Acc: 61.97\n",
      "Epoch 1244: | Train Loss: 0.0170 | Val Loss: 6.7535 | Train Acc: 98.73| Val Acc: 61.56\n",
      "Epoch 1245: | Train Loss: 0.0196 | Val Loss: 6.8193 | Train Acc: 98.58| Val Acc: 61.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1246: | Train Loss: 0.0230 | Val Loss: 6.8472 | Train Acc: 98.29| Val Acc: 62.38\n",
      "Epoch 1247: | Train Loss: 0.0187 | Val Loss: 6.6502 | Train Acc: 98.33| Val Acc: 62.38\n",
      "Epoch 1248: | Train Loss: 0.0279 | Val Loss: 6.6119 | Train Acc: 97.91| Val Acc: 62.15\n",
      "Epoch 1249: | Train Loss: 0.0240 | Val Loss: 6.5504 | Train Acc: 98.26| Val Acc: 61.24\n",
      "Epoch 1250: | Train Loss: 0.0167 | Val Loss: 6.5720 | Train Acc: 98.59| Val Acc: 61.51\n",
      "Epoch 1251: | Train Loss: 0.0202 | Val Loss: 6.5703 | Train Acc: 98.46| Val Acc: 61.64\n",
      "Epoch 1252: | Train Loss: 0.0191 | Val Loss: 6.5742 | Train Acc: 98.48| Val Acc: 61.93\n",
      "Epoch 1253: | Train Loss: 0.0171 | Val Loss: 6.4810 | Train Acc: 98.52| Val Acc: 62.07\n",
      "Epoch 1254: | Train Loss: 0.0186 | Val Loss: 6.5305 | Train Acc: 98.33| Val Acc: 61.77\n",
      "Epoch 1255: | Train Loss: 0.0182 | Val Loss: 6.5241 | Train Acc: 98.73| Val Acc: 62.27\n",
      "Epoch 1256: | Train Loss: 0.0194 | Val Loss: 6.5217 | Train Acc: 98.40| Val Acc: 61.84\n",
      "Epoch 1257: | Train Loss: 0.0193 | Val Loss: 6.6128 | Train Acc: 98.41| Val Acc: 61.96\n",
      "Epoch 1258: | Train Loss: 0.0176 | Val Loss: 6.7083 | Train Acc: 98.85| Val Acc: 61.56\n",
      "Epoch 1259: | Train Loss: 0.0195 | Val Loss: 6.7084 | Train Acc: 98.26| Val Acc: 60.96\n",
      "Epoch 1260: | Train Loss: 0.0152 | Val Loss: 6.6960 | Train Acc: 98.92| Val Acc: 61.06\n",
      "Epoch 1261: | Train Loss: 0.0181 | Val Loss: 6.7573 | Train Acc: 98.54| Val Acc: 61.46\n",
      "Epoch 1262: | Train Loss: 0.0158 | Val Loss: 6.6425 | Train Acc: 98.87| Val Acc: 60.86\n",
      "Epoch 1263: | Train Loss: 0.0186 | Val Loss: 6.7073 | Train Acc: 98.44| Val Acc: 61.58\n",
      "Epoch 1264: | Train Loss: 0.0177 | Val Loss: 6.9030 | Train Acc: 98.43| Val Acc: 61.59\n",
      "Epoch 1265: | Train Loss: 0.0173 | Val Loss: 6.9306 | Train Acc: 98.87| Val Acc: 61.77\n",
      "Epoch 1266: | Train Loss: 0.0148 | Val Loss: 6.8526 | Train Acc: 98.89| Val Acc: 62.30\n",
      "Epoch 1267: | Train Loss: 0.0151 | Val Loss: 6.8204 | Train Acc: 98.75| Val Acc: 62.09\n",
      "Epoch 1268: | Train Loss: 0.0152 | Val Loss: 6.8518 | Train Acc: 98.58| Val Acc: 62.52\n",
      "Epoch 1269: | Train Loss: 0.0210 | Val Loss: 6.8364 | Train Acc: 98.60| Val Acc: 61.51\n",
      "Epoch 1270: | Train Loss: 0.0186 | Val Loss: 6.7516 | Train Acc: 98.48| Val Acc: 62.13\n",
      "Epoch 1271: | Train Loss: 0.0168 | Val Loss: 6.8250 | Train Acc: 98.71| Val Acc: 62.51\n",
      "Epoch 1272: | Train Loss: 0.0173 | Val Loss: 6.8844 | Train Acc: 98.66| Val Acc: 62.51\n",
      "Epoch 1273: | Train Loss: 0.0166 | Val Loss: 6.8645 | Train Acc: 98.74| Val Acc: 63.00\n",
      "Epoch 1274: | Train Loss: 0.0249 | Val Loss: 6.8641 | Train Acc: 98.27| Val Acc: 62.59\n",
      "Epoch 1275: | Train Loss: 0.0182 | Val Loss: 6.7743 | Train Acc: 98.12| Val Acc: 62.59\n",
      "Epoch 1276: | Train Loss: 0.0206 | Val Loss: 6.8566 | Train Acc: 98.67| Val Acc: 62.57\n",
      "Epoch 1277: | Train Loss: 0.0213 | Val Loss: 6.9210 | Train Acc: 98.03| Val Acc: 62.23\n",
      "Epoch 1278: | Train Loss: 0.0243 | Val Loss: 6.8820 | Train Acc: 98.02| Val Acc: 62.77\n",
      "Epoch 1279: | Train Loss: 0.0200 | Val Loss: 6.7972 | Train Acc: 98.26| Val Acc: 62.27\n",
      "Epoch 1280: | Train Loss: 0.0191 | Val Loss: 6.7709 | Train Acc: 98.63| Val Acc: 62.39\n",
      "Epoch 1281: | Train Loss: 0.0139 | Val Loss: 6.7746 | Train Acc: 98.65| Val Acc: 62.08\n",
      "Epoch 1282: | Train Loss: 0.0161 | Val Loss: 6.8275 | Train Acc: 98.68| Val Acc: 61.79\n",
      "Epoch 1283: | Train Loss: 0.0232 | Val Loss: 6.8262 | Train Acc: 98.10| Val Acc: 61.65\n",
      "Epoch 1284: | Train Loss: 0.0164 | Val Loss: 6.7763 | Train Acc: 98.73| Val Acc: 60.83\n",
      "Epoch 1285: | Train Loss: 0.0162 | Val Loss: 6.7411 | Train Acc: 98.73| Val Acc: 60.71\n",
      "Epoch 1286: | Train Loss: 0.0213 | Val Loss: 6.6842 | Train Acc: 98.39| Val Acc: 61.55\n",
      "Epoch 1287: | Train Loss: 0.0202 | Val Loss: 6.5185 | Train Acc: 98.46| Val Acc: 62.15\n",
      "Epoch 1288: | Train Loss: 0.0167 | Val Loss: 6.5834 | Train Acc: 98.54| Val Acc: 62.36\n",
      "Epoch 1289: | Train Loss: 0.0174 | Val Loss: 6.7702 | Train Acc: 98.52| Val Acc: 61.90\n",
      "Epoch 1290: | Train Loss: 0.0156 | Val Loss: 6.8740 | Train Acc: 98.38| Val Acc: 62.07\n",
      "Epoch 1291: | Train Loss: 0.0153 | Val Loss: 6.6989 | Train Acc: 98.98| Val Acc: 62.17\n",
      "Epoch 1292: | Train Loss: 0.0157 | Val Loss: 6.7427 | Train Acc: 98.56| Val Acc: 62.28\n",
      "Epoch 1293: | Train Loss: 0.0135 | Val Loss: 6.8447 | Train Acc: 98.94| Val Acc: 62.69\n",
      "Epoch 1294: | Train Loss: 0.0159 | Val Loss: 6.9360 | Train Acc: 98.74| Val Acc: 62.56\n",
      "Epoch 1295: | Train Loss: 0.0144 | Val Loss: 6.9725 | Train Acc: 98.81| Val Acc: 62.98\n",
      "Epoch 1296: | Train Loss: 0.0182 | Val Loss: 6.8318 | Train Acc: 98.48| Val Acc: 62.10\n",
      "Epoch 1297: | Train Loss: 0.0145 | Val Loss: 6.8056 | Train Acc: 99.03| Val Acc: 63.02\n",
      "Epoch 1298: | Train Loss: 0.0170 | Val Loss: 6.8737 | Train Acc: 98.29| Val Acc: 63.01\n",
      "Epoch 1299: | Train Loss: 0.0166 | Val Loss: 6.9789 | Train Acc: 98.67| Val Acc: 62.88\n",
      "Epoch 1300: | Train Loss: 0.0187 | Val Loss: 6.9461 | Train Acc: 98.28| Val Acc: 63.01\n",
      "Epoch 1301: | Train Loss: 0.0125 | Val Loss: 6.9247 | Train Acc: 98.97| Val Acc: 62.28\n",
      "Epoch 1302: | Train Loss: 0.0149 | Val Loss: 6.8509 | Train Acc: 98.71| Val Acc: 62.17\n",
      "Epoch 1303: | Train Loss: 0.0132 | Val Loss: 6.8812 | Train Acc: 98.94| Val Acc: 62.38\n",
      "Epoch 1304: | Train Loss: 0.0162 | Val Loss: 6.8731 | Train Acc: 98.66| Val Acc: 62.73\n",
      "Epoch 1305: | Train Loss: 0.0155 | Val Loss: 6.9156 | Train Acc: 98.85| Val Acc: 62.16\n",
      "Epoch 1306: | Train Loss: 0.0222 | Val Loss: 6.9868 | Train Acc: 98.43| Val Acc: 62.86\n",
      "Epoch 1307: | Train Loss: 0.0176 | Val Loss: 7.0086 | Train Acc: 98.75| Val Acc: 62.39\n",
      "Epoch 1308: | Train Loss: 0.0135 | Val Loss: 7.0754 | Train Acc: 98.93| Val Acc: 61.76\n",
      "Epoch 1309: | Train Loss: 0.0167 | Val Loss: 7.1209 | Train Acc: 98.75| Val Acc: 62.20\n",
      "Epoch 1310: | Train Loss: 0.0162 | Val Loss: 7.1627 | Train Acc: 98.53| Val Acc: 62.22\n",
      "Epoch 1311: | Train Loss: 0.0169 | Val Loss: 7.0475 | Train Acc: 98.53| Val Acc: 62.49\n",
      "Epoch 1312: | Train Loss: 0.0176 | Val Loss: 6.8152 | Train Acc: 98.77| Val Acc: 62.17\n",
      "Epoch 1313: | Train Loss: 0.0170 | Val Loss: 6.6819 | Train Acc: 98.97| Val Acc: 62.26\n",
      "Epoch 1314: | Train Loss: 0.0226 | Val Loss: 6.7321 | Train Acc: 98.53| Val Acc: 61.96\n",
      "Epoch 1315: | Train Loss: 0.0173 | Val Loss: 6.8519 | Train Acc: 98.54| Val Acc: 61.67\n",
      "Epoch 1316: | Train Loss: 0.0186 | Val Loss: 6.9156 | Train Acc: 98.34| Val Acc: 61.74\n",
      "Epoch 1317: | Train Loss: 0.0187 | Val Loss: 6.9204 | Train Acc: 98.36| Val Acc: 61.76\n",
      "Epoch 1318: | Train Loss: 0.0181 | Val Loss: 6.9465 | Train Acc: 98.37| Val Acc: 62.19\n",
      "Epoch 1319: | Train Loss: 0.0158 | Val Loss: 7.0546 | Train Acc: 98.58| Val Acc: 61.46\n",
      "Epoch 1320: | Train Loss: 0.0187 | Val Loss: 7.0498 | Train Acc: 98.51| Val Acc: 61.26\n",
      "Epoch 1321: | Train Loss: 0.0132 | Val Loss: 7.0295 | Train Acc: 98.87| Val Acc: 61.68\n",
      "Epoch 1322: | Train Loss: 0.0150 | Val Loss: 7.0744 | Train Acc: 98.64| Val Acc: 62.08\n",
      "Epoch 1323: | Train Loss: 0.0157 | Val Loss: 7.1210 | Train Acc: 98.60| Val Acc: 62.08\n",
      "Epoch 1324: | Train Loss: 0.0146 | Val Loss: 7.0783 | Train Acc: 98.76| Val Acc: 61.89\n",
      "Epoch 1325: | Train Loss: 0.0154 | Val Loss: 6.9844 | Train Acc: 98.89| Val Acc: 61.91\n",
      "Epoch 1326: | Train Loss: 0.0153 | Val Loss: 7.0057 | Train Acc: 98.69| Val Acc: 62.49\n",
      "Epoch 1327: | Train Loss: 0.0144 | Val Loss: 6.9575 | Train Acc: 98.79| Val Acc: 61.99\n",
      "Epoch 1328: | Train Loss: 0.0158 | Val Loss: 6.8425 | Train Acc: 98.66| Val Acc: 62.00\n",
      "Epoch 1329: | Train Loss: 0.0141 | Val Loss: 6.9569 | Train Acc: 98.74| Val Acc: 61.46\n",
      "Epoch 1330: | Train Loss: 0.0186 | Val Loss: 7.1712 | Train Acc: 98.83| Val Acc: 61.78\n",
      "Epoch 1331: | Train Loss: 0.0151 | Val Loss: 7.1338 | Train Acc: 98.71| Val Acc: 61.89\n",
      "Epoch 1332: | Train Loss: 0.0173 | Val Loss: 6.9909 | Train Acc: 98.93| Val Acc: 61.48\n",
      "Epoch 1333: | Train Loss: 0.0154 | Val Loss: 6.9310 | Train Acc: 98.64| Val Acc: 61.60\n",
      "Epoch 1334: | Train Loss: 0.0163 | Val Loss: 6.9935 | Train Acc: 98.49| Val Acc: 62.32\n",
      "Epoch 1335: | Train Loss: 0.0158 | Val Loss: 6.9138 | Train Acc: 98.74| Val Acc: 62.29\n",
      "Epoch 1336: | Train Loss: 0.0198 | Val Loss: 6.7369 | Train Acc: 98.39| Val Acc: 62.31\n",
      "Epoch 1337: | Train Loss: 0.0164 | Val Loss: 6.6402 | Train Acc: 98.52| Val Acc: 62.10\n",
      "Epoch 1338: | Train Loss: 0.0182 | Val Loss: 6.7458 | Train Acc: 98.54| Val Acc: 62.71\n",
      "Epoch 1339: | Train Loss: 0.0168 | Val Loss: 6.6894 | Train Acc: 98.36| Val Acc: 62.07\n",
      "Epoch 1340: | Train Loss: 0.0149 | Val Loss: 6.6476 | Train Acc: 98.86| Val Acc: 61.87\n",
      "Epoch 1341: | Train Loss: 0.0158 | Val Loss: 6.6750 | Train Acc: 98.76| Val Acc: 62.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1342: | Train Loss: 0.0139 | Val Loss: 6.6958 | Train Acc: 98.92| Val Acc: 61.61\n",
      "Epoch 1343: | Train Loss: 0.0168 | Val Loss: 6.8505 | Train Acc: 98.90| Val Acc: 61.79\n",
      "Epoch 1344: | Train Loss: 0.0156 | Val Loss: 7.0116 | Train Acc: 98.55| Val Acc: 61.38\n",
      "Epoch 1345: | Train Loss: 0.0133 | Val Loss: 7.1092 | Train Acc: 98.98| Val Acc: 61.98\n",
      "Epoch 1346: | Train Loss: 0.0178 | Val Loss: 7.2856 | Train Acc: 98.48| Val Acc: 62.39\n",
      "Epoch 1347: | Train Loss: 0.0137 | Val Loss: 7.2317 | Train Acc: 98.78| Val Acc: 62.00\n",
      "Epoch 1348: | Train Loss: 0.0129 | Val Loss: 7.1887 | Train Acc: 98.81| Val Acc: 61.96\n",
      "Epoch 1349: | Train Loss: 0.0140 | Val Loss: 7.1638 | Train Acc: 99.05| Val Acc: 61.86\n",
      "Epoch 1350: | Train Loss: 0.0137 | Val Loss: 7.1898 | Train Acc: 99.13| Val Acc: 61.87\n",
      "Epoch 1351: | Train Loss: 0.0202 | Val Loss: 7.2108 | Train Acc: 98.35| Val Acc: 61.97\n",
      "Epoch 1352: | Train Loss: 0.0142 | Val Loss: 7.3032 | Train Acc: 99.23| Val Acc: 61.67\n",
      "Epoch 1353: | Train Loss: 0.0156 | Val Loss: 7.2891 | Train Acc: 98.71| Val Acc: 61.50\n",
      "Epoch 1354: | Train Loss: 0.0149 | Val Loss: 7.2015 | Train Acc: 98.76| Val Acc: 61.58\n",
      "Epoch 1355: | Train Loss: 0.0141 | Val Loss: 7.1076 | Train Acc: 98.71| Val Acc: 61.98\n",
      "Epoch 1356: | Train Loss: 0.0155 | Val Loss: 7.0645 | Train Acc: 98.59| Val Acc: 60.85\n",
      "Epoch 1357: | Train Loss: 0.0157 | Val Loss: 7.0214 | Train Acc: 98.61| Val Acc: 61.27\n",
      "Epoch 1358: | Train Loss: 0.0146 | Val Loss: 7.1241 | Train Acc: 98.88| Val Acc: 61.96\n",
      "Epoch 1359: | Train Loss: 0.0119 | Val Loss: 7.2972 | Train Acc: 99.20| Val Acc: 61.47\n",
      "Epoch 1360: | Train Loss: 0.0152 | Val Loss: 7.3272 | Train Acc: 98.74| Val Acc: 61.66\n",
      "Epoch 1361: | Train Loss: 0.0153 | Val Loss: 7.2362 | Train Acc: 98.76| Val Acc: 62.26\n",
      "Epoch 1362: | Train Loss: 0.0128 | Val Loss: 7.2204 | Train Acc: 98.88| Val Acc: 61.25\n",
      "Epoch 1363: | Train Loss: 0.0132 | Val Loss: 7.1883 | Train Acc: 98.92| Val Acc: 61.96\n",
      "Epoch 1364: | Train Loss: 0.0157 | Val Loss: 7.2629 | Train Acc: 98.97| Val Acc: 61.77\n",
      "Epoch 1365: | Train Loss: 0.0220 | Val Loss: 7.1460 | Train Acc: 98.34| Val Acc: 62.18\n",
      "Epoch 1366: | Train Loss: 0.0212 | Val Loss: 7.0310 | Train Acc: 98.13| Val Acc: 62.68\n",
      "Epoch 1367: | Train Loss: 0.0173 | Val Loss: 7.0629 | Train Acc: 98.55| Val Acc: 61.44\n",
      "Epoch 1368: | Train Loss: 0.0192 | Val Loss: 6.9890 | Train Acc: 98.13| Val Acc: 62.14\n",
      "Epoch 1369: | Train Loss: 0.0152 | Val Loss: 6.9952 | Train Acc: 98.77| Val Acc: 61.45\n",
      "Epoch 1370: | Train Loss: 0.0151 | Val Loss: 7.0855 | Train Acc: 98.82| Val Acc: 61.87\n",
      "Epoch 1371: | Train Loss: 0.0150 | Val Loss: 7.0856 | Train Acc: 98.97| Val Acc: 62.27\n",
      "Epoch 1372: | Train Loss: 0.0149 | Val Loss: 7.0929 | Train Acc: 98.70| Val Acc: 62.08\n",
      "Epoch 1373: | Train Loss: 0.0139 | Val Loss: 7.1444 | Train Acc: 98.91| Val Acc: 62.30\n",
      "Epoch 1374: | Train Loss: 0.0096 | Val Loss: 7.2571 | Train Acc: 99.30| Val Acc: 62.30\n",
      "Epoch 1375: | Train Loss: 0.0175 | Val Loss: 7.2917 | Train Acc: 98.46| Val Acc: 61.76\n",
      "Epoch 1376: | Train Loss: 0.0138 | Val Loss: 7.2944 | Train Acc: 98.47| Val Acc: 61.67\n",
      "Epoch 1377: | Train Loss: 0.0148 | Val Loss: 7.3247 | Train Acc: 98.83| Val Acc: 62.15\n",
      "Epoch 1378: | Train Loss: 0.0149 | Val Loss: 7.3641 | Train Acc: 98.78| Val Acc: 62.46\n",
      "Epoch 1379: | Train Loss: 0.0207 | Val Loss: 7.2969 | Train Acc: 98.80| Val Acc: 62.18\n",
      "Epoch 1380: | Train Loss: 0.0148 | Val Loss: 7.3485 | Train Acc: 98.67| Val Acc: 61.95\n",
      "Epoch 1381: | Train Loss: 0.0152 | Val Loss: 7.3709 | Train Acc: 98.94| Val Acc: 61.76\n",
      "Epoch 1382: | Train Loss: 0.0140 | Val Loss: 7.4139 | Train Acc: 98.99| Val Acc: 61.36\n",
      "Epoch 1383: | Train Loss: 0.0151 | Val Loss: 7.4861 | Train Acc: 98.68| Val Acc: 61.65\n",
      "Epoch 1384: | Train Loss: 0.0130 | Val Loss: 7.3459 | Train Acc: 98.93| Val Acc: 61.74\n",
      "Epoch 1385: | Train Loss: 0.0139 | Val Loss: 7.1550 | Train Acc: 98.76| Val Acc: 62.29\n",
      "Epoch 1386: | Train Loss: 0.0137 | Val Loss: 7.0412 | Train Acc: 98.86| Val Acc: 62.49\n",
      "Epoch 1387: | Train Loss: 0.0137 | Val Loss: 7.0664 | Train Acc: 99.24| Val Acc: 61.69\n",
      "Epoch 1388: | Train Loss: 0.0127 | Val Loss: 7.2270 | Train Acc: 98.90| Val Acc: 61.46\n",
      "Epoch 1389: | Train Loss: 0.0187 | Val Loss: 7.3525 | Train Acc: 98.82| Val Acc: 60.67\n",
      "Epoch 1390: | Train Loss: 0.0145 | Val Loss: 7.4239 | Train Acc: 98.94| Val Acc: 61.27\n",
      "Epoch 1391: | Train Loss: 0.0156 | Val Loss: 7.4040 | Train Acc: 98.72| Val Acc: 61.05\n",
      "Epoch 1392: | Train Loss: 0.0132 | Val Loss: 7.3604 | Train Acc: 98.90| Val Acc: 60.15\n",
      "Epoch 1393: | Train Loss: 0.0139 | Val Loss: 7.3183 | Train Acc: 98.99| Val Acc: 60.86\n",
      "Epoch 1394: | Train Loss: 0.0136 | Val Loss: 7.2920 | Train Acc: 98.97| Val Acc: 61.67\n",
      "Epoch 1395: | Train Loss: 0.0136 | Val Loss: 7.2761 | Train Acc: 98.90| Val Acc: 61.45\n",
      "Epoch 1396: | Train Loss: 0.0154 | Val Loss: 7.2824 | Train Acc: 98.74| Val Acc: 61.67\n",
      "Epoch 1397: | Train Loss: 0.0164 | Val Loss: 7.2363 | Train Acc: 98.95| Val Acc: 61.37\n",
      "Epoch 1398: | Train Loss: 0.0156 | Val Loss: 7.1328 | Train Acc: 98.92| Val Acc: 61.16\n",
      "Epoch 1399: | Train Loss: 0.0186 | Val Loss: 7.0393 | Train Acc: 98.74| Val Acc: 61.65\n",
      "Epoch 1400: | Train Loss: 0.0211 | Val Loss: 7.1179 | Train Acc: 98.44| Val Acc: 61.84\n",
      "Epoch 1401: | Train Loss: 0.0163 | Val Loss: 7.2908 | Train Acc: 98.63| Val Acc: 62.04\n",
      "Epoch 1402: | Train Loss: 0.0178 | Val Loss: 7.2500 | Train Acc: 98.40| Val Acc: 62.05\n",
      "Epoch 1403: | Train Loss: 0.0196 | Val Loss: 7.2130 | Train Acc: 98.47| Val Acc: 62.37\n",
      "Epoch 1404: | Train Loss: 0.0153 | Val Loss: 7.1944 | Train Acc: 98.55| Val Acc: 62.87\n",
      "Epoch 1405: | Train Loss: 0.0134 | Val Loss: 7.2147 | Train Acc: 98.66| Val Acc: 62.37\n",
      "Epoch 1406: | Train Loss: 0.0122 | Val Loss: 7.2166 | Train Acc: 99.20| Val Acc: 61.47\n",
      "Epoch 1407: | Train Loss: 0.0150 | Val Loss: 7.1744 | Train Acc: 98.84| Val Acc: 61.58\n",
      "Epoch 1408: | Train Loss: 0.0120 | Val Loss: 7.1838 | Train Acc: 99.02| Val Acc: 61.68\n",
      "Epoch 1409: | Train Loss: 0.0159 | Val Loss: 7.2721 | Train Acc: 98.72| Val Acc: 61.98\n",
      "Epoch 1410: | Train Loss: 0.0121 | Val Loss: 7.2227 | Train Acc: 99.08| Val Acc: 61.78\n",
      "Epoch 1411: | Train Loss: 0.0169 | Val Loss: 7.1073 | Train Acc: 98.48| Val Acc: 62.31\n",
      "Epoch 1412: | Train Loss: 0.0189 | Val Loss: 7.1570 | Train Acc: 98.89| Val Acc: 61.37\n",
      "Epoch 1413: | Train Loss: 0.0165 | Val Loss: 7.1497 | Train Acc: 98.68| Val Acc: 60.86\n",
      "Epoch 1414: | Train Loss: 0.0203 | Val Loss: 7.1370 | Train Acc: 98.65| Val Acc: 61.50\n",
      "Epoch 1415: | Train Loss: 0.0152 | Val Loss: 7.2113 | Train Acc: 98.85| Val Acc: 61.69\n",
      "Epoch 1416: | Train Loss: 0.0195 | Val Loss: 7.2016 | Train Acc: 98.50| Val Acc: 61.68\n",
      "Epoch 1417: | Train Loss: 0.0188 | Val Loss: 7.1972 | Train Acc: 98.85| Val Acc: 61.49\n",
      "Epoch 1418: | Train Loss: 0.0136 | Val Loss: 7.0783 | Train Acc: 98.91| Val Acc: 61.20\n",
      "Epoch 1419: | Train Loss: 0.0139 | Val Loss: 7.1192 | Train Acc: 98.67| Val Acc: 61.00\n",
      "Epoch 1420: | Train Loss: 0.0137 | Val Loss: 7.1433 | Train Acc: 98.83| Val Acc: 61.08\n",
      "Epoch 1421: | Train Loss: 0.0152 | Val Loss: 7.1435 | Train Acc: 98.77| Val Acc: 61.58\n",
      "Epoch 1422: | Train Loss: 0.0166 | Val Loss: 7.2635 | Train Acc: 98.74| Val Acc: 62.16\n",
      "Epoch 1423: | Train Loss: 0.0139 | Val Loss: 7.2909 | Train Acc: 98.94| Val Acc: 62.18\n",
      "Epoch 1424: | Train Loss: 0.0118 | Val Loss: 7.2622 | Train Acc: 99.01| Val Acc: 62.39\n",
      "Epoch 1425: | Train Loss: 0.0124 | Val Loss: 7.1554 | Train Acc: 98.94| Val Acc: 62.17\n",
      "Epoch 1426: | Train Loss: 0.0128 | Val Loss: 7.1536 | Train Acc: 98.99| Val Acc: 62.27\n",
      "Epoch 1427: | Train Loss: 0.0176 | Val Loss: 7.3260 | Train Acc: 98.38| Val Acc: 61.87\n",
      "Epoch 1428: | Train Loss: 0.0180 | Val Loss: 7.4213 | Train Acc: 98.90| Val Acc: 62.59\n",
      "Epoch 1429: | Train Loss: 0.0169 | Val Loss: 7.4268 | Train Acc: 98.63| Val Acc: 62.07\n",
      "Epoch 1430: | Train Loss: 0.0155 | Val Loss: 7.3182 | Train Acc: 98.88| Val Acc: 62.00\n",
      "Epoch 1431: | Train Loss: 0.0154 | Val Loss: 7.2923 | Train Acc: 98.54| Val Acc: 61.25\n",
      "Epoch 1432: | Train Loss: 0.0149 | Val Loss: 7.2526 | Train Acc: 98.97| Val Acc: 61.47\n",
      "Epoch 1433: | Train Loss: 0.0139 | Val Loss: 7.2217 | Train Acc: 99.13| Val Acc: 61.08\n",
      "Epoch 1434: | Train Loss: 0.0156 | Val Loss: 7.0976 | Train Acc: 98.91| Val Acc: 61.08\n",
      "Epoch 1435: | Train Loss: 0.0181 | Val Loss: 7.0359 | Train Acc: 98.54| Val Acc: 60.68\n",
      "Epoch 1436: | Train Loss: 0.0166 | Val Loss: 7.0716 | Train Acc: 98.65| Val Acc: 61.48\n",
      "Epoch 1437: | Train Loss: 0.0163 | Val Loss: 7.1731 | Train Acc: 98.54| Val Acc: 61.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1438: | Train Loss: 0.0150 | Val Loss: 7.3395 | Train Acc: 98.62| Val Acc: 62.29\n",
      "Epoch 1439: | Train Loss: 0.0148 | Val Loss: 7.3791 | Train Acc: 98.77| Val Acc: 61.98\n",
      "Epoch 1440: | Train Loss: 0.0145 | Val Loss: 7.2377 | Train Acc: 99.04| Val Acc: 61.98\n",
      "Epoch 1441: | Train Loss: 0.0130 | Val Loss: 7.0872 | Train Acc: 98.99| Val Acc: 62.57\n",
      "Epoch 1442: | Train Loss: 0.0162 | Val Loss: 7.1305 | Train Acc: 98.57| Val Acc: 62.07\n",
      "Epoch 1443: | Train Loss: 0.0128 | Val Loss: 7.2442 | Train Acc: 98.93| Val Acc: 62.99\n",
      "Epoch 1444: | Train Loss: 0.0155 | Val Loss: 7.1943 | Train Acc: 98.50| Val Acc: 61.89\n",
      "Epoch 1445: | Train Loss: 0.0101 | Val Loss: 7.1596 | Train Acc: 99.23| Val Acc: 61.67\n",
      "Epoch 1446: | Train Loss: 0.0109 | Val Loss: 7.1437 | Train Acc: 99.21| Val Acc: 61.88\n",
      "Epoch 1447: | Train Loss: 0.0130 | Val Loss: 7.2123 | Train Acc: 99.24| Val Acc: 61.59\n",
      "Epoch 1448: | Train Loss: 0.0134 | Val Loss: 7.2222 | Train Acc: 98.95| Val Acc: 61.80\n",
      "Epoch 1449: | Train Loss: 0.0131 | Val Loss: 7.1437 | Train Acc: 98.74| Val Acc: 61.70\n",
      "Epoch 1450: | Train Loss: 0.0130 | Val Loss: 7.0891 | Train Acc: 98.96| Val Acc: 61.81\n",
      "Epoch 1451: | Train Loss: 0.0134 | Val Loss: 7.0434 | Train Acc: 98.80| Val Acc: 61.99\n",
      "Epoch 1452: | Train Loss: 0.0124 | Val Loss: 7.1038 | Train Acc: 98.80| Val Acc: 62.49\n",
      "Epoch 1453: | Train Loss: 0.0110 | Val Loss: 7.2062 | Train Acc: 99.03| Val Acc: 62.37\n",
      "Epoch 1454: | Train Loss: 0.0130 | Val Loss: 7.1743 | Train Acc: 99.13| Val Acc: 62.07\n",
      "Epoch 1455: | Train Loss: 0.0123 | Val Loss: 7.1290 | Train Acc: 99.40| Val Acc: 62.46\n",
      "Epoch 1456: | Train Loss: 0.0134 | Val Loss: 7.2159 | Train Acc: 98.91| Val Acc: 61.53\n",
      "Epoch 1457: | Train Loss: 0.0124 | Val Loss: 7.3490 | Train Acc: 98.89| Val Acc: 61.66\n",
      "Epoch 1458: | Train Loss: 0.0139 | Val Loss: 7.3227 | Train Acc: 99.09| Val Acc: 61.67\n",
      "Epoch 1459: | Train Loss: 0.0126 | Val Loss: 7.1344 | Train Acc: 98.88| Val Acc: 61.57\n",
      "Epoch 1460: | Train Loss: 0.0102 | Val Loss: 7.1543 | Train Acc: 99.15| Val Acc: 62.46\n",
      "Epoch 1461: | Train Loss: 0.0141 | Val Loss: 7.1611 | Train Acc: 98.94| Val Acc: 62.14\n",
      "Epoch 1462: | Train Loss: 0.0117 | Val Loss: 7.1563 | Train Acc: 99.26| Val Acc: 62.55\n",
      "Epoch 1463: | Train Loss: 0.0139 | Val Loss: 7.2269 | Train Acc: 99.13| Val Acc: 62.49\n",
      "Epoch 1464: | Train Loss: 0.0149 | Val Loss: 7.2929 | Train Acc: 98.88| Val Acc: 62.27\n",
      "Epoch 1465: | Train Loss: 0.0156 | Val Loss: 7.2836 | Train Acc: 98.83| Val Acc: 62.32\n",
      "Epoch 1466: | Train Loss: 0.0153 | Val Loss: 7.3996 | Train Acc: 98.84| Val Acc: 62.10\n",
      "Epoch 1467: | Train Loss: 0.0149 | Val Loss: 7.4438 | Train Acc: 98.98| Val Acc: 62.52\n",
      "Epoch 1468: | Train Loss: 0.0125 | Val Loss: 7.4680 | Train Acc: 99.09| Val Acc: 62.23\n",
      "Epoch 1469: | Train Loss: 0.0157 | Val Loss: 7.4006 | Train Acc: 98.94| Val Acc: 62.21\n",
      "Epoch 1470: | Train Loss: 0.0146 | Val Loss: 7.3741 | Train Acc: 98.68| Val Acc: 62.79\n",
      "Epoch 1471: | Train Loss: 0.0131 | Val Loss: 7.2857 | Train Acc: 98.90| Val Acc: 63.22\n",
      "Epoch 1472: | Train Loss: 0.0138 | Val Loss: 7.3572 | Train Acc: 98.74| Val Acc: 62.91\n",
      "Epoch 1473: | Train Loss: 0.0142 | Val Loss: 7.4829 | Train Acc: 98.91| Val Acc: 62.72\n",
      "Epoch 1474: | Train Loss: 0.0122 | Val Loss: 7.3903 | Train Acc: 98.93| Val Acc: 63.01\n",
      "Epoch 1475: | Train Loss: 0.0122 | Val Loss: 7.3295 | Train Acc: 98.77| Val Acc: 62.39\n",
      "Epoch 1476: | Train Loss: 0.0129 | Val Loss: 7.4961 | Train Acc: 98.98| Val Acc: 62.26\n",
      "Epoch 1477: | Train Loss: 0.0153 | Val Loss: 7.5224 | Train Acc: 98.64| Val Acc: 61.68\n",
      "Epoch 1478: | Train Loss: 0.0131 | Val Loss: 7.2178 | Train Acc: 99.03| Val Acc: 62.29\n",
      "Epoch 1479: | Train Loss: 0.0136 | Val Loss: 7.1126 | Train Acc: 98.87| Val Acc: 62.29\n",
      "Epoch 1480: | Train Loss: 0.0147 | Val Loss: 7.1590 | Train Acc: 98.74| Val Acc: 62.47\n",
      "Epoch 1481: | Train Loss: 0.0129 | Val Loss: 7.1233 | Train Acc: 98.98| Val Acc: 61.97\n",
      "Epoch 1482: | Train Loss: 0.0118 | Val Loss: 7.2511 | Train Acc: 98.92| Val Acc: 62.18\n",
      "Epoch 1483: | Train Loss: 0.0122 | Val Loss: 7.2690 | Train Acc: 99.04| Val Acc: 61.89\n",
      "Epoch 1484: | Train Loss: 0.0131 | Val Loss: 7.2211 | Train Acc: 98.74| Val Acc: 61.59\n",
      "Epoch 1485: | Train Loss: 0.0102 | Val Loss: 7.2136 | Train Acc: 99.29| Val Acc: 62.29\n",
      "Epoch 1486: | Train Loss: 0.0123 | Val Loss: 7.2879 | Train Acc: 98.89| Val Acc: 62.48\n",
      "Epoch 1487: | Train Loss: 0.0118 | Val Loss: 7.2848 | Train Acc: 99.02| Val Acc: 61.97\n",
      "Epoch 1488: | Train Loss: 0.0235 | Val Loss: 7.4555 | Train Acc: 98.91| Val Acc: 62.37\n",
      "Epoch 1489: | Train Loss: 0.0227 | Val Loss: 7.6392 | Train Acc: 98.27| Val Acc: 62.58\n",
      "Epoch 1490: | Train Loss: 0.0231 | Val Loss: 7.3723 | Train Acc: 98.01| Val Acc: 62.39\n",
      "Epoch 1491: | Train Loss: 0.0237 | Val Loss: 7.2491 | Train Acc: 98.30| Val Acc: 62.79\n",
      "Epoch 1492: | Train Loss: 0.0226 | Val Loss: 7.0804 | Train Acc: 98.34| Val Acc: 63.93\n",
      "Epoch 1493: | Train Loss: 0.0286 | Val Loss: 7.1414 | Train Acc: 97.78| Val Acc: 62.93\n",
      "Epoch 1494: | Train Loss: 0.0210 | Val Loss: 7.1378 | Train Acc: 98.17| Val Acc: 62.72\n",
      "Epoch 1495: | Train Loss: 0.0220 | Val Loss: 7.1083 | Train Acc: 98.31| Val Acc: 62.00\n",
      "Epoch 1496: | Train Loss: 0.0227 | Val Loss: 6.9674 | Train Acc: 98.21| Val Acc: 61.68\n",
      "Epoch 1497: | Train Loss: 0.0195 | Val Loss: 7.0211 | Train Acc: 98.36| Val Acc: 61.28\n",
      "Epoch 1498: | Train Loss: 0.0149 | Val Loss: 7.0992 | Train Acc: 99.01| Val Acc: 61.06\n",
      "Epoch 1499: | Train Loss: 0.0173 | Val Loss: 7.0995 | Train Acc: 98.38| Val Acc: 61.68\n",
      "Epoch 1500: | Train Loss: 0.0164 | Val Loss: 7.0431 | Train Acc: 98.82| Val Acc: 61.90\n",
      "Epoch 1501: | Train Loss: 0.0178 | Val Loss: 7.0372 | Train Acc: 98.96| Val Acc: 62.01\n",
      "Epoch 1502: | Train Loss: 0.0187 | Val Loss: 7.1589 | Train Acc: 98.77| Val Acc: 61.92\n",
      "Epoch 1503: | Train Loss: 0.0189 | Val Loss: 7.2991 | Train Acc: 98.67| Val Acc: 61.11\n",
      "Epoch 1504: | Train Loss: 0.0190 | Val Loss: 7.3811 | Train Acc: 98.38| Val Acc: 61.28\n",
      "Epoch 1505: | Train Loss: 0.0141 | Val Loss: 7.5175 | Train Acc: 98.81| Val Acc: 61.18\n",
      "Epoch 1506: | Train Loss: 0.0151 | Val Loss: 7.6018 | Train Acc: 98.86| Val Acc: 61.18\n",
      "Epoch 1507: | Train Loss: 0.0209 | Val Loss: 7.5216 | Train Acc: 98.62| Val Acc: 61.58\n",
      "Epoch 1508: | Train Loss: 0.0166 | Val Loss: 7.2332 | Train Acc: 98.64| Val Acc: 61.89\n",
      "Epoch 1509: | Train Loss: 0.0170 | Val Loss: 7.2162 | Train Acc: 98.47| Val Acc: 61.71\n",
      "Epoch 1510: | Train Loss: 0.0166 | Val Loss: 7.4176 | Train Acc: 98.60| Val Acc: 61.60\n",
      "Epoch 1511: | Train Loss: 0.0153 | Val Loss: 7.5575 | Train Acc: 98.50| Val Acc: 61.38\n",
      "Epoch 1512: | Train Loss: 0.0124 | Val Loss: 7.5637 | Train Acc: 99.14| Val Acc: 61.33\n",
      "Epoch 1513: | Train Loss: 0.0129 | Val Loss: 7.4193 | Train Acc: 98.93| Val Acc: 60.95\n",
      "Epoch 1514: | Train Loss: 0.0111 | Val Loss: 7.1936 | Train Acc: 99.13| Val Acc: 61.16\n",
      "Epoch 1515: | Train Loss: 0.0138 | Val Loss: 7.1980 | Train Acc: 99.00| Val Acc: 61.66\n",
      "Epoch 1516: | Train Loss: 0.0141 | Val Loss: 7.3100 | Train Acc: 98.94| Val Acc: 61.67\n",
      "Epoch 1517: | Train Loss: 0.0139 | Val Loss: 7.4718 | Train Acc: 98.86| Val Acc: 61.97\n",
      "Epoch 1518: | Train Loss: 0.0149 | Val Loss: 7.5613 | Train Acc: 98.77| Val Acc: 62.11\n",
      "Epoch 1519: | Train Loss: 0.0124 | Val Loss: 7.6306 | Train Acc: 98.98| Val Acc: 61.59\n",
      "Epoch 1520: | Train Loss: 0.0124 | Val Loss: 7.4703 | Train Acc: 98.83| Val Acc: 61.60\n",
      "Epoch 1521: | Train Loss: 0.0169 | Val Loss: 7.4255 | Train Acc: 98.72| Val Acc: 61.83\n",
      "Epoch 1522: | Train Loss: 0.0130 | Val Loss: 7.4437 | Train Acc: 99.07| Val Acc: 61.74\n",
      "Epoch 1523: | Train Loss: 0.0134 | Val Loss: 7.4481 | Train Acc: 98.95| Val Acc: 61.62\n",
      "Epoch 1524: | Train Loss: 0.0256 | Val Loss: 7.0808 | Train Acc: 98.94| Val Acc: 62.17\n",
      "Epoch 1525: | Train Loss: 0.0241 | Val Loss: 6.9053 | Train Acc: 98.16| Val Acc: 61.12\n",
      "Epoch 1526: | Train Loss: 0.0258 | Val Loss: 6.9695 | Train Acc: 97.84| Val Acc: 61.36\n",
      "Epoch 1527: | Train Loss: 0.0324 | Val Loss: 7.1880 | Train Acc: 97.83| Val Acc: 61.89\n",
      "Epoch 1528: | Train Loss: 0.0217 | Val Loss: 7.3386 | Train Acc: 98.31| Val Acc: 61.70\n",
      "Epoch 1529: | Train Loss: 0.0219 | Val Loss: 7.3961 | Train Acc: 97.81| Val Acc: 61.60\n",
      "Epoch 1530: | Train Loss: 0.0192 | Val Loss: 7.4438 | Train Acc: 97.99| Val Acc: 61.88\n",
      "Epoch 1531: | Train Loss: 0.0271 | Val Loss: 8.3178 | Train Acc: 98.48| Val Acc: 62.40\n",
      "Epoch 1532: | Train Loss: 0.0182 | Val Loss: 8.4755 | Train Acc: 98.62| Val Acc: 62.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1533: | Train Loss: 0.0200 | Val Loss: 8.2325 | Train Acc: 98.55| Val Acc: 62.21\n",
      "Epoch 1534: | Train Loss: 0.0163 | Val Loss: 8.1818 | Train Acc: 98.67| Val Acc: 62.31\n",
      "Epoch 1535: | Train Loss: 0.0167 | Val Loss: 8.1609 | Train Acc: 98.86| Val Acc: 62.61\n",
      "Epoch 1536: | Train Loss: 0.0196 | Val Loss: 8.3752 | Train Acc: 98.36| Val Acc: 63.01\n",
      "Epoch 1537: | Train Loss: 0.0207 | Val Loss: 8.5418 | Train Acc: 98.16| Val Acc: 61.59\n",
      "Epoch 1538: | Train Loss: 0.0165 | Val Loss: 8.4721 | Train Acc: 98.78| Val Acc: 61.91\n",
      "Epoch 1539: | Train Loss: 0.0155 | Val Loss: 8.3727 | Train Acc: 98.61| Val Acc: 61.29\n",
      "Epoch 1540: | Train Loss: 0.0179 | Val Loss: 8.2407 | Train Acc: 98.16| Val Acc: 61.21\n",
      "Epoch 1541: | Train Loss: 0.0163 | Val Loss: 8.3234 | Train Acc: 98.74| Val Acc: 61.92\n",
      "Epoch 1542: | Train Loss: 0.0140 | Val Loss: 8.3315 | Train Acc: 98.90| Val Acc: 61.93\n",
      "Epoch 1543: | Train Loss: 0.0202 | Val Loss: 8.2292 | Train Acc: 98.74| Val Acc: 61.89\n",
      "Epoch 1544: | Train Loss: 0.0175 | Val Loss: 8.0321 | Train Acc: 98.85| Val Acc: 61.92\n",
      "Epoch 1545: | Train Loss: 0.0174 | Val Loss: 7.9132 | Train Acc: 98.66| Val Acc: 61.71\n",
      "Epoch 1546: | Train Loss: 0.0145 | Val Loss: 7.9480 | Train Acc: 99.00| Val Acc: 61.99\n",
      "Epoch 1547: | Train Loss: 0.0138 | Val Loss: 7.9290 | Train Acc: 99.16| Val Acc: 61.89\n",
      "Epoch 1548: | Train Loss: 0.0129 | Val Loss: 8.0079 | Train Acc: 98.96| Val Acc: 61.50\n",
      "Epoch 1549: | Train Loss: 0.0135 | Val Loss: 8.0817 | Train Acc: 98.73| Val Acc: 62.21\n",
      "Epoch 1550: | Train Loss: 0.0125 | Val Loss: 8.0805 | Train Acc: 99.07| Val Acc: 62.81\n",
      "Epoch 1551: | Train Loss: 0.0173 | Val Loss: 8.1196 | Train Acc: 98.89| Val Acc: 62.48\n",
      "Epoch 1552: | Train Loss: 0.0157 | Val Loss: 8.1011 | Train Acc: 98.71| Val Acc: 62.68\n",
      "Epoch 1553: | Train Loss: 0.0128 | Val Loss: 8.0304 | Train Acc: 98.92| Val Acc: 62.79\n",
      "Epoch 1554: | Train Loss: 0.0126 | Val Loss: 8.1315 | Train Acc: 99.03| Val Acc: 62.63\n",
      "Epoch 1555: | Train Loss: 0.0111 | Val Loss: 8.1245 | Train Acc: 99.29| Val Acc: 62.11\n",
      "Epoch 1556: | Train Loss: 0.0128 | Val Loss: 8.1030 | Train Acc: 98.80| Val Acc: 62.00\n",
      "Epoch 1557: | Train Loss: 0.0115 | Val Loss: 8.1437 | Train Acc: 99.01| Val Acc: 61.58\n",
      "Epoch 1558: | Train Loss: 0.0138 | Val Loss: 8.1422 | Train Acc: 98.91| Val Acc: 61.90\n",
      "Epoch 1559: | Train Loss: 0.0102 | Val Loss: 8.1201 | Train Acc: 99.23| Val Acc: 61.70\n",
      "Epoch 1560: | Train Loss: 0.0150 | Val Loss: 8.2654 | Train Acc: 98.54| Val Acc: 61.39\n",
      "Epoch 1561: | Train Loss: 0.0141 | Val Loss: 8.4032 | Train Acc: 98.84| Val Acc: 61.39\n",
      "Epoch 1562: | Train Loss: 0.0110 | Val Loss: 8.3057 | Train Acc: 99.16| Val Acc: 61.90\n",
      "Epoch 1563: | Train Loss: 0.0123 | Val Loss: 8.1951 | Train Acc: 98.94| Val Acc: 61.68\n",
      "Epoch 1564: | Train Loss: 0.0084 | Val Loss: 8.1367 | Train Acc: 99.36| Val Acc: 61.69\n",
      "Epoch 1565: | Train Loss: 0.0119 | Val Loss: 8.0899 | Train Acc: 98.98| Val Acc: 61.67\n",
      "Epoch 1566: | Train Loss: 0.0112 | Val Loss: 8.1031 | Train Acc: 99.16| Val Acc: 61.68\n",
      "Epoch 1567: | Train Loss: 0.0112 | Val Loss: 8.1185 | Train Acc: 98.96| Val Acc: 61.98\n",
      "Epoch 1568: | Train Loss: 0.0100 | Val Loss: 8.0836 | Train Acc: 99.23| Val Acc: 61.77\n",
      "Epoch 1569: | Train Loss: 0.0099 | Val Loss: 8.0360 | Train Acc: 99.37| Val Acc: 61.78\n",
      "Epoch 1570: | Train Loss: 0.0083 | Val Loss: 8.0737 | Train Acc: 99.37| Val Acc: 61.74\n",
      "Epoch 1571: | Train Loss: 0.0109 | Val Loss: 8.1788 | Train Acc: 99.12| Val Acc: 61.86\n",
      "Epoch 1572: | Train Loss: 0.0099 | Val Loss: 8.2389 | Train Acc: 99.10| Val Acc: 61.98\n",
      "Epoch 1573: | Train Loss: 0.0086 | Val Loss: 8.2296 | Train Acc: 99.34| Val Acc: 62.00\n",
      "Epoch 1574: | Train Loss: 0.0103 | Val Loss: 8.2833 | Train Acc: 99.15| Val Acc: 61.60\n",
      "Epoch 1575: | Train Loss: 0.0096 | Val Loss: 8.2654 | Train Acc: 99.27| Val Acc: 61.49\n",
      "Epoch 1576: | Train Loss: 0.0082 | Val Loss: 8.1715 | Train Acc: 99.44| Val Acc: 61.88\n",
      "Epoch 1577: | Train Loss: 0.0089 | Val Loss: 8.0682 | Train Acc: 99.29| Val Acc: 61.87\n",
      "Epoch 1578: | Train Loss: 0.0119 | Val Loss: 8.0826 | Train Acc: 99.00| Val Acc: 61.68\n",
      "Epoch 1579: | Train Loss: 0.0094 | Val Loss: 8.0402 | Train Acc: 99.38| Val Acc: 61.79\n",
      "Epoch 1580: | Train Loss: 0.0125 | Val Loss: 7.9889 | Train Acc: 99.03| Val Acc: 61.91\n",
      "Epoch 1581: | Train Loss: 0.0095 | Val Loss: 7.9265 | Train Acc: 99.24| Val Acc: 62.01\n",
      "Epoch 1582: | Train Loss: 0.0114 | Val Loss: 7.8774 | Train Acc: 99.27| Val Acc: 62.52\n",
      "Epoch 1583: | Train Loss: 0.0121 | Val Loss: 7.9714 | Train Acc: 99.06| Val Acc: 62.19\n",
      "Epoch 1584: | Train Loss: 0.0107 | Val Loss: 8.1576 | Train Acc: 99.21| Val Acc: 61.68\n",
      "Epoch 1585: | Train Loss: 0.0118 | Val Loss: 8.2459 | Train Acc: 99.07| Val Acc: 61.44\n",
      "Epoch 1586: | Train Loss: 0.0092 | Val Loss: 8.2593 | Train Acc: 99.12| Val Acc: 61.34\n",
      "Epoch 1587: | Train Loss: 0.0143 | Val Loss: 8.2349 | Train Acc: 98.77| Val Acc: 61.98\n",
      "Epoch 1588: | Train Loss: 0.0091 | Val Loss: 8.1236 | Train Acc: 99.26| Val Acc: 62.09\n",
      "Epoch 1589: | Train Loss: 0.0103 | Val Loss: 8.1044 | Train Acc: 99.02| Val Acc: 62.60\n",
      "Epoch 1590: | Train Loss: 0.0107 | Val Loss: 8.0899 | Train Acc: 99.15| Val Acc: 62.59\n",
      "Epoch 1591: | Train Loss: 0.0094 | Val Loss: 8.1208 | Train Acc: 99.04| Val Acc: 61.88\n",
      "Epoch 1592: | Train Loss: 0.0089 | Val Loss: 8.1127 | Train Acc: 99.21| Val Acc: 62.00\n",
      "Epoch 1593: | Train Loss: 0.0106 | Val Loss: 8.1456 | Train Acc: 99.10| Val Acc: 61.89\n",
      "Epoch 1594: | Train Loss: 0.0089 | Val Loss: 8.1958 | Train Acc: 99.30| Val Acc: 61.78\n",
      "Epoch 1595: | Train Loss: 0.0123 | Val Loss: 8.3408 | Train Acc: 98.83| Val Acc: 61.44\n",
      "Epoch 1596: | Train Loss: 0.0104 | Val Loss: 8.4578 | Train Acc: 98.85| Val Acc: 61.76\n",
      "Epoch 1597: | Train Loss: 0.0085 | Val Loss: 8.5141 | Train Acc: 99.23| Val Acc: 62.27\n",
      "Epoch 1598: | Train Loss: 0.0087 | Val Loss: 8.4837 | Train Acc: 99.32| Val Acc: 61.66\n",
      "Epoch 1599: | Train Loss: 0.0106 | Val Loss: 8.4159 | Train Acc: 99.17| Val Acc: 61.76\n",
      "Epoch 1600: | Train Loss: 0.0084 | Val Loss: 8.3047 | Train Acc: 99.30| Val Acc: 61.67\n",
      "Epoch 1601: | Train Loss: 0.0133 | Val Loss: 8.0111 | Train Acc: 99.07| Val Acc: 61.68\n",
      "Epoch 1602: | Train Loss: 0.0093 | Val Loss: 7.8552 | Train Acc: 99.38| Val Acc: 61.49\n",
      "Epoch 1603: | Train Loss: 0.0077 | Val Loss: 7.7890 | Train Acc: 99.24| Val Acc: 61.67\n",
      "Epoch 1604: | Train Loss: 0.0100 | Val Loss: 7.7678 | Train Acc: 99.40| Val Acc: 61.77\n",
      "Epoch 1605: | Train Loss: 0.0080 | Val Loss: 7.7443 | Train Acc: 99.44| Val Acc: 61.68\n",
      "Epoch 1606: | Train Loss: 0.0107 | Val Loss: 7.7944 | Train Acc: 99.21| Val Acc: 61.58\n",
      "Epoch 1607: | Train Loss: 0.0082 | Val Loss: 7.8294 | Train Acc: 99.32| Val Acc: 62.28\n",
      "Epoch 1608: | Train Loss: 0.0079 | Val Loss: 7.8593 | Train Acc: 99.58| Val Acc: 62.27\n",
      "Epoch 1609: | Train Loss: 0.0094 | Val Loss: 7.9153 | Train Acc: 99.12| Val Acc: 61.86\n",
      "Epoch 1610: | Train Loss: 0.0150 | Val Loss: 7.8449 | Train Acc: 99.37| Val Acc: 61.60\n",
      "Epoch 1611: | Train Loss: 0.0101 | Val Loss: 7.8348 | Train Acc: 99.30| Val Acc: 62.49\n",
      "Epoch 1612: | Train Loss: 0.0109 | Val Loss: 7.9406 | Train Acc: 99.11| Val Acc: 62.27\n",
      "Epoch 1613: | Train Loss: 0.0097 | Val Loss: 8.0297 | Train Acc: 99.22| Val Acc: 62.36\n",
      "Epoch 1614: | Train Loss: 0.0109 | Val Loss: 8.0320 | Train Acc: 99.07| Val Acc: 62.17\n",
      "Epoch 1615: | Train Loss: 0.0100 | Val Loss: 8.0988 | Train Acc: 99.13| Val Acc: 62.00\n",
      "Epoch 1616: | Train Loss: 0.0124 | Val Loss: 8.1680 | Train Acc: 99.01| Val Acc: 61.70\n",
      "Epoch 1617: | Train Loss: 0.0127 | Val Loss: 8.1583 | Train Acc: 99.10| Val Acc: 61.20\n",
      "Epoch 1618: | Train Loss: 0.0117 | Val Loss: 8.1580 | Train Acc: 98.94| Val Acc: 61.38\n",
      "Epoch 1619: | Train Loss: 0.0108 | Val Loss: 8.0743 | Train Acc: 99.10| Val Acc: 62.12\n",
      "Epoch 1620: | Train Loss: 0.0218 | Val Loss: 8.2912 | Train Acc: 99.41| Val Acc: 61.60\n",
      "Epoch 1621: | Train Loss: 0.0306 | Val Loss: 8.6159 | Train Acc: 97.86| Val Acc: 61.37\n",
      "Epoch 1622: | Train Loss: 0.0408 | Val Loss: 8.5814 | Train Acc: 97.94| Val Acc: 61.80\n",
      "Epoch 1623: | Train Loss: 0.0305 | Val Loss: 8.3185 | Train Acc: 98.11| Val Acc: 61.35\n",
      "Epoch 1624: | Train Loss: 0.0279 | Val Loss: 8.1472 | Train Acc: 98.34| Val Acc: 61.78\n",
      "Epoch 1625: | Train Loss: 0.0254 | Val Loss: 7.9919 | Train Acc: 97.85| Val Acc: 62.51\n",
      "Epoch 1626: | Train Loss: 0.0290 | Val Loss: 7.7676 | Train Acc: 98.20| Val Acc: 61.79\n",
      "Epoch 1627: | Train Loss: 0.0218 | Val Loss: 7.8257 | Train Acc: 97.98| Val Acc: 62.10\n",
      "Epoch 1628: | Train Loss: 0.0224 | Val Loss: 7.8982 | Train Acc: 97.95| Val Acc: 61.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1629: | Train Loss: 0.0182 | Val Loss: 7.7821 | Train Acc: 98.53| Val Acc: 60.55\n",
      "Epoch 1630: | Train Loss: 0.0216 | Val Loss: 7.1807 | Train Acc: 98.65| Val Acc: 60.66\n",
      "Epoch 1631: | Train Loss: 0.0195 | Val Loss: 6.9686 | Train Acc: 98.43| Val Acc: 61.05\n",
      "Epoch 1632: | Train Loss: 0.0223 | Val Loss: 7.0705 | Train Acc: 98.09| Val Acc: 61.27\n",
      "Epoch 1633: | Train Loss: 0.0164 | Val Loss: 7.1368 | Train Acc: 98.67| Val Acc: 61.76\n",
      "Epoch 1634: | Train Loss: 0.0159 | Val Loss: 7.1239 | Train Acc: 98.36| Val Acc: 61.34\n",
      "Epoch 1635: | Train Loss: 0.0177 | Val Loss: 7.1162 | Train Acc: 98.36| Val Acc: 61.66\n",
      "Epoch 1636: | Train Loss: 0.0128 | Val Loss: 7.1303 | Train Acc: 98.97| Val Acc: 61.65\n",
      "Epoch 1637: | Train Loss: 0.0140 | Val Loss: 7.2002 | Train Acc: 98.86| Val Acc: 61.44\n",
      "Epoch 1638: | Train Loss: 0.0159 | Val Loss: 7.2286 | Train Acc: 98.85| Val Acc: 61.07\n",
      "Epoch 1639: | Train Loss: 0.0142 | Val Loss: 7.2559 | Train Acc: 98.70| Val Acc: 61.45\n",
      "Epoch 1640: | Train Loss: 0.0125 | Val Loss: 7.2096 | Train Acc: 98.96| Val Acc: 61.34\n",
      "Epoch 1641: | Train Loss: 0.0145 | Val Loss: 7.3070 | Train Acc: 99.01| Val Acc: 61.97\n",
      "Epoch 1642: | Train Loss: 0.0132 | Val Loss: 7.3743 | Train Acc: 98.90| Val Acc: 61.95\n",
      "Epoch 1643: | Train Loss: 0.0109 | Val Loss: 7.3893 | Train Acc: 98.88| Val Acc: 61.75\n",
      "Epoch 1644: | Train Loss: 0.0130 | Val Loss: 7.3773 | Train Acc: 99.21| Val Acc: 61.46\n",
      "Epoch 1645: | Train Loss: 0.0135 | Val Loss: 7.4604 | Train Acc: 98.95| Val Acc: 61.66\n",
      "Epoch 1646: | Train Loss: 0.0104 | Val Loss: 7.5381 | Train Acc: 99.24| Val Acc: 61.46\n",
      "Epoch 1647: | Train Loss: 0.0126 | Val Loss: 7.6011 | Train Acc: 99.14| Val Acc: 61.89\n",
      "Epoch 1648: | Train Loss: 0.0124 | Val Loss: 7.5821 | Train Acc: 98.99| Val Acc: 61.37\n",
      "Epoch 1649: | Train Loss: 0.0130 | Val Loss: 7.5410 | Train Acc: 98.97| Val Acc: 61.57\n",
      "Epoch 1650: | Train Loss: 0.0115 | Val Loss: 7.5677 | Train Acc: 99.11| Val Acc: 60.64\n",
      "Epoch 1651: | Train Loss: 0.0112 | Val Loss: 7.5217 | Train Acc: 99.12| Val Acc: 61.23\n",
      "Epoch 1652: | Train Loss: 0.0129 | Val Loss: 7.5304 | Train Acc: 99.15| Val Acc: 61.05\n",
      "Epoch 1653: | Train Loss: 0.0129 | Val Loss: 7.5450 | Train Acc: 99.24| Val Acc: 61.35\n",
      "Epoch 1654: | Train Loss: 0.0135 | Val Loss: 7.5102 | Train Acc: 98.80| Val Acc: 61.46\n",
      "Epoch 1655: | Train Loss: 0.0115 | Val Loss: 7.5037 | Train Acc: 99.13| Val Acc: 61.13\n",
      "Epoch 1656: | Train Loss: 0.0137 | Val Loss: 7.5917 | Train Acc: 98.89| Val Acc: 60.85\n",
      "Epoch 1657: | Train Loss: 0.0128 | Val Loss: 7.6862 | Train Acc: 98.89| Val Acc: 60.75\n",
      "Epoch 1658: | Train Loss: 0.0102 | Val Loss: 7.7517 | Train Acc: 99.33| Val Acc: 60.65\n",
      "Epoch 1659: | Train Loss: 0.0100 | Val Loss: 7.6984 | Train Acc: 99.21| Val Acc: 61.17\n",
      "Epoch 1660: | Train Loss: 0.0094 | Val Loss: 7.6625 | Train Acc: 99.07| Val Acc: 61.47\n",
      "Epoch 1661: | Train Loss: 0.0106 | Val Loss: 7.6718 | Train Acc: 99.18| Val Acc: 61.67\n",
      "Epoch 1662: | Train Loss: 0.0090 | Val Loss: 7.6495 | Train Acc: 99.51| Val Acc: 61.58\n",
      "Epoch 1663: | Train Loss: 0.0100 | Val Loss: 7.6403 | Train Acc: 99.20| Val Acc: 61.37\n",
      "Epoch 1664: | Train Loss: 0.0117 | Val Loss: 7.6438 | Train Acc: 98.98| Val Acc: 61.06\n",
      "Epoch 1665: | Train Loss: 0.0142 | Val Loss: 7.6675 | Train Acc: 99.18| Val Acc: 61.34\n",
      "Epoch 1666: | Train Loss: 0.0116 | Val Loss: 7.6413 | Train Acc: 99.11| Val Acc: 61.53\n",
      "Epoch 1667: | Train Loss: 0.0100 | Val Loss: 7.6540 | Train Acc: 99.00| Val Acc: 61.21\n",
      "Epoch 1668: | Train Loss: 0.0127 | Val Loss: 7.6503 | Train Acc: 99.21| Val Acc: 60.72\n",
      "Epoch 1669: | Train Loss: 0.0120 | Val Loss: 7.7317 | Train Acc: 99.03| Val Acc: 60.63\n",
      "Epoch 1670: | Train Loss: 0.0094 | Val Loss: 7.9000 | Train Acc: 99.18| Val Acc: 61.56\n",
      "Epoch 1671: | Train Loss: 0.0103 | Val Loss: 7.9358 | Train Acc: 99.10| Val Acc: 61.57\n",
      "Epoch 1672: | Train Loss: 0.0081 | Val Loss: 7.8120 | Train Acc: 99.39| Val Acc: 61.25\n",
      "Epoch 1673: | Train Loss: 0.0102 | Val Loss: 7.8200 | Train Acc: 99.14| Val Acc: 61.25\n",
      "Epoch 1674: | Train Loss: 0.0099 | Val Loss: 7.8225 | Train Acc: 99.36| Val Acc: 61.37\n",
      "Epoch 1675: | Train Loss: 0.0111 | Val Loss: 7.7675 | Train Acc: 99.27| Val Acc: 61.58\n",
      "Epoch 1676: | Train Loss: 0.0102 | Val Loss: 7.7270 | Train Acc: 99.23| Val Acc: 61.58\n",
      "Epoch 1677: | Train Loss: 0.0078 | Val Loss: 7.7383 | Train Acc: 99.45| Val Acc: 61.57\n",
      "Epoch 1678: | Train Loss: 0.0084 | Val Loss: 7.7897 | Train Acc: 99.47| Val Acc: 61.54\n",
      "Epoch 1679: | Train Loss: 0.0098 | Val Loss: 7.8724 | Train Acc: 99.11| Val Acc: 61.56\n",
      "Epoch 1680: | Train Loss: 0.0095 | Val Loss: 7.9604 | Train Acc: 99.35| Val Acc: 61.57\n",
      "Epoch 1681: | Train Loss: 0.0075 | Val Loss: 8.0388 | Train Acc: 99.28| Val Acc: 61.67\n",
      "Epoch 1682: | Train Loss: 0.0101 | Val Loss: 7.9814 | Train Acc: 99.16| Val Acc: 61.88\n",
      "Epoch 1683: | Train Loss: 0.0125 | Val Loss: 7.9128 | Train Acc: 98.78| Val Acc: 62.19\n",
      "Epoch 1684: | Train Loss: 0.0094 | Val Loss: 7.8750 | Train Acc: 99.41| Val Acc: 62.06\n",
      "Epoch 1685: | Train Loss: 0.0082 | Val Loss: 7.8344 | Train Acc: 99.53| Val Acc: 61.66\n",
      "Epoch 1686: | Train Loss: 0.0079 | Val Loss: 7.8671 | Train Acc: 99.48| Val Acc: 61.46\n",
      "Epoch 1687: | Train Loss: 0.0101 | Val Loss: 7.9900 | Train Acc: 99.14| Val Acc: 61.37\n",
      "Epoch 1688: | Train Loss: 0.0083 | Val Loss: 8.1171 | Train Acc: 99.30| Val Acc: 61.67\n",
      "Epoch 1689: | Train Loss: 0.0188 | Val Loss: 8.0168 | Train Acc: 99.42| Val Acc: 61.55\n",
      "Epoch 1690: | Train Loss: 0.0141 | Val Loss: 8.0004 | Train Acc: 98.98| Val Acc: 61.94\n",
      "Epoch 1691: | Train Loss: 0.0144 | Val Loss: 7.8055 | Train Acc: 98.87| Val Acc: 61.74\n",
      "Epoch 1692: | Train Loss: 0.0128 | Val Loss: 7.6731 | Train Acc: 99.14| Val Acc: 61.75\n",
      "Epoch 1693: | Train Loss: 0.0118 | Val Loss: 7.5797 | Train Acc: 98.92| Val Acc: 62.37\n",
      "Epoch 1694: | Train Loss: 0.0132 | Val Loss: 7.6394 | Train Acc: 98.99| Val Acc: 62.04\n",
      "Epoch 1695: | Train Loss: 0.0138 | Val Loss: 7.7181 | Train Acc: 98.96| Val Acc: 62.78\n",
      "Epoch 1696: | Train Loss: 0.0204 | Val Loss: 8.1431 | Train Acc: 98.76| Val Acc: 62.27\n",
      "Epoch 1697: | Train Loss: 0.0135 | Val Loss: 8.0608 | Train Acc: 98.78| Val Acc: 62.07\n",
      "Epoch 1698: | Train Loss: 0.0150 | Val Loss: 7.9245 | Train Acc: 98.75| Val Acc: 61.57\n",
      "Epoch 1699: | Train Loss: 0.0121 | Val Loss: 7.8236 | Train Acc: 99.04| Val Acc: 61.46\n",
      "Epoch 1700: | Train Loss: 0.0137 | Val Loss: 7.8366 | Train Acc: 98.98| Val Acc: 61.75\n",
      "Epoch 1701: | Train Loss: 0.0111 | Val Loss: 7.8234 | Train Acc: 99.25| Val Acc: 61.98\n",
      "Epoch 1702: | Train Loss: 0.0130 | Val Loss: 7.8118 | Train Acc: 98.99| Val Acc: 61.78\n",
      "Epoch 1703: | Train Loss: 0.0128 | Val Loss: 7.8400 | Train Acc: 98.93| Val Acc: 61.89\n",
      "Epoch 1704: | Train Loss: 0.0131 | Val Loss: 7.8909 | Train Acc: 98.96| Val Acc: 61.97\n",
      "Epoch 1705: | Train Loss: 0.0116 | Val Loss: 7.9220 | Train Acc: 99.01| Val Acc: 61.76\n",
      "Epoch 1706: | Train Loss: 0.0082 | Val Loss: 7.8819 | Train Acc: 99.47| Val Acc: 61.96\n",
      "Epoch 1707: | Train Loss: 0.0117 | Val Loss: 7.8754 | Train Acc: 98.73| Val Acc: 62.38\n",
      "Epoch 1708: | Train Loss: 0.0071 | Val Loss: 7.8666 | Train Acc: 99.54| Val Acc: 62.16\n",
      "Epoch 1709: | Train Loss: 0.0093 | Val Loss: 7.8536 | Train Acc: 99.21| Val Acc: 61.66\n",
      "Epoch 1710: | Train Loss: 0.0105 | Val Loss: 7.8531 | Train Acc: 99.25| Val Acc: 61.57\n",
      "Epoch 1711: | Train Loss: 0.0079 | Val Loss: 7.8840 | Train Acc: 99.29| Val Acc: 61.68\n",
      "Epoch 1712: | Train Loss: 0.0105 | Val Loss: 7.9158 | Train Acc: 99.21| Val Acc: 61.88\n",
      "Epoch 1713: | Train Loss: 0.0095 | Val Loss: 7.9226 | Train Acc: 99.21| Val Acc: 62.07\n",
      "Epoch 1714: | Train Loss: 0.0108 | Val Loss: 7.8971 | Train Acc: 99.20| Val Acc: 61.76\n",
      "Epoch 1715: | Train Loss: 0.0101 | Val Loss: 7.8568 | Train Acc: 99.31| Val Acc: 62.58\n",
      "Epoch 1716: | Train Loss: 0.0120 | Val Loss: 7.6810 | Train Acc: 98.98| Val Acc: 62.29\n",
      "Epoch 1717: | Train Loss: 0.0124 | Val Loss: 7.7945 | Train Acc: 99.26| Val Acc: 61.83\n",
      "Epoch 1718: | Train Loss: 0.0106 | Val Loss: 7.8772 | Train Acc: 99.07| Val Acc: 62.13\n",
      "Epoch 1719: | Train Loss: 0.0124 | Val Loss: 7.9873 | Train Acc: 98.77| Val Acc: 62.04\n",
      "Epoch 1720: | Train Loss: 0.0078 | Val Loss: 8.0660 | Train Acc: 99.28| Val Acc: 62.02\n",
      "Epoch 1721: | Train Loss: 0.0128 | Val Loss: 8.0372 | Train Acc: 99.10| Val Acc: 61.82\n",
      "Epoch 1722: | Train Loss: 0.0125 | Val Loss: 8.0434 | Train Acc: 98.99| Val Acc: 61.95\n",
      "Epoch 1723: | Train Loss: 0.0109 | Val Loss: 8.1254 | Train Acc: 99.09| Val Acc: 61.96\n",
      "Epoch 1724: | Train Loss: 0.0095 | Val Loss: 8.0726 | Train Acc: 99.22| Val Acc: 61.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1725: | Train Loss: 0.0105 | Val Loss: 8.0039 | Train Acc: 99.33| Val Acc: 61.35\n",
      "Epoch 1726: | Train Loss: 0.0092 | Val Loss: 7.8977 | Train Acc: 99.20| Val Acc: 61.36\n",
      "Epoch 1727: | Train Loss: 0.0111 | Val Loss: 7.8276 | Train Acc: 99.14| Val Acc: 61.55\n",
      "Epoch 1728: | Train Loss: 0.0116 | Val Loss: 7.8468 | Train Acc: 99.00| Val Acc: 61.33\n",
      "Epoch 1729: | Train Loss: 0.0119 | Val Loss: 7.8383 | Train Acc: 98.92| Val Acc: 61.43\n",
      "Epoch 1730: | Train Loss: 0.0098 | Val Loss: 7.8634 | Train Acc: 99.24| Val Acc: 61.54\n",
      "Epoch 1731: | Train Loss: 0.0093 | Val Loss: 7.8769 | Train Acc: 99.33| Val Acc: 61.47\n",
      "Epoch 1732: | Train Loss: 0.0127 | Val Loss: 7.8402 | Train Acc: 98.89| Val Acc: 61.85\n",
      "Epoch 1733: | Train Loss: 0.0097 | Val Loss: 7.7875 | Train Acc: 99.21| Val Acc: 61.76\n",
      "Epoch 1734: | Train Loss: 0.0087 | Val Loss: 7.8293 | Train Acc: 99.49| Val Acc: 61.86\n",
      "Epoch 1735: | Train Loss: 0.0089 | Val Loss: 7.8036 | Train Acc: 99.22| Val Acc: 61.97\n",
      "Epoch 1736: | Train Loss: 0.0079 | Val Loss: 7.8335 | Train Acc: 99.47| Val Acc: 61.44\n",
      "Epoch 1737: | Train Loss: 0.0105 | Val Loss: 7.8875 | Train Acc: 99.24| Val Acc: 61.86\n",
      "Epoch 1738: | Train Loss: 0.0108 | Val Loss: 7.9796 | Train Acc: 99.28| Val Acc: 61.86\n",
      "Epoch 1739: | Train Loss: 0.0103 | Val Loss: 8.0197 | Train Acc: 99.28| Val Acc: 62.28\n",
      "Epoch 1740: | Train Loss: 0.0072 | Val Loss: 8.0023 | Train Acc: 99.44| Val Acc: 61.90\n",
      "Epoch 1741: | Train Loss: 0.0085 | Val Loss: 7.9330 | Train Acc: 99.36| Val Acc: 61.77\n",
      "Epoch 1742: | Train Loss: 0.0121 | Val Loss: 7.8174 | Train Acc: 98.90| Val Acc: 61.78\n",
      "Epoch 1743: | Train Loss: 0.0118 | Val Loss: 7.7161 | Train Acc: 99.23| Val Acc: 61.86\n",
      "Epoch 1744: | Train Loss: 0.0080 | Val Loss: 7.6287 | Train Acc: 99.53| Val Acc: 62.37\n",
      "Epoch 1745: | Train Loss: 0.0098 | Val Loss: 7.7024 | Train Acc: 99.27| Val Acc: 62.69\n",
      "Epoch 1746: | Train Loss: 0.0098 | Val Loss: 7.8306 | Train Acc: 99.18| Val Acc: 62.39\n",
      "Epoch 1747: | Train Loss: 0.0121 | Val Loss: 7.8857 | Train Acc: 99.02| Val Acc: 61.98\n",
      "Epoch 1748: | Train Loss: 0.0092 | Val Loss: 7.8163 | Train Acc: 99.47| Val Acc: 61.87\n",
      "Epoch 1749: | Train Loss: 0.0122 | Val Loss: 7.7709 | Train Acc: 98.95| Val Acc: 61.88\n",
      "Epoch 1750: | Train Loss: 0.0083 | Val Loss: 7.7608 | Train Acc: 99.17| Val Acc: 61.14\n",
      "Epoch 1751: | Train Loss: 0.0100 | Val Loss: 7.7589 | Train Acc: 99.16| Val Acc: 61.14\n",
      "Epoch 1752: | Train Loss: 0.0093 | Val Loss: 7.7655 | Train Acc: 99.10| Val Acc: 61.34\n",
      "Epoch 1753: | Train Loss: 0.0082 | Val Loss: 7.7479 | Train Acc: 99.28| Val Acc: 61.75\n",
      "Epoch 1754: | Train Loss: 0.0088 | Val Loss: 7.8070 | Train Acc: 99.33| Val Acc: 61.36\n",
      "Epoch 1755: | Train Loss: 0.0104 | Val Loss: 7.8849 | Train Acc: 99.21| Val Acc: 61.06\n",
      "Epoch 1756: | Train Loss: 0.0092 | Val Loss: 7.8507 | Train Acc: 99.18| Val Acc: 60.87\n",
      "Epoch 1757: | Train Loss: 0.0107 | Val Loss: 7.7497 | Train Acc: 98.93| Val Acc: 61.39\n",
      "Epoch 1758: | Train Loss: 0.0077 | Val Loss: 7.6747 | Train Acc: 99.40| Val Acc: 61.47\n",
      "Epoch 1759: | Train Loss: 0.0084 | Val Loss: 7.7290 | Train Acc: 99.41| Val Acc: 61.95\n",
      "Epoch 1760: | Train Loss: 0.0069 | Val Loss: 7.7789 | Train Acc: 99.41| Val Acc: 62.28\n",
      "Epoch 1761: | Train Loss: 0.0066 | Val Loss: 7.9281 | Train Acc: 99.54| Val Acc: 61.87\n",
      "Epoch 1762: | Train Loss: 0.0083 | Val Loss: 8.0379 | Train Acc: 99.22| Val Acc: 62.07\n",
      "Epoch 1763: | Train Loss: 0.0077 | Val Loss: 8.1593 | Train Acc: 99.42| Val Acc: 62.27\n",
      "Epoch 1764: | Train Loss: 0.0074 | Val Loss: 8.1166 | Train Acc: 99.53| Val Acc: 62.17\n",
      "Epoch 1765: | Train Loss: 0.0099 | Val Loss: 8.0363 | Train Acc: 99.23| Val Acc: 61.45\n",
      "Epoch 1766: | Train Loss: 0.0106 | Val Loss: 7.9496 | Train Acc: 99.22| Val Acc: 61.67\n",
      "Epoch 1767: | Train Loss: 0.0072 | Val Loss: 8.0273 | Train Acc: 99.60| Val Acc: 61.88\n",
      "Epoch 1768: | Train Loss: 0.0093 | Val Loss: 8.0027 | Train Acc: 99.18| Val Acc: 61.97\n",
      "Epoch 1769: | Train Loss: 0.0085 | Val Loss: 7.9969 | Train Acc: 99.74| Val Acc: 62.07\n",
      "Epoch 1770: | Train Loss: 0.0099 | Val Loss: 7.9066 | Train Acc: 99.02| Val Acc: 63.07\n",
      "Epoch 1771: | Train Loss: 0.0092 | Val Loss: 7.9332 | Train Acc: 99.36| Val Acc: 62.88\n",
      "Epoch 1772: | Train Loss: 0.0080 | Val Loss: 7.9901 | Train Acc: 99.33| Val Acc: 62.67\n",
      "Epoch 1773: | Train Loss: 0.0087 | Val Loss: 8.0091 | Train Acc: 99.25| Val Acc: 62.27\n",
      "Epoch 1774: | Train Loss: 0.0100 | Val Loss: 7.9474 | Train Acc: 99.36| Val Acc: 62.58\n",
      "Epoch 1775: | Train Loss: 0.0075 | Val Loss: 7.8323 | Train Acc: 99.46| Val Acc: 62.39\n",
      "Epoch 1776: | Train Loss: 0.0102 | Val Loss: 7.8450 | Train Acc: 99.04| Val Acc: 62.49\n",
      "Epoch 1777: | Train Loss: 0.0094 | Val Loss: 7.8342 | Train Acc: 99.35| Val Acc: 62.72\n",
      "Epoch 1778: | Train Loss: 0.0111 | Val Loss: 8.0746 | Train Acc: 98.97| Val Acc: 61.97\n",
      "Epoch 1779: | Train Loss: 0.0089 | Val Loss: 8.0959 | Train Acc: 99.32| Val Acc: 61.97\n",
      "Epoch 1780: | Train Loss: 0.0076 | Val Loss: 8.0414 | Train Acc: 99.28| Val Acc: 61.99\n",
      "Epoch 1781: | Train Loss: 0.0105 | Val Loss: 8.0434 | Train Acc: 99.46| Val Acc: 62.28\n",
      "Epoch 1782: | Train Loss: 0.0077 | Val Loss: 8.0872 | Train Acc: 99.21| Val Acc: 62.49\n",
      "Epoch 1783: | Train Loss: 0.0090 | Val Loss: 8.1098 | Train Acc: 99.27| Val Acc: 62.61\n",
      "Epoch 1784: | Train Loss: 0.0073 | Val Loss: 8.0670 | Train Acc: 99.49| Val Acc: 62.51\n",
      "Epoch 1785: | Train Loss: 0.0083 | Val Loss: 8.1087 | Train Acc: 99.35| Val Acc: 62.17\n",
      "Epoch 1786: | Train Loss: 0.0067 | Val Loss: 8.1669 | Train Acc: 99.44| Val Acc: 62.27\n",
      "Epoch 1787: | Train Loss: 0.0096 | Val Loss: 8.0867 | Train Acc: 99.07| Val Acc: 62.39\n",
      "Epoch 1788: | Train Loss: 0.0070 | Val Loss: 8.1182 | Train Acc: 99.57| Val Acc: 62.10\n",
      "Epoch 1789: | Train Loss: 0.0069 | Val Loss: 8.1995 | Train Acc: 99.60| Val Acc: 61.70\n",
      "Epoch 1790: | Train Loss: 0.0072 | Val Loss: 8.2266 | Train Acc: 99.48| Val Acc: 61.77\n",
      "Epoch 1791: | Train Loss: 0.0091 | Val Loss: 8.2389 | Train Acc: 99.39| Val Acc: 62.18\n",
      "Epoch 1792: | Train Loss: 0.0071 | Val Loss: 8.2326 | Train Acc: 99.42| Val Acc: 62.07\n",
      "Epoch 1793: | Train Loss: 0.0058 | Val Loss: 8.1866 | Train Acc: 99.66| Val Acc: 62.07\n",
      "Epoch 1794: | Train Loss: 0.0080 | Val Loss: 8.2338 | Train Acc: 99.47| Val Acc: 62.16\n",
      "Epoch 1795: | Train Loss: 0.1138 | Val Loss: 8.2600 | Train Acc: 98.94| Val Acc: 62.00\n",
      "Epoch 1796: | Train Loss: 0.0221 | Val Loss: 8.3106 | Train Acc: 98.43| Val Acc: 62.17\n",
      "Epoch 1797: | Train Loss: 0.0211 | Val Loss: 8.0729 | Train Acc: 98.16| Val Acc: 62.00\n",
      "Epoch 1798: | Train Loss: 0.0208 | Val Loss: 7.6433 | Train Acc: 98.39| Val Acc: 62.40\n",
      "Epoch 1799: | Train Loss: 0.0257 | Val Loss: 7.6668 | Train Acc: 98.16| Val Acc: 62.11\n",
      "Epoch 1800: | Train Loss: 0.0195 | Val Loss: 7.7997 | Train Acc: 98.37| Val Acc: 61.70\n",
      "Epoch 1801: | Train Loss: 0.0160 | Val Loss: 7.8669 | Train Acc: 98.55| Val Acc: 61.48\n",
      "Epoch 1802: | Train Loss: 0.0204 | Val Loss: 7.9765 | Train Acc: 98.58| Val Acc: 61.27\n",
      "Epoch 1803: | Train Loss: 0.0211 | Val Loss: 8.0356 | Train Acc: 98.25| Val Acc: 61.58\n",
      "Epoch 1804: | Train Loss: 0.0173 | Val Loss: 7.8917 | Train Acc: 98.61| Val Acc: 61.70\n",
      "Epoch 1805: | Train Loss: 0.0136 | Val Loss: 7.7683 | Train Acc: 98.92| Val Acc: 61.50\n",
      "Epoch 1806: | Train Loss: 0.0153 | Val Loss: 7.7637 | Train Acc: 98.62| Val Acc: 61.98\n",
      "Epoch 1807: | Train Loss: 0.0146 | Val Loss: 7.7921 | Train Acc: 98.87| Val Acc: 62.28\n",
      "Epoch 1808: | Train Loss: 0.0142 | Val Loss: 7.7534 | Train Acc: 98.80| Val Acc: 61.88\n",
      "Epoch 1809: | Train Loss: 0.0131 | Val Loss: 7.7374 | Train Acc: 98.84| Val Acc: 61.37\n",
      "Epoch 1810: | Train Loss: 0.0162 | Val Loss: 7.9688 | Train Acc: 98.90| Val Acc: 60.88\n",
      "Epoch 1811: | Train Loss: 0.0141 | Val Loss: 8.1084 | Train Acc: 98.87| Val Acc: 60.48\n",
      "Epoch 1812: | Train Loss: 0.0092 | Val Loss: 8.1412 | Train Acc: 99.34| Val Acc: 60.28\n",
      "Epoch 1813: | Train Loss: 0.0098 | Val Loss: 8.0951 | Train Acc: 99.15| Val Acc: 60.49\n",
      "Epoch 1814: | Train Loss: 0.0142 | Val Loss: 8.1237 | Train Acc: 99.05| Val Acc: 60.49\n",
      "Epoch 1815: | Train Loss: 0.0110 | Val Loss: 8.1882 | Train Acc: 98.91| Val Acc: 60.69\n",
      "Epoch 1816: | Train Loss: 0.0110 | Val Loss: 8.1712 | Train Acc: 99.19| Val Acc: 60.37\n",
      "Epoch 1817: | Train Loss: 0.0126 | Val Loss: 8.1418 | Train Acc: 99.11| Val Acc: 60.98\n",
      "Epoch 1818: | Train Loss: 0.0158 | Val Loss: 8.1837 | Train Acc: 99.03| Val Acc: 61.77\n",
      "Epoch 1819: | Train Loss: 0.0108 | Val Loss: 8.2212 | Train Acc: 99.38| Val Acc: 61.89\n",
      "Epoch 1820: | Train Loss: 0.0123 | Val Loss: 8.2499 | Train Acc: 99.40| Val Acc: 61.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1821: | Train Loss: 0.0091 | Val Loss: 8.2860 | Train Acc: 99.36| Val Acc: 60.86\n",
      "Epoch 1822: | Train Loss: 0.0117 | Val Loss: 8.1616 | Train Acc: 99.00| Val Acc: 60.75\n",
      "Epoch 1823: | Train Loss: 0.0098 | Val Loss: 8.1192 | Train Acc: 99.29| Val Acc: 61.25\n",
      "Epoch 1824: | Train Loss: 0.0122 | Val Loss: 8.1145 | Train Acc: 99.11| Val Acc: 61.08\n",
      "Epoch 1825: | Train Loss: 0.0105 | Val Loss: 8.0991 | Train Acc: 99.15| Val Acc: 61.09\n",
      "Epoch 1826: | Train Loss: 0.0071 | Val Loss: 8.0980 | Train Acc: 99.53| Val Acc: 61.07\n",
      "Epoch 1827: | Train Loss: 0.0098 | Val Loss: 8.1446 | Train Acc: 99.02| Val Acc: 61.58\n",
      "Epoch 1828: | Train Loss: 0.0093 | Val Loss: 8.1947 | Train Acc: 99.37| Val Acc: 61.08\n",
      "Epoch 1829: | Train Loss: 0.0101 | Val Loss: 8.1378 | Train Acc: 99.28| Val Acc: 61.06\n",
      "Epoch 1830: | Train Loss: 0.0083 | Val Loss: 8.1579 | Train Acc: 99.12| Val Acc: 61.67\n",
      "Epoch 1831: | Train Loss: 0.0083 | Val Loss: 8.1940 | Train Acc: 99.49| Val Acc: 61.58\n",
      "Epoch 1832: | Train Loss: 0.0084 | Val Loss: 8.1254 | Train Acc: 99.26| Val Acc: 61.37\n",
      "Epoch 1833: | Train Loss: 0.0096 | Val Loss: 8.1154 | Train Acc: 99.23| Val Acc: 61.14\n",
      "Epoch 1834: | Train Loss: 0.0079 | Val Loss: 8.1094 | Train Acc: 99.44| Val Acc: 61.15\n",
      "Epoch 1835: | Train Loss: 0.0074 | Val Loss: 8.1306 | Train Acc: 99.30| Val Acc: 61.35\n",
      "Epoch 1836: | Train Loss: 0.0083 | Val Loss: 8.2103 | Train Acc: 99.29| Val Acc: 61.37\n",
      "Epoch 1837: | Train Loss: 0.0080 | Val Loss: 8.2247 | Train Acc: 99.44| Val Acc: 61.27\n",
      "Epoch 1838: | Train Loss: 0.0086 | Val Loss: 8.2467 | Train Acc: 99.30| Val Acc: 61.47\n",
      "Epoch 1839: | Train Loss: 0.0066 | Val Loss: 8.2355 | Train Acc: 99.46| Val Acc: 61.77\n",
      "Epoch 1840: | Train Loss: 0.0063 | Val Loss: 8.1618 | Train Acc: 99.41| Val Acc: 62.00\n",
      "Epoch 1841: | Train Loss: 0.0076 | Val Loss: 8.0956 | Train Acc: 99.37| Val Acc: 61.91\n",
      "Epoch 1842: | Train Loss: 0.0074 | Val Loss: 8.1285 | Train Acc: 99.51| Val Acc: 61.88\n",
      "Epoch 1843: | Train Loss: 0.0106 | Val Loss: 8.3204 | Train Acc: 99.36| Val Acc: 62.18\n",
      "Epoch 1844: | Train Loss: 0.0087 | Val Loss: 8.3014 | Train Acc: 99.12| Val Acc: 62.28\n",
      "Epoch 1845: | Train Loss: 0.0106 | Val Loss: 8.2110 | Train Acc: 99.17| Val Acc: 62.08\n",
      "Epoch 1846: | Train Loss: 0.0086 | Val Loss: 8.0702 | Train Acc: 99.21| Val Acc: 61.90\n",
      "Epoch 1847: | Train Loss: 0.0093 | Val Loss: 7.9939 | Train Acc: 99.33| Val Acc: 62.08\n",
      "Epoch 1848: | Train Loss: 0.0092 | Val Loss: 8.0658 | Train Acc: 99.29| Val Acc: 62.39\n",
      "Epoch 1849: | Train Loss: 0.0055 | Val Loss: 8.0387 | Train Acc: 99.57| Val Acc: 61.27\n",
      "Epoch 1850: | Train Loss: 0.0072 | Val Loss: 8.0546 | Train Acc: 99.57| Val Acc: 61.26\n",
      "Epoch 1851: | Train Loss: 0.0063 | Val Loss: 8.0596 | Train Acc: 99.62| Val Acc: 61.56\n",
      "Epoch 1852: | Train Loss: 0.0070 | Val Loss: 8.0513 | Train Acc: 99.42| Val Acc: 61.38\n",
      "Epoch 1853: | Train Loss: 0.0083 | Val Loss: 8.0740 | Train Acc: 99.36| Val Acc: 61.36\n",
      "Epoch 1854: | Train Loss: 0.0070 | Val Loss: 8.0934 | Train Acc: 99.29| Val Acc: 61.58\n",
      "Epoch 1855: | Train Loss: 0.0076 | Val Loss: 8.1612 | Train Acc: 99.44| Val Acc: 62.28\n",
      "Epoch 1856: | Train Loss: 0.0059 | Val Loss: 8.1787 | Train Acc: 99.55| Val Acc: 61.89\n",
      "Epoch 1857: | Train Loss: 0.0085 | Val Loss: 8.1625 | Train Acc: 99.30| Val Acc: 61.37\n",
      "Epoch 1858: | Train Loss: 0.0071 | Val Loss: 8.3140 | Train Acc: 99.37| Val Acc: 61.38\n",
      "Epoch 1859: | Train Loss: 0.0097 | Val Loss: 8.4125 | Train Acc: 99.34| Val Acc: 61.27\n",
      "Epoch 1860: | Train Loss: 0.0095 | Val Loss: 8.4682 | Train Acc: 99.25| Val Acc: 61.30\n",
      "Epoch 1861: | Train Loss: 0.0089 | Val Loss: 8.4059 | Train Acc: 99.37| Val Acc: 61.78\n",
      "Epoch 1862: | Train Loss: 0.0052 | Val Loss: 8.2702 | Train Acc: 99.61| Val Acc: 61.48\n",
      "Epoch 1863: | Train Loss: 0.0094 | Val Loss: 8.1544 | Train Acc: 99.39| Val Acc: 61.35\n",
      "Epoch 1864: | Train Loss: 0.0058 | Val Loss: 8.1184 | Train Acc: 99.62| Val Acc: 61.57\n",
      "Epoch 1865: | Train Loss: 0.0092 | Val Loss: 8.1661 | Train Acc: 99.12| Val Acc: 62.07\n",
      "Epoch 1866: | Train Loss: 0.0071 | Val Loss: 8.2529 | Train Acc: 99.44| Val Acc: 61.88\n",
      "Epoch 1867: | Train Loss: 0.0072 | Val Loss: 8.2296 | Train Acc: 99.36| Val Acc: 61.27\n",
      "Epoch 1868: | Train Loss: 0.0089 | Val Loss: 8.2288 | Train Acc: 99.36| Val Acc: 61.48\n",
      "Epoch 1869: | Train Loss: 0.0195 | Val Loss: 8.2490 | Train Acc: 99.35| Val Acc: 61.18\n",
      "Epoch 1870: | Train Loss: 0.0083 | Val Loss: 8.3105 | Train Acc: 99.36| Val Acc: 61.60\n",
      "Epoch 1871: | Train Loss: 0.0176 | Val Loss: 8.3923 | Train Acc: 99.16| Val Acc: 61.41\n",
      "Epoch 1872: | Train Loss: 0.0183 | Val Loss: 8.0129 | Train Acc: 98.84| Val Acc: 60.70\n",
      "Epoch 1873: | Train Loss: 0.0153 | Val Loss: 7.8861 | Train Acc: 98.98| Val Acc: 61.09\n",
      "Epoch 1874: | Train Loss: 0.0174 | Val Loss: 7.8937 | Train Acc: 98.85| Val Acc: 61.48\n",
      "Epoch 1875: | Train Loss: 0.0114 | Val Loss: 8.0289 | Train Acc: 99.18| Val Acc: 62.10\n",
      "Epoch 1876: | Train Loss: 0.0103 | Val Loss: 8.0059 | Train Acc: 99.17| Val Acc: 62.39\n",
      "Epoch 1877: | Train Loss: 0.0092 | Val Loss: 7.9981 | Train Acc: 99.34| Val Acc: 62.09\n",
      "Epoch 1878: | Train Loss: 0.0094 | Val Loss: 7.9249 | Train Acc: 99.12| Val Acc: 62.30\n",
      "Epoch 1879: | Train Loss: 0.0081 | Val Loss: 7.8545 | Train Acc: 99.47| Val Acc: 62.09\n",
      "Epoch 1880: | Train Loss: 0.0089 | Val Loss: 7.9230 | Train Acc: 99.25| Val Acc: 62.39\n",
      "Epoch 1881: | Train Loss: 0.0123 | Val Loss: 8.0167 | Train Acc: 98.98| Val Acc: 61.88\n",
      "Epoch 1882: | Train Loss: 0.0093 | Val Loss: 8.0303 | Train Acc: 99.21| Val Acc: 61.91\n",
      "Epoch 1883: | Train Loss: 0.0080 | Val Loss: 8.0195 | Train Acc: 99.39| Val Acc: 61.61\n",
      "Epoch 1884: | Train Loss: 0.0067 | Val Loss: 8.0006 | Train Acc: 99.59| Val Acc: 61.19\n",
      "Epoch 1885: | Train Loss: 0.0100 | Val Loss: 8.0085 | Train Acc: 99.18| Val Acc: 61.27\n",
      "Epoch 1886: | Train Loss: 0.0087 | Val Loss: 8.0271 | Train Acc: 99.48| Val Acc: 61.58\n",
      "Epoch 1887: | Train Loss: 0.0086 | Val Loss: 8.0275 | Train Acc: 99.33| Val Acc: 61.68\n",
      "Epoch 1888: | Train Loss: 0.0081 | Val Loss: 8.1109 | Train Acc: 99.36| Val Acc: 61.28\n",
      "Epoch 1889: | Train Loss: 0.0097 | Val Loss: 8.1144 | Train Acc: 99.16| Val Acc: 61.57\n",
      "Epoch 1890: | Train Loss: 0.0070 | Val Loss: 7.9714 | Train Acc: 99.53| Val Acc: 61.76\n",
      "Epoch 1891: | Train Loss: 0.0082 | Val Loss: 7.9111 | Train Acc: 99.31| Val Acc: 61.89\n",
      "Epoch 1892: | Train Loss: 0.0065 | Val Loss: 7.8743 | Train Acc: 99.51| Val Acc: 62.39\n",
      "Epoch 1893: | Train Loss: 0.0132 | Val Loss: 7.8607 | Train Acc: 99.28| Val Acc: 62.30\n",
      "Epoch 1894: | Train Loss: 0.0085 | Val Loss: 7.9053 | Train Acc: 99.14| Val Acc: 61.89\n",
      "Epoch 1895: | Train Loss: 0.0094 | Val Loss: 7.9216 | Train Acc: 99.42| Val Acc: 61.89\n",
      "Epoch 1896: | Train Loss: 0.0076 | Val Loss: 7.9019 | Train Acc: 99.51| Val Acc: 62.39\n",
      "Epoch 1897: | Train Loss: 0.0078 | Val Loss: 7.9158 | Train Acc: 99.47| Val Acc: 62.21\n",
      "Epoch 1898: | Train Loss: 0.0090 | Val Loss: 7.9391 | Train Acc: 99.38| Val Acc: 61.91\n",
      "Epoch 1899: | Train Loss: 0.0080 | Val Loss: 7.9327 | Train Acc: 99.34| Val Acc: 61.88\n",
      "Epoch 1900: | Train Loss: 0.0118 | Val Loss: 7.9792 | Train Acc: 99.16| Val Acc: 62.50\n",
      "Epoch 1901: | Train Loss: 0.0082 | Val Loss: 8.0669 | Train Acc: 99.40| Val Acc: 62.09\n",
      "Epoch 1902: | Train Loss: 0.0093 | Val Loss: 8.1088 | Train Acc: 99.24| Val Acc: 61.71\n",
      "Epoch 1903: | Train Loss: 0.0068 | Val Loss: 8.1605 | Train Acc: 99.24| Val Acc: 61.60\n",
      "Epoch 1904: | Train Loss: 0.0126 | Val Loss: 8.2048 | Train Acc: 99.08| Val Acc: 61.69\n",
      "Epoch 1905: | Train Loss: 0.0076 | Val Loss: 8.1579 | Train Acc: 99.35| Val Acc: 61.57\n",
      "Epoch 1906: | Train Loss: 0.0081 | Val Loss: 8.1393 | Train Acc: 99.54| Val Acc: 61.88\n",
      "Epoch 1907: | Train Loss: 0.0075 | Val Loss: 8.0425 | Train Acc: 99.37| Val Acc: 62.39\n",
      "Epoch 1908: | Train Loss: 0.0072 | Val Loss: 8.0465 | Train Acc: 99.35| Val Acc: 62.19\n",
      "Epoch 1909: | Train Loss: 0.0070 | Val Loss: 8.0872 | Train Acc: 99.50| Val Acc: 61.98\n",
      "Epoch 1910: | Train Loss: 0.0067 | Val Loss: 8.1371 | Train Acc: 99.33| Val Acc: 61.99\n",
      "Epoch 1911: | Train Loss: 0.0055 | Val Loss: 8.1666 | Train Acc: 99.66| Val Acc: 62.00\n",
      "Epoch 1912: | Train Loss: 0.0062 | Val Loss: 8.1269 | Train Acc: 99.50| Val Acc: 62.09\n",
      "Epoch 1913: | Train Loss: 0.0069 | Val Loss: 8.1597 | Train Acc: 99.37| Val Acc: 62.29\n",
      "Epoch 1914: | Train Loss: 0.0073 | Val Loss: 8.1304 | Train Acc: 99.53| Val Acc: 62.60\n",
      "Epoch 1915: | Train Loss: 0.0069 | Val Loss: 8.1333 | Train Acc: 99.42| Val Acc: 62.40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1916: | Train Loss: 0.0091 | Val Loss: 8.0584 | Train Acc: 99.34| Val Acc: 62.40\n",
      "Epoch 1917: | Train Loss: 0.0107 | Val Loss: 7.9449 | Train Acc: 99.28| Val Acc: 62.00\n",
      "Epoch 1918: | Train Loss: 0.0085 | Val Loss: 7.8627 | Train Acc: 99.44| Val Acc: 62.32\n",
      "Epoch 1919: | Train Loss: 0.0065 | Val Loss: 7.8345 | Train Acc: 99.46| Val Acc: 62.32\n",
      "Epoch 1920: | Train Loss: 0.0092 | Val Loss: 7.8254 | Train Acc: 99.40| Val Acc: 62.11\n",
      "Epoch 1921: | Train Loss: 0.0091 | Val Loss: 7.8484 | Train Acc: 99.20| Val Acc: 61.81\n",
      "Epoch 1922: | Train Loss: 0.0063 | Val Loss: 7.8779 | Train Acc: 99.52| Val Acc: 61.89\n",
      "Epoch 1923: | Train Loss: 0.0064 | Val Loss: 7.8894 | Train Acc: 99.37| Val Acc: 61.51\n",
      "Epoch 1924: | Train Loss: 0.0084 | Val Loss: 7.9251 | Train Acc: 99.23| Val Acc: 61.81\n",
      "Epoch 1925: | Train Loss: 0.0072 | Val Loss: 8.2041 | Train Acc: 99.39| Val Acc: 61.29\n",
      "Epoch 1926: | Train Loss: 0.0065 | Val Loss: 8.2861 | Train Acc: 99.58| Val Acc: 61.89\n",
      "Epoch 1927: | Train Loss: 0.0081 | Val Loss: 8.2318 | Train Acc: 99.23| Val Acc: 62.49\n",
      "Epoch 1928: | Train Loss: 0.0102 | Val Loss: 8.2616 | Train Acc: 99.27| Val Acc: 63.11\n",
      "Epoch 1929: | Train Loss: 0.0074 | Val Loss: 8.1912 | Train Acc: 99.48| Val Acc: 62.40\n",
      "Epoch 1930: | Train Loss: 0.0059 | Val Loss: 8.1555 | Train Acc: 99.49| Val Acc: 62.20\n",
      "Epoch 1931: | Train Loss: 0.0084 | Val Loss: 8.1731 | Train Acc: 99.45| Val Acc: 62.39\n",
      "Epoch 1932: | Train Loss: 0.0070 | Val Loss: 8.2081 | Train Acc: 99.30| Val Acc: 62.38\n",
      "Epoch 1933: | Train Loss: 0.0080 | Val Loss: 8.2252 | Train Acc: 99.42| Val Acc: 62.60\n",
      "Epoch 1934: | Train Loss: 0.0081 | Val Loss: 8.2014 | Train Acc: 99.52| Val Acc: 61.99\n",
      "Epoch 1935: | Train Loss: 0.0075 | Val Loss: 8.1576 | Train Acc: 99.31| Val Acc: 62.38\n",
      "Epoch 1936: | Train Loss: 0.0059 | Val Loss: 8.0803 | Train Acc: 99.60| Val Acc: 62.61\n",
      "Epoch 1937: | Train Loss: 0.0077 | Val Loss: 8.1233 | Train Acc: 99.34| Val Acc: 62.39\n",
      "Epoch 1938: | Train Loss: 0.0072 | Val Loss: 8.1269 | Train Acc: 99.44| Val Acc: 62.39\n",
      "Epoch 1939: | Train Loss: 0.0066 | Val Loss: 8.1431 | Train Acc: 99.60| Val Acc: 62.79\n",
      "Epoch 1940: | Train Loss: 0.0072 | Val Loss: 8.1846 | Train Acc: 99.48| Val Acc: 62.48\n",
      "Epoch 1941: | Train Loss: 0.0068 | Val Loss: 8.1821 | Train Acc: 99.36| Val Acc: 63.30\n",
      "Epoch 1942: | Train Loss: 0.0095 | Val Loss: 8.2168 | Train Acc: 99.48| Val Acc: 62.79\n",
      "Epoch 1943: | Train Loss: 0.0081 | Val Loss: 8.1711 | Train Acc: 99.42| Val Acc: 62.48\n",
      "Epoch 1944: | Train Loss: 0.0085 | Val Loss: 8.1303 | Train Acc: 99.31| Val Acc: 62.30\n",
      "Epoch 1945: | Train Loss: 0.0060 | Val Loss: 8.1597 | Train Acc: 99.60| Val Acc: 61.89\n",
      "Epoch 1946: | Train Loss: 0.0075 | Val Loss: 8.0909 | Train Acc: 99.37| Val Acc: 61.58\n",
      "Epoch 1947: | Train Loss: 0.0080 | Val Loss: 8.0862 | Train Acc: 99.25| Val Acc: 62.00\n",
      "Epoch 1948: | Train Loss: 0.0084 | Val Loss: 8.1905 | Train Acc: 99.57| Val Acc: 62.18\n",
      "Epoch 1949: | Train Loss: 0.0070 | Val Loss: 8.2643 | Train Acc: 99.44| Val Acc: 62.17\n",
      "Epoch 1950: | Train Loss: 0.0061 | Val Loss: 8.3135 | Train Acc: 99.57| Val Acc: 62.18\n",
      "Epoch 1951: | Train Loss: 0.0079 | Val Loss: 8.2129 | Train Acc: 99.57| Val Acc: 62.38\n",
      "Epoch 1952: | Train Loss: 0.0083 | Val Loss: 8.1118 | Train Acc: 99.42| Val Acc: 62.29\n",
      "Epoch 1953: | Train Loss: 0.0064 | Val Loss: 8.0886 | Train Acc: 99.39| Val Acc: 62.07\n",
      "Epoch 1954: | Train Loss: 0.0083 | Val Loss: 8.1804 | Train Acc: 99.27| Val Acc: 62.39\n",
      "Epoch 1955: | Train Loss: 0.0063 | Val Loss: 8.2139 | Train Acc: 99.46| Val Acc: 61.99\n",
      "Epoch 1956: | Train Loss: 0.0065 | Val Loss: 8.2386 | Train Acc: 99.60| Val Acc: 61.66\n",
      "Epoch 1957: | Train Loss: 0.0111 | Val Loss: 8.0581 | Train Acc: 99.25| Val Acc: 61.56\n",
      "Epoch 1958: | Train Loss: 0.0075 | Val Loss: 8.0020 | Train Acc: 99.42| Val Acc: 61.75\n",
      "Epoch 1959: | Train Loss: 0.0068 | Val Loss: 8.0331 | Train Acc: 99.50| Val Acc: 61.97\n",
      "Epoch 1960: | Train Loss: 0.0057 | Val Loss: 8.1482 | Train Acc: 99.54| Val Acc: 61.76\n",
      "Epoch 1961: | Train Loss: 0.0073 | Val Loss: 8.2206 | Train Acc: 99.49| Val Acc: 61.95\n",
      "Epoch 1962: | Train Loss: 0.0062 | Val Loss: 8.2180 | Train Acc: 99.66| Val Acc: 61.78\n",
      "Epoch 1963: | Train Loss: 0.0077 | Val Loss: 8.1910 | Train Acc: 99.41| Val Acc: 61.58\n",
      "Epoch 1964: | Train Loss: 0.0056 | Val Loss: 8.1815 | Train Acc: 99.71| Val Acc: 61.47\n",
      "Epoch 1965: | Train Loss: 0.0073 | Val Loss: 8.2436 | Train Acc: 99.31| Val Acc: 61.78\n",
      "Epoch 1966: | Train Loss: 0.0067 | Val Loss: 8.2289 | Train Acc: 99.34| Val Acc: 62.28\n",
      "Epoch 1967: | Train Loss: 0.0057 | Val Loss: 8.2718 | Train Acc: 99.58| Val Acc: 62.17\n",
      "Epoch 1968: | Train Loss: 0.0073 | Val Loss: 8.2467 | Train Acc: 99.31| Val Acc: 62.17\n",
      "Epoch 1969: | Train Loss: 0.0072 | Val Loss: 8.2275 | Train Acc: 99.37| Val Acc: 61.87\n",
      "Epoch 1970: | Train Loss: 0.0112 | Val Loss: 8.1982 | Train Acc: 99.28| Val Acc: 62.37\n",
      "Epoch 1971: | Train Loss: 0.0072 | Val Loss: 8.1708 | Train Acc: 99.55| Val Acc: 62.27\n",
      "Epoch 1972: | Train Loss: 0.0075 | Val Loss: 8.1960 | Train Acc: 99.44| Val Acc: 62.49\n",
      "Epoch 1973: | Train Loss: 0.0092 | Val Loss: 8.3032 | Train Acc: 99.11| Val Acc: 62.28\n",
      "Epoch 1974: | Train Loss: 0.0093 | Val Loss: 8.3069 | Train Acc: 99.24| Val Acc: 62.18\n",
      "Epoch 1975: | Train Loss: 0.0081 | Val Loss: 8.3205 | Train Acc: 99.48| Val Acc: 62.28\n",
      "Epoch 1976: | Train Loss: 0.0061 | Val Loss: 8.3108 | Train Acc: 99.51| Val Acc: 62.27\n",
      "Epoch 1977: | Train Loss: 0.0084 | Val Loss: 8.3316 | Train Acc: 99.24| Val Acc: 61.97\n",
      "Epoch 1978: | Train Loss: 0.0083 | Val Loss: 8.3533 | Train Acc: 99.25| Val Acc: 61.96\n",
      "Epoch 1979: | Train Loss: 0.0059 | Val Loss: 8.3785 | Train Acc: 99.48| Val Acc: 62.27\n",
      "Epoch 1980: | Train Loss: 0.0078 | Val Loss: 8.3364 | Train Acc: 99.50| Val Acc: 62.06\n",
      "Epoch 1981: | Train Loss: 0.0074 | Val Loss: 8.3205 | Train Acc: 99.39| Val Acc: 62.47\n",
      "Epoch 1982: | Train Loss: 0.0075 | Val Loss: 8.2780 | Train Acc: 99.37| Val Acc: 62.39\n",
      "Epoch 1983: | Train Loss: 0.0090 | Val Loss: 8.3294 | Train Acc: 99.13| Val Acc: 62.97\n",
      "Epoch 1984: | Train Loss: 0.0075 | Val Loss: 8.2985 | Train Acc: 99.39| Val Acc: 62.98\n",
      "Epoch 1985: | Train Loss: 0.0065 | Val Loss: 8.2029 | Train Acc: 99.59| Val Acc: 62.99\n",
      "Epoch 1986: | Train Loss: 0.0071 | Val Loss: 8.1766 | Train Acc: 99.47| Val Acc: 62.99\n",
      "Epoch 1987: | Train Loss: 0.0084 | Val Loss: 8.2094 | Train Acc: 99.37| Val Acc: 62.78\n",
      "Epoch 1988: | Train Loss: 0.0056 | Val Loss: 8.2911 | Train Acc: 99.66| Val Acc: 62.29\n",
      "Epoch 1989: | Train Loss: 0.0073 | Val Loss: 8.3510 | Train Acc: 99.42| Val Acc: 62.48\n",
      "Epoch 1990: | Train Loss: 0.0063 | Val Loss: 8.3367 | Train Acc: 99.47| Val Acc: 62.48\n",
      "Epoch 1991: | Train Loss: 0.0062 | Val Loss: 8.2717 | Train Acc: 99.49| Val Acc: 62.28\n",
      "Epoch 1992: | Train Loss: 0.0061 | Val Loss: 8.1729 | Train Acc: 99.49| Val Acc: 62.18\n",
      "Epoch 1993: | Train Loss: 0.0038 | Val Loss: 8.1759 | Train Acc: 99.84| Val Acc: 62.39\n",
      "Epoch 1994: | Train Loss: 0.0052 | Val Loss: 8.2093 | Train Acc: 99.60| Val Acc: 62.43\n",
      "Epoch 1995: | Train Loss: 0.0068 | Val Loss: 8.2162 | Train Acc: 99.60| Val Acc: 62.80\n",
      "Epoch 1996: | Train Loss: 0.0064 | Val Loss: 8.2778 | Train Acc: 99.48| Val Acc: 62.31\n",
      "Epoch 1997: | Train Loss: 0.0072 | Val Loss: 8.3077 | Train Acc: 99.50| Val Acc: 62.31\n",
      "Epoch 1998: | Train Loss: 0.0059 | Val Loss: 8.3184 | Train Acc: 99.53| Val Acc: 62.61\n",
      "Epoch 1999: | Train Loss: 0.0065 | Val Loss: 8.3533 | Train Acc: 99.37| Val Acc: 62.39\n",
      "Epoch 2000: | Train Loss: 0.0109 | Val Loss: 8.3583 | Train Acc: 99.62| Val Acc: 62.17\n",
      "Epoch 2001: | Train Loss: 0.0070 | Val Loss: 8.4451 | Train Acc: 99.37| Val Acc: 61.56\n",
      "Epoch 2002: | Train Loss: 0.0066 | Val Loss: 8.4508 | Train Acc: 99.48| Val Acc: 61.77\n",
      "Epoch 2003: | Train Loss: 0.0077 | Val Loss: 8.4122 | Train Acc: 99.51| Val Acc: 61.88\n",
      "Epoch 2004: | Train Loss: 0.0076 | Val Loss: 8.3150 | Train Acc: 99.49| Val Acc: 61.47\n",
      "Epoch 2005: | Train Loss: 0.0073 | Val Loss: 8.2697 | Train Acc: 99.61| Val Acc: 61.47\n",
      "Epoch 2006: | Train Loss: 0.0074 | Val Loss: 8.2725 | Train Acc: 99.35| Val Acc: 61.59\n",
      "Epoch 2007: | Train Loss: 0.0055 | Val Loss: 8.2861 | Train Acc: 99.57| Val Acc: 61.18\n",
      "Epoch 2008: | Train Loss: 0.0059 | Val Loss: 8.2909 | Train Acc: 99.55| Val Acc: 61.19\n",
      "Epoch 2009: | Train Loss: 0.0067 | Val Loss: 8.2592 | Train Acc: 99.46| Val Acc: 61.50\n",
      "Epoch 2010: | Train Loss: 0.0076 | Val Loss: 8.2090 | Train Acc: 99.42| Val Acc: 61.71\n",
      "Epoch 2011: | Train Loss: 0.0067 | Val Loss: 8.1867 | Train Acc: 99.54| Val Acc: 61.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2012: | Train Loss: 0.0058 | Val Loss: 8.2018 | Train Acc: 99.50| Val Acc: 61.67\n",
      "Epoch 2013: | Train Loss: 0.0075 | Val Loss: 8.2732 | Train Acc: 99.22| Val Acc: 61.27\n",
      "Epoch 2014: | Train Loss: 0.0058 | Val Loss: 8.3105 | Train Acc: 99.67| Val Acc: 61.28\n",
      "Epoch 2015: | Train Loss: 0.0050 | Val Loss: 8.3728 | Train Acc: 99.61| Val Acc: 61.39\n",
      "Epoch 2016: | Train Loss: 0.0091 | Val Loss: 8.4099 | Train Acc: 99.23| Val Acc: 61.60\n",
      "Epoch 2017: | Train Loss: 0.0077 | Val Loss: 8.3980 | Train Acc: 99.50| Val Acc: 61.38\n",
      "Epoch 2018: | Train Loss: 0.0067 | Val Loss: 8.3203 | Train Acc: 99.57| Val Acc: 61.58\n",
      "Epoch 2019: | Train Loss: 0.0051 | Val Loss: 8.3535 | Train Acc: 99.64| Val Acc: 61.58\n",
      "Epoch 2020: | Train Loss: 0.0061 | Val Loss: 8.3702 | Train Acc: 99.50| Val Acc: 61.76\n",
      "Epoch 2021: | Train Loss: 0.0068 | Val Loss: 8.4274 | Train Acc: 99.34| Val Acc: 62.08\n",
      "Epoch 2022: | Train Loss: 0.0078 | Val Loss: 8.4463 | Train Acc: 99.47| Val Acc: 62.09\n",
      "Epoch 2023: | Train Loss: 0.0064 | Val Loss: 8.4172 | Train Acc: 99.51| Val Acc: 62.30\n",
      "Epoch 2024: | Train Loss: 0.0055 | Val Loss: 8.4407 | Train Acc: 99.63| Val Acc: 62.60\n",
      "Epoch 2025: | Train Loss: 0.0053 | Val Loss: 8.4843 | Train Acc: 99.64| Val Acc: 62.48\n",
      "Epoch 2026: | Train Loss: 0.0080 | Val Loss: 8.4477 | Train Acc: 99.23| Val Acc: 62.28\n",
      "Epoch 2027: | Train Loss: 0.0074 | Val Loss: 8.3799 | Train Acc: 99.38| Val Acc: 61.90\n",
      "Epoch 2028: | Train Loss: 0.0057 | Val Loss: 8.4146 | Train Acc: 99.67| Val Acc: 61.80\n",
      "Epoch 2029: | Train Loss: 0.0059 | Val Loss: 8.4198 | Train Acc: 99.43| Val Acc: 61.67\n",
      "Epoch 2030: | Train Loss: 0.0065 | Val Loss: 8.4153 | Train Acc: 99.47| Val Acc: 62.00\n",
      "Epoch 2031: | Train Loss: 0.0074 | Val Loss: 8.4886 | Train Acc: 99.44| Val Acc: 61.99\n",
      "Epoch 2032: | Train Loss: 0.0064 | Val Loss: 8.5590 | Train Acc: 99.45| Val Acc: 61.80\n",
      "Epoch 2033: | Train Loss: 0.0061 | Val Loss: 8.5586 | Train Acc: 99.41| Val Acc: 61.80\n",
      "Epoch 2034: | Train Loss: 0.0050 | Val Loss: 8.6051 | Train Acc: 99.72| Val Acc: 62.20\n",
      "Epoch 2035: | Train Loss: 0.0069 | Val Loss: 8.5933 | Train Acc: 99.66| Val Acc: 61.89\n",
      "Epoch 2036: | Train Loss: 0.0065 | Val Loss: 8.5828 | Train Acc: 99.58| Val Acc: 61.68\n",
      "Epoch 2037: | Train Loss: 0.0059 | Val Loss: 8.5641 | Train Acc: 99.45| Val Acc: 62.31\n",
      "Epoch 2038: | Train Loss: 0.0045 | Val Loss: 8.5282 | Train Acc: 99.71| Val Acc: 62.32\n",
      "Epoch 2039: | Train Loss: 0.0066 | Val Loss: 8.4491 | Train Acc: 99.54| Val Acc: 62.02\n",
      "Epoch 2040: | Train Loss: 0.0053 | Val Loss: 8.4289 | Train Acc: 99.70| Val Acc: 61.92\n",
      "Epoch 2041: | Train Loss: 0.0066 | Val Loss: 8.5064 | Train Acc: 99.40| Val Acc: 61.92\n",
      "Epoch 2042: | Train Loss: 0.0057 | Val Loss: 8.5855 | Train Acc: 99.57| Val Acc: 61.70\n",
      "Epoch 2043: | Train Loss: 0.0067 | Val Loss: 8.6444 | Train Acc: 99.57| Val Acc: 62.00\n",
      "Epoch 2044: | Train Loss: 0.0053 | Val Loss: 8.6628 | Train Acc: 99.53| Val Acc: 62.60\n",
      "Epoch 2045: | Train Loss: 0.0055 | Val Loss: 8.5888 | Train Acc: 99.51| Val Acc: 62.50\n",
      "Epoch 2046: | Train Loss: 0.0056 | Val Loss: 8.5552 | Train Acc: 99.61| Val Acc: 62.52\n",
      "Epoch 2047: | Train Loss: 0.0070 | Val Loss: 8.4719 | Train Acc: 99.28| Val Acc: 62.90\n",
      "Epoch 2048: | Train Loss: 0.0082 | Val Loss: 8.3840 | Train Acc: 99.36| Val Acc: 62.58\n",
      "Epoch 2049: | Train Loss: 0.0059 | Val Loss: 8.2394 | Train Acc: 99.62| Val Acc: 61.76\n",
      "Epoch 2050: | Train Loss: 0.0060 | Val Loss: 8.2217 | Train Acc: 99.51| Val Acc: 61.35\n",
      "Epoch 2051: | Train Loss: 0.0073 | Val Loss: 8.3642 | Train Acc: 99.47| Val Acc: 61.26\n",
      "Epoch 2052: | Train Loss: 0.0060 | Val Loss: 8.4497 | Train Acc: 99.58| Val Acc: 61.37\n",
      "Epoch 2053: | Train Loss: 0.0077 | Val Loss: 8.4512 | Train Acc: 99.57| Val Acc: 61.48\n",
      "Epoch 2054: | Train Loss: 0.0408 | Val Loss: 8.5048 | Train Acc: 99.37| Val Acc: 62.08\n",
      "Epoch 2055: | Train Loss: 0.0093 | Val Loss: 8.3996 | Train Acc: 99.20| Val Acc: 62.19\n",
      "Epoch 2056: | Train Loss: 0.0122 | Val Loss: 8.3364 | Train Acc: 99.05| Val Acc: 62.40\n",
      "Epoch 2057: | Train Loss: 0.0142 | Val Loss: 8.2093 | Train Acc: 99.28| Val Acc: 62.40\n",
      "Epoch 2058: | Train Loss: 0.0106 | Val Loss: 8.1199 | Train Acc: 99.06| Val Acc: 62.48\n",
      "Epoch 2059: | Train Loss: 0.0097 | Val Loss: 8.0580 | Train Acc: 99.37| Val Acc: 62.15\n",
      "Epoch 2060: | Train Loss: 0.0103 | Val Loss: 8.0516 | Train Acc: 99.09| Val Acc: 61.72\n",
      "Epoch 2061: | Train Loss: 0.0069 | Val Loss: 7.9501 | Train Acc: 99.62| Val Acc: 61.81\n",
      "Epoch 2062: | Train Loss: 0.0097 | Val Loss: 7.8719 | Train Acc: 99.24| Val Acc: 62.14\n",
      "Epoch 2063: | Train Loss: 0.0127 | Val Loss: 7.9616 | Train Acc: 99.26| Val Acc: 61.63\n",
      "Epoch 2064: | Train Loss: 0.0100 | Val Loss: 8.0407 | Train Acc: 99.21| Val Acc: 61.93\n",
      "Epoch 2065: | Train Loss: 0.0090 | Val Loss: 8.1428 | Train Acc: 99.35| Val Acc: 61.52\n",
      "Epoch 2066: | Train Loss: 0.0107 | Val Loss: 8.0622 | Train Acc: 99.23| Val Acc: 61.32\n",
      "Epoch 2067: | Train Loss: 0.0068 | Val Loss: 8.0639 | Train Acc: 99.55| Val Acc: 61.50\n",
      "Epoch 2068: | Train Loss: 0.0065 | Val Loss: 8.0685 | Train Acc: 99.54| Val Acc: 62.13\n",
      "Epoch 2069: | Train Loss: 0.0098 | Val Loss: 7.9950 | Train Acc: 99.31| Val Acc: 62.54\n",
      "Epoch 2070: | Train Loss: 0.0081 | Val Loss: 7.7706 | Train Acc: 99.50| Val Acc: 62.78\n",
      "Epoch 2071: | Train Loss: 0.0101 | Val Loss: 7.7306 | Train Acc: 98.99| Val Acc: 62.57\n",
      "Epoch 2072: | Train Loss: 0.0072 | Val Loss: 7.7755 | Train Acc: 99.39| Val Acc: 62.30\n",
      "Epoch 2073: | Train Loss: 0.0069 | Val Loss: 7.8178 | Train Acc: 99.47| Val Acc: 62.27\n",
      "Epoch 2074: | Train Loss: 0.0102 | Val Loss: 7.9107 | Train Acc: 99.12| Val Acc: 62.07\n",
      "Epoch 2075: | Train Loss: 0.0072 | Val Loss: 8.0985 | Train Acc: 99.45| Val Acc: 61.35\n",
      "Epoch 2076: | Train Loss: 0.0067 | Val Loss: 8.1353 | Train Acc: 99.44| Val Acc: 62.00\n",
      "Epoch 2077: | Train Loss: 0.0066 | Val Loss: 8.0931 | Train Acc: 99.41| Val Acc: 61.89\n",
      "Epoch 2078: | Train Loss: 0.0057 | Val Loss: 8.0591 | Train Acc: 99.66| Val Acc: 62.08\n",
      "Epoch 2079: | Train Loss: 0.0084 | Val Loss: 8.0808 | Train Acc: 99.07| Val Acc: 62.29\n",
      "Epoch 2080: | Train Loss: 0.0065 | Val Loss: 8.1382 | Train Acc: 99.40| Val Acc: 62.08\n",
      "Epoch 2081: | Train Loss: 0.0103 | Val Loss: 8.1413 | Train Acc: 99.41| Val Acc: 62.17\n",
      "Epoch 2082: | Train Loss: 0.0051 | Val Loss: 8.1400 | Train Acc: 99.66| Val Acc: 62.48\n",
      "Epoch 2083: | Train Loss: 0.0059 | Val Loss: 8.1129 | Train Acc: 99.57| Val Acc: 62.29\n",
      "Epoch 2084: | Train Loss: 0.0054 | Val Loss: 8.1043 | Train Acc: 99.62| Val Acc: 62.58\n",
      "Epoch 2085: | Train Loss: 0.0060 | Val Loss: 8.0630 | Train Acc: 99.57| Val Acc: 61.57\n",
      "Epoch 2086: | Train Loss: 0.0077 | Val Loss: 8.0327 | Train Acc: 99.30| Val Acc: 61.57\n",
      "Epoch 2087: | Train Loss: 0.0058 | Val Loss: 8.0304 | Train Acc: 99.53| Val Acc: 61.64\n",
      "Epoch 2088: | Train Loss: 0.0108 | Val Loss: 8.0229 | Train Acc: 99.46| Val Acc: 62.07\n",
      "Epoch 2089: | Train Loss: 0.0074 | Val Loss: 8.0576 | Train Acc: 99.37| Val Acc: 61.77\n",
      "Epoch 2090: | Train Loss: 0.0074 | Val Loss: 8.1857 | Train Acc: 99.54| Val Acc: 61.99\n",
      "Epoch 2091: | Train Loss: 0.0099 | Val Loss: 8.2869 | Train Acc: 99.15| Val Acc: 61.98\n",
      "Epoch 2092: | Train Loss: 0.0071 | Val Loss: 8.3464 | Train Acc: 99.55| Val Acc: 61.67\n",
      "Epoch 2093: | Train Loss: 0.0071 | Val Loss: 8.3105 | Train Acc: 99.54| Val Acc: 62.20\n",
      "Epoch 2094: | Train Loss: 0.0085 | Val Loss: 8.2892 | Train Acc: 99.25| Val Acc: 61.68\n",
      "Epoch 2095: | Train Loss: 0.0071 | Val Loss: 8.2711 | Train Acc: 99.44| Val Acc: 61.88\n",
      "Epoch 2096: | Train Loss: 0.0074 | Val Loss: 8.1643 | Train Acc: 99.45| Val Acc: 62.19\n",
      "Epoch 2097: | Train Loss: 0.0052 | Val Loss: 8.1380 | Train Acc: 99.67| Val Acc: 62.60\n",
      "Epoch 2098: | Train Loss: 0.0081 | Val Loss: 8.1180 | Train Acc: 99.38| Val Acc: 62.39\n",
      "Epoch 2099: | Train Loss: 0.0075 | Val Loss: 8.1863 | Train Acc: 99.37| Val Acc: 62.37\n",
      "Epoch 2100: | Train Loss: 0.0055 | Val Loss: 8.2135 | Train Acc: 99.58| Val Acc: 62.27\n",
      "Epoch 2101: | Train Loss: 0.0118 | Val Loss: 8.3846 | Train Acc: 99.53| Val Acc: 62.28\n",
      "Epoch 2102: | Train Loss: 0.0083 | Val Loss: 8.4815 | Train Acc: 99.19| Val Acc: 62.21\n",
      "Epoch 2103: | Train Loss: 0.0088 | Val Loss: 8.2631 | Train Acc: 99.30| Val Acc: 62.10\n",
      "Epoch 2104: | Train Loss: 0.0073 | Val Loss: 8.2469 | Train Acc: 99.50| Val Acc: 61.71\n",
      "Epoch 2105: | Train Loss: 0.0064 | Val Loss: 8.3656 | Train Acc: 99.49| Val Acc: 61.98\n",
      "Epoch 2106: | Train Loss: 0.0077 | Val Loss: 8.4314 | Train Acc: 99.36| Val Acc: 61.78\n",
      "Epoch 2107: | Train Loss: 0.0077 | Val Loss: 8.3674 | Train Acc: 99.42| Val Acc: 62.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2108: | Train Loss: 0.0064 | Val Loss: 8.3441 | Train Acc: 99.44| Val Acc: 61.81\n",
      "Epoch 2109: | Train Loss: 0.0058 | Val Loss: 8.2748 | Train Acc: 99.70| Val Acc: 62.10\n",
      "Epoch 2110: | Train Loss: 0.0059 | Val Loss: 8.2057 | Train Acc: 99.70| Val Acc: 62.19\n",
      "Epoch 2111: | Train Loss: 0.0068 | Val Loss: 8.1739 | Train Acc: 99.63| Val Acc: 61.98\n",
      "Epoch 2112: | Train Loss: 0.0064 | Val Loss: 8.1890 | Train Acc: 99.53| Val Acc: 61.97\n",
      "Epoch 2113: | Train Loss: 0.0068 | Val Loss: 8.1686 | Train Acc: 99.41| Val Acc: 61.68\n",
      "Epoch 2114: | Train Loss: 0.0047 | Val Loss: 8.1194 | Train Acc: 99.70| Val Acc: 61.70\n",
      "Epoch 2115: | Train Loss: 0.0061 | Val Loss: 8.1393 | Train Acc: 99.46| Val Acc: 61.50\n",
      "Epoch 2116: | Train Loss: 0.0066 | Val Loss: 8.1814 | Train Acc: 99.60| Val Acc: 61.48\n",
      "Epoch 2117: | Train Loss: 0.0067 | Val Loss: 8.2016 | Train Acc: 99.42| Val Acc: 61.58\n",
      "Epoch 2118: | Train Loss: 0.0070 | Val Loss: 8.2505 | Train Acc: 99.37| Val Acc: 61.27\n",
      "Epoch 2119: | Train Loss: 0.0052 | Val Loss: 8.2776 | Train Acc: 99.67| Val Acc: 61.18\n",
      "Epoch 2120: | Train Loss: 0.0069 | Val Loss: 8.3503 | Train Acc: 99.47| Val Acc: 61.28\n",
      "Epoch 2121: | Train Loss: 0.0063 | Val Loss: 8.4217 | Train Acc: 99.53| Val Acc: 61.39\n",
      "Epoch 2122: | Train Loss: 0.0046 | Val Loss: 8.3954 | Train Acc: 99.74| Val Acc: 61.68\n",
      "Epoch 2123: | Train Loss: 0.0082 | Val Loss: 8.4009 | Train Acc: 99.32| Val Acc: 61.38\n",
      "Epoch 2124: | Train Loss: 0.0061 | Val Loss: 8.2732 | Train Acc: 99.53| Val Acc: 61.69\n",
      "Epoch 2125: | Train Loss: 0.0057 | Val Loss: 8.1860 | Train Acc: 99.39| Val Acc: 61.81\n",
      "Epoch 2126: | Train Loss: 0.0076 | Val Loss: 8.1693 | Train Acc: 99.61| Val Acc: 61.91\n",
      "Epoch 2127: | Train Loss: 0.0074 | Val Loss: 8.2190 | Train Acc: 99.48| Val Acc: 61.70\n",
      "Epoch 2128: | Train Loss: 0.0061 | Val Loss: 8.2965 | Train Acc: 99.60| Val Acc: 61.91\n",
      "Epoch 2129: | Train Loss: 0.0081 | Val Loss: 8.3224 | Train Acc: 99.36| Val Acc: 62.21\n",
      "Epoch 2130: | Train Loss: 0.0056 | Val Loss: 8.3323 | Train Acc: 99.53| Val Acc: 62.19\n",
      "Epoch 2131: | Train Loss: 0.0057 | Val Loss: 8.3550 | Train Acc: 99.59| Val Acc: 62.09\n",
      "Epoch 2132: | Train Loss: 0.0054 | Val Loss: 8.3549 | Train Acc: 99.73| Val Acc: 61.99\n",
      "Epoch 2133: | Train Loss: 0.0053 | Val Loss: 8.3379 | Train Acc: 99.65| Val Acc: 61.99\n",
      "Epoch 2134: | Train Loss: 0.0070 | Val Loss: 8.3543 | Train Acc: 99.47| Val Acc: 62.19\n",
      "Epoch 2135: | Train Loss: 0.0062 | Val Loss: 8.3232 | Train Acc: 99.46| Val Acc: 61.89\n",
      "Epoch 2136: | Train Loss: 0.0048 | Val Loss: 8.2766 | Train Acc: 99.67| Val Acc: 61.90\n",
      "Epoch 2137: | Train Loss: 0.0076 | Val Loss: 8.2805 | Train Acc: 99.42| Val Acc: 61.90\n",
      "Epoch 2138: | Train Loss: 0.0047 | Val Loss: 8.3255 | Train Acc: 99.71| Val Acc: 61.49\n",
      "Epoch 2139: | Train Loss: 0.0051 | Val Loss: 8.2881 | Train Acc: 99.54| Val Acc: 61.49\n",
      "Epoch 2140: | Train Loss: 0.0072 | Val Loss: 8.2602 | Train Acc: 99.41| Val Acc: 61.39\n",
      "Epoch 2141: | Train Loss: 0.0069 | Val Loss: 8.1950 | Train Acc: 99.52| Val Acc: 61.68\n",
      "Epoch 2142: | Train Loss: 0.0068 | Val Loss: 8.1811 | Train Acc: 99.36| Val Acc: 61.99\n",
      "Epoch 2143: | Train Loss: 0.0058 | Val Loss: 8.1857 | Train Acc: 99.49| Val Acc: 62.37\n",
      "Epoch 2144: | Train Loss: 0.0070 | Val Loss: 8.2519 | Train Acc: 99.45| Val Acc: 61.97\n",
      "Epoch 2145: | Train Loss: 0.0050 | Val Loss: 8.3035 | Train Acc: 99.60| Val Acc: 61.77\n",
      "Epoch 2146: | Train Loss: 0.0067 | Val Loss: 8.2775 | Train Acc: 99.38| Val Acc: 60.90\n",
      "Epoch 2147: | Train Loss: 0.0051 | Val Loss: 8.2610 | Train Acc: 99.63| Val Acc: 61.62\n",
      "Epoch 2148: | Train Loss: 0.0050 | Val Loss: 8.2889 | Train Acc: 99.64| Val Acc: 61.79\n",
      "Epoch 2149: | Train Loss: 0.0054 | Val Loss: 8.2660 | Train Acc: 99.60| Val Acc: 61.68\n",
      "Epoch 2150: | Train Loss: 0.0053 | Val Loss: 8.3535 | Train Acc: 99.61| Val Acc: 62.12\n",
      "Epoch 2151: | Train Loss: 0.0061 | Val Loss: 8.3537 | Train Acc: 99.63| Val Acc: 61.43\n",
      "Epoch 2152: | Train Loss: 0.0055 | Val Loss: 8.3464 | Train Acc: 99.61| Val Acc: 61.84\n",
      "Epoch 2153: | Train Loss: 0.0071 | Val Loss: 8.3444 | Train Acc: 99.51| Val Acc: 61.81\n",
      "Epoch 2154: | Train Loss: 0.0050 | Val Loss: 8.3711 | Train Acc: 99.54| Val Acc: 61.91\n",
      "Epoch 2155: | Train Loss: 0.0054 | Val Loss: 8.3989 | Train Acc: 99.42| Val Acc: 61.39\n",
      "Epoch 2156: | Train Loss: 0.0075 | Val Loss: 8.4343 | Train Acc: 99.30| Val Acc: 61.79\n",
      "Epoch 2157: | Train Loss: 0.0052 | Val Loss: 8.4418 | Train Acc: 99.64| Val Acc: 61.58\n",
      "Epoch 2158: | Train Loss: 0.0057 | Val Loss: 8.5309 | Train Acc: 99.50| Val Acc: 61.49\n",
      "Epoch 2159: | Train Loss: 0.0063 | Val Loss: 8.5624 | Train Acc: 99.53| Val Acc: 61.50\n",
      "Epoch 2160: | Train Loss: 0.0051 | Val Loss: 8.5150 | Train Acc: 99.74| Val Acc: 61.50\n",
      "Epoch 2161: | Train Loss: 0.0057 | Val Loss: 8.4429 | Train Acc: 99.57| Val Acc: 61.59\n",
      "Epoch 2162: | Train Loss: 0.0059 | Val Loss: 8.3883 | Train Acc: 99.57| Val Acc: 62.20\n",
      "Epoch 2163: | Train Loss: 0.0065 | Val Loss: 8.4225 | Train Acc: 99.46| Val Acc: 62.31\n",
      "Epoch 2164: | Train Loss: 0.0064 | Val Loss: 8.4173 | Train Acc: 99.47| Val Acc: 62.10\n",
      "Epoch 2165: | Train Loss: 0.0064 | Val Loss: 8.3864 | Train Acc: 99.54| Val Acc: 62.10\n",
      "Epoch 2166: | Train Loss: 0.0072 | Val Loss: 8.3834 | Train Acc: 99.15| Val Acc: 61.80\n",
      "Epoch 2167: | Train Loss: 0.0071 | Val Loss: 8.4241 | Train Acc: 99.54| Val Acc: 62.20\n",
      "Epoch 2168: | Train Loss: 0.0074 | Val Loss: 8.4662 | Train Acc: 99.36| Val Acc: 62.49\n",
      "Epoch 2169: | Train Loss: 0.0066 | Val Loss: 8.5093 | Train Acc: 99.26| Val Acc: 62.17\n",
      "Epoch 2170: | Train Loss: 0.0070 | Val Loss: 8.7158 | Train Acc: 99.51| Val Acc: 62.07\n",
      "Epoch 2171: | Train Loss: 0.0075 | Val Loss: 8.7395 | Train Acc: 99.37| Val Acc: 61.96\n",
      "Epoch 2172: | Train Loss: 0.0061 | Val Loss: 8.5918 | Train Acc: 99.47| Val Acc: 61.88\n",
      "Epoch 2173: | Train Loss: 0.0073 | Val Loss: 8.4101 | Train Acc: 99.38| Val Acc: 62.02\n",
      "Epoch 2174: | Train Loss: 0.0067 | Val Loss: 8.4185 | Train Acc: 99.34| Val Acc: 61.52\n",
      "Epoch 2175: | Train Loss: 0.0051 | Val Loss: 8.4910 | Train Acc: 99.74| Val Acc: 61.47\n",
      "Epoch 2176: | Train Loss: 0.0083 | Val Loss: 8.5888 | Train Acc: 99.38| Val Acc: 61.80\n",
      "Epoch 2177: | Train Loss: 0.0055 | Val Loss: 8.6347 | Train Acc: 99.59| Val Acc: 62.09\n",
      "Epoch 2178: | Train Loss: 0.0063 | Val Loss: 8.7640 | Train Acc: 99.46| Val Acc: 61.90\n",
      "Epoch 2179: | Train Loss: 0.0064 | Val Loss: 8.8315 | Train Acc: 99.42| Val Acc: 61.78\n",
      "Epoch 2180: | Train Loss: 0.0043 | Val Loss: 8.8457 | Train Acc: 99.57| Val Acc: 62.08\n",
      "Epoch 2181: | Train Loss: 0.0049 | Val Loss: 8.7863 | Train Acc: 99.66| Val Acc: 62.17\n",
      "Epoch 2182: | Train Loss: 0.0067 | Val Loss: 8.7200 | Train Acc: 99.58| Val Acc: 62.19\n",
      "Epoch 2183: | Train Loss: 0.0047 | Val Loss: 8.6647 | Train Acc: 99.68| Val Acc: 61.99\n",
      "Epoch 2184: | Train Loss: 0.0042 | Val Loss: 8.6488 | Train Acc: 99.73| Val Acc: 62.17\n",
      "Epoch 2185: | Train Loss: 0.0051 | Val Loss: 8.6511 | Train Acc: 99.55| Val Acc: 61.99\n",
      "Epoch 2186: | Train Loss: 0.0048 | Val Loss: 8.6836 | Train Acc: 99.64| Val Acc: 62.07\n",
      "Epoch 2187: | Train Loss: 0.0060 | Val Loss: 8.6840 | Train Acc: 99.59| Val Acc: 62.08\n",
      "Epoch 2188: | Train Loss: 0.0066 | Val Loss: 8.6366 | Train Acc: 99.44| Val Acc: 62.08\n",
      "Epoch 2189: | Train Loss: 0.0056 | Val Loss: 8.7174 | Train Acc: 99.62| Val Acc: 62.17\n",
      "Epoch 2190: | Train Loss: 0.0049 | Val Loss: 8.7154 | Train Acc: 99.70| Val Acc: 62.61\n",
      "Epoch 2191: | Train Loss: 0.0075 | Val Loss: 8.7626 | Train Acc: 99.34| Val Acc: 62.20\n",
      "Epoch 2192: | Train Loss: 0.0040 | Val Loss: 8.8409 | Train Acc: 99.66| Val Acc: 62.40\n",
      "Epoch 2193: | Train Loss: 0.0058 | Val Loss: 8.8510 | Train Acc: 99.76| Val Acc: 62.10\n",
      "Epoch 2194: | Train Loss: 0.0051 | Val Loss: 8.8451 | Train Acc: 99.74| Val Acc: 62.10\n",
      "Epoch 2195: | Train Loss: 0.0046 | Val Loss: 8.9041 | Train Acc: 99.66| Val Acc: 61.89\n",
      "Epoch 2196: | Train Loss: 0.0055 | Val Loss: 8.9100 | Train Acc: 99.70| Val Acc: 62.19\n",
      "Epoch 2197: | Train Loss: 0.0040 | Val Loss: 8.8653 | Train Acc: 99.68| Val Acc: 61.79\n",
      "Epoch 2198: | Train Loss: 0.0049 | Val Loss: 8.8577 | Train Acc: 99.58| Val Acc: 62.00\n",
      "Epoch 2199: | Train Loss: 0.0060 | Val Loss: 8.7841 | Train Acc: 99.63| Val Acc: 61.69\n",
      "Epoch 2200: | Train Loss: 0.0046 | Val Loss: 8.7029 | Train Acc: 99.64| Val Acc: 62.00\n",
      "Epoch 2201: | Train Loss: 0.0075 | Val Loss: 8.6769 | Train Acc: 99.44| Val Acc: 61.80\n",
      "Epoch 2202: | Train Loss: 0.0042 | Val Loss: 8.6449 | Train Acc: 99.72| Val Acc: 62.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2203: | Train Loss: 0.0039 | Val Loss: 8.5999 | Train Acc: 99.80| Val Acc: 62.01\n",
      "Epoch 2204: | Train Loss: 0.0053 | Val Loss: 8.6110 | Train Acc: 99.70| Val Acc: 62.00\n",
      "Epoch 2205: | Train Loss: 0.0041 | Val Loss: 8.6372 | Train Acc: 99.65| Val Acc: 62.00\n",
      "Epoch 2206: | Train Loss: 0.0055 | Val Loss: 8.6688 | Train Acc: 99.75| Val Acc: 61.99\n",
      "Epoch 2207: | Train Loss: 0.0047 | Val Loss: 8.6513 | Train Acc: 99.52| Val Acc: 61.78\n",
      "Epoch 2208: | Train Loss: 0.0054 | Val Loss: 8.5664 | Train Acc: 99.72| Val Acc: 61.89\n",
      "Epoch 2209: | Train Loss: 0.0049 | Val Loss: 8.5555 | Train Acc: 99.64| Val Acc: 61.87\n",
      "Epoch 2210: | Train Loss: 0.0071 | Val Loss: 8.5973 | Train Acc: 99.57| Val Acc: 61.67\n",
      "Epoch 2211: | Train Loss: 0.0064 | Val Loss: 8.6001 | Train Acc: 99.34| Val Acc: 61.67\n",
      "Epoch 2212: | Train Loss: 0.0044 | Val Loss: 8.6045 | Train Acc: 99.65| Val Acc: 61.56\n",
      "Epoch 2213: | Train Loss: 0.0064 | Val Loss: 8.5721 | Train Acc: 99.66| Val Acc: 61.54\n",
      "Epoch 2214: | Train Loss: 0.0077 | Val Loss: 8.5660 | Train Acc: 99.72| Val Acc: 61.34\n",
      "Epoch 2215: | Train Loss: 0.0051 | Val Loss: 8.5985 | Train Acc: 99.64| Val Acc: 61.56\n",
      "Epoch 2216: | Train Loss: 0.0074 | Val Loss: 8.6354 | Train Acc: 99.27| Val Acc: 61.16\n",
      "Epoch 2217: | Train Loss: 0.0065 | Val Loss: 8.7010 | Train Acc: 99.49| Val Acc: 61.56\n",
      "Epoch 2218: | Train Loss: 0.0055 | Val Loss: 8.6836 | Train Acc: 99.60| Val Acc: 61.76\n",
      "Epoch 2219: | Train Loss: 0.0038 | Val Loss: 8.6049 | Train Acc: 99.83| Val Acc: 61.97\n",
      "Epoch 2220: | Train Loss: 0.0044 | Val Loss: 8.6052 | Train Acc: 99.65| Val Acc: 61.68\n",
      "Epoch 2221: | Train Loss: 0.0053 | Val Loss: 8.6333 | Train Acc: 99.57| Val Acc: 62.28\n",
      "Epoch 2222: | Train Loss: 0.0055 | Val Loss: 8.6138 | Train Acc: 99.67| Val Acc: 62.37\n",
      "Epoch 2223: | Train Loss: 0.0059 | Val Loss: 8.6206 | Train Acc: 99.57| Val Acc: 61.87\n",
      "Epoch 2224: | Train Loss: 0.0049 | Val Loss: 8.6453 | Train Acc: 99.63| Val Acc: 61.99\n",
      "Epoch 2225: | Train Loss: 0.0085 | Val Loss: 8.7000 | Train Acc: 99.55| Val Acc: 61.67\n",
      "Epoch 2226: | Train Loss: 0.0054 | Val Loss: 8.7798 | Train Acc: 99.72| Val Acc: 61.37\n",
      "Epoch 2227: | Train Loss: 0.0071 | Val Loss: 8.7917 | Train Acc: 99.57| Val Acc: 61.37\n",
      "Epoch 2228: | Train Loss: 0.0077 | Val Loss: 8.8547 | Train Acc: 99.24| Val Acc: 61.57\n",
      "Epoch 2229: | Train Loss: 0.0071 | Val Loss: 8.7910 | Train Acc: 99.44| Val Acc: 61.78\n",
      "Epoch 2230: | Train Loss: 0.0068 | Val Loss: 8.6726 | Train Acc: 99.49| Val Acc: 61.68\n",
      "Epoch 2231: | Train Loss: 0.0057 | Val Loss: 8.6091 | Train Acc: 99.57| Val Acc: 61.28\n",
      "Epoch 2232: | Train Loss: 0.0057 | Val Loss: 8.5825 | Train Acc: 99.53| Val Acc: 61.49\n",
      "Epoch 2233: | Train Loss: 0.0062 | Val Loss: 8.6231 | Train Acc: 99.34| Val Acc: 61.49\n",
      "Epoch 2234: | Train Loss: 0.0055 | Val Loss: 8.6421 | Train Acc: 99.52| Val Acc: 61.40\n",
      "Epoch 2235: | Train Loss: 0.0055 | Val Loss: 8.6407 | Train Acc: 99.47| Val Acc: 61.39\n",
      "Epoch 2236: | Train Loss: 0.0068 | Val Loss: 8.6938 | Train Acc: 99.54| Val Acc: 61.39\n",
      "Epoch 2237: | Train Loss: 0.0050 | Val Loss: 8.7440 | Train Acc: 99.65| Val Acc: 61.79\n",
      "Epoch 2238: | Train Loss: 0.0087 | Val Loss: 8.6638 | Train Acc: 99.52| Val Acc: 61.77\n",
      "Epoch 2239: | Train Loss: 0.0050 | Val Loss: 8.5391 | Train Acc: 99.60| Val Acc: 62.29\n",
      "Epoch 2240: | Train Loss: 0.0048 | Val Loss: 8.5487 | Train Acc: 99.70| Val Acc: 61.69\n",
      "Epoch 2241: | Train Loss: 0.0068 | Val Loss: 8.5924 | Train Acc: 99.60| Val Acc: 61.81\n",
      "Epoch 2242: | Train Loss: 0.0049 | Val Loss: 8.6637 | Train Acc: 99.49| Val Acc: 61.80\n",
      "Epoch 2243: | Train Loss: 0.0068 | Val Loss: 8.6986 | Train Acc: 99.42| Val Acc: 61.69\n",
      "Epoch 2244: | Train Loss: 0.0066 | Val Loss: 8.6752 | Train Acc: 99.42| Val Acc: 61.80\n",
      "Epoch 2245: | Train Loss: 0.0061 | Val Loss: 8.6114 | Train Acc: 99.45| Val Acc: 61.67\n",
      "Epoch 2246: | Train Loss: 0.0080 | Val Loss: 8.5853 | Train Acc: 99.55| Val Acc: 61.39\n",
      "Epoch 2247: | Train Loss: 0.0047 | Val Loss: 8.5775 | Train Acc: 99.65| Val Acc: 61.90\n",
      "Epoch 2248: | Train Loss: 0.0042 | Val Loss: 8.5709 | Train Acc: 99.76| Val Acc: 61.70\n",
      "Epoch 2249: | Train Loss: 0.0052 | Val Loss: 8.5640 | Train Acc: 99.63| Val Acc: 61.71\n",
      "Epoch 2250: | Train Loss: 0.0057 | Val Loss: 8.5968 | Train Acc: 99.47| Val Acc: 61.51\n",
      "Epoch 2251: | Train Loss: 0.0062 | Val Loss: 8.6188 | Train Acc: 99.50| Val Acc: 62.20\n",
      "Epoch 2252: | Train Loss: 0.0064 | Val Loss: 8.7477 | Train Acc: 99.46| Val Acc: 61.99\n",
      "Epoch 2253: | Train Loss: 0.0051 | Val Loss: 8.8422 | Train Acc: 99.63| Val Acc: 61.91\n",
      "Epoch 2254: | Train Loss: 0.0052 | Val Loss: 8.8348 | Train Acc: 99.58| Val Acc: 61.90\n",
      "Epoch 2255: | Train Loss: 0.0049 | Val Loss: 8.8397 | Train Acc: 99.73| Val Acc: 61.69\n",
      "Epoch 2256: | Train Loss: 0.0056 | Val Loss: 8.7811 | Train Acc: 99.39| Val Acc: 62.00\n",
      "Epoch 2257: | Train Loss: 0.0077 | Val Loss: 8.7407 | Train Acc: 99.53| Val Acc: 61.69\n",
      "Epoch 2258: | Train Loss: 0.0055 | Val Loss: 8.7325 | Train Acc: 99.61| Val Acc: 61.47\n",
      "Epoch 2259: | Train Loss: 0.0049 | Val Loss: 8.7673 | Train Acc: 99.63| Val Acc: 61.79\n",
      "Epoch 2260: | Train Loss: 0.0063 | Val Loss: 8.7470 | Train Acc: 99.49| Val Acc: 61.68\n",
      "Epoch 2261: | Train Loss: 0.0048 | Val Loss: 8.7171 | Train Acc: 99.57| Val Acc: 61.79\n",
      "Epoch 2262: | Train Loss: 0.0067 | Val Loss: 8.6715 | Train Acc: 99.40| Val Acc: 62.10\n",
      "Epoch 2263: | Train Loss: 0.0045 | Val Loss: 8.7895 | Train Acc: 99.70| Val Acc: 62.18\n",
      "Epoch 2264: | Train Loss: 0.0054 | Val Loss: 8.8741 | Train Acc: 99.64| Val Acc: 62.09\n",
      "Epoch 2265: | Train Loss: 0.0045 | Val Loss: 8.9115 | Train Acc: 99.77| Val Acc: 62.08\n",
      "Epoch 2266: | Train Loss: 0.0065 | Val Loss: 8.8591 | Train Acc: 99.47| Val Acc: 61.60\n",
      "Epoch 2267: | Train Loss: 0.0061 | Val Loss: 8.8112 | Train Acc: 99.57| Val Acc: 61.27\n",
      "Epoch 2268: | Train Loss: 0.0055 | Val Loss: 8.7763 | Train Acc: 99.66| Val Acc: 61.38\n",
      "Epoch 2269: | Train Loss: 0.0052 | Val Loss: 8.7367 | Train Acc: 99.42| Val Acc: 61.60\n",
      "Epoch 2270: | Train Loss: 0.0067 | Val Loss: 8.6855 | Train Acc: 99.42| Val Acc: 61.70\n",
      "Epoch 2271: | Train Loss: 0.0062 | Val Loss: 8.6893 | Train Acc: 99.41| Val Acc: 62.00\n",
      "Epoch 2272: | Train Loss: 0.0049 | Val Loss: 8.6223 | Train Acc: 99.57| Val Acc: 62.20\n",
      "Epoch 2273: | Train Loss: 0.0051 | Val Loss: 8.6031 | Train Acc: 99.70| Val Acc: 62.20\n",
      "Epoch 2274: | Train Loss: 0.0071 | Val Loss: 8.6001 | Train Acc: 99.46| Val Acc: 62.00\n",
      "Epoch 2275: | Train Loss: 0.0060 | Val Loss: 8.6867 | Train Acc: 99.52| Val Acc: 62.32\n",
      "Epoch 2276: | Train Loss: 0.0061 | Val Loss: 8.7514 | Train Acc: 99.51| Val Acc: 62.01\n",
      "Epoch 2277: | Train Loss: 0.0057 | Val Loss: 8.7740 | Train Acc: 99.59| Val Acc: 62.11\n",
      "Epoch 2278: | Train Loss: 0.0041 | Val Loss: 8.7911 | Train Acc: 99.68| Val Acc: 61.69\n",
      "Epoch 2279: | Train Loss: 0.0051 | Val Loss: 8.7643 | Train Acc: 99.60| Val Acc: 61.92\n",
      "Epoch 2280: | Train Loss: 0.0059 | Val Loss: 8.7448 | Train Acc: 99.53| Val Acc: 62.12\n",
      "Epoch 2281: | Train Loss: 0.0056 | Val Loss: 8.7568 | Train Acc: 99.44| Val Acc: 61.79\n",
      "Epoch 2282: | Train Loss: 0.0263 | Val Loss: 8.7986 | Train Acc: 99.53| Val Acc: 62.50\n",
      "Epoch 2283: | Train Loss: 0.0043 | Val Loss: 8.9385 | Train Acc: 99.66| Val Acc: 62.07\n",
      "Epoch 2284: | Train Loss: 0.0066 | Val Loss: 8.9291 | Train Acc: 99.53| Val Acc: 61.87\n",
      "Epoch 2285: | Train Loss: 0.0069 | Val Loss: 8.8762 | Train Acc: 99.44| Val Acc: 62.18\n",
      "Epoch 2286: | Train Loss: 0.0104 | Val Loss: 8.8081 | Train Acc: 99.35| Val Acc: 62.48\n",
      "Epoch 2287: | Train Loss: 0.0089 | Val Loss: 8.8008 | Train Acc: 99.44| Val Acc: 62.08\n",
      "Epoch 2288: | Train Loss: 0.0056 | Val Loss: 8.7731 | Train Acc: 99.50| Val Acc: 62.17\n",
      "Epoch 2289: | Train Loss: 0.0067 | Val Loss: 8.7943 | Train Acc: 99.67| Val Acc: 62.30\n",
      "Epoch 2290: | Train Loss: 0.0077 | Val Loss: 8.7534 | Train Acc: 99.42| Val Acc: 61.88\n",
      "Epoch 2291: | Train Loss: 0.0036 | Val Loss: 8.6845 | Train Acc: 99.73| Val Acc: 61.36\n",
      "Epoch 2292: | Train Loss: 0.0053 | Val Loss: 8.6775 | Train Acc: 99.44| Val Acc: 61.89\n",
      "Epoch 2293: | Train Loss: 0.0070 | Val Loss: 8.6659 | Train Acc: 99.51| Val Acc: 61.37\n",
      "Epoch 2294: | Train Loss: 0.0064 | Val Loss: 8.6790 | Train Acc: 99.34| Val Acc: 61.39\n",
      "Epoch 2295: | Train Loss: 0.0085 | Val Loss: 8.6847 | Train Acc: 99.33| Val Acc: 61.38\n",
      "Epoch 2296: | Train Loss: 0.0076 | Val Loss: 8.7335 | Train Acc: 99.46| Val Acc: 61.20\n",
      "Epoch 2297: | Train Loss: 0.0059 | Val Loss: 8.8355 | Train Acc: 99.60| Val Acc: 61.40\n",
      "Epoch 2298: | Train Loss: 0.0064 | Val Loss: 8.9065 | Train Acc: 99.51| Val Acc: 61.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2299: | Train Loss: 0.0045 | Val Loss: 8.9553 | Train Acc: 99.63| Val Acc: 61.36\n",
      "Epoch 2300: | Train Loss: 0.0072 | Val Loss: 8.9726 | Train Acc: 99.38| Val Acc: 61.37\n",
      "Epoch 2301: | Train Loss: 0.0069 | Val Loss: 8.9284 | Train Acc: 99.48| Val Acc: 61.47\n",
      "Epoch 2302: | Train Loss: 0.0061 | Val Loss: 8.8120 | Train Acc: 99.63| Val Acc: 61.37\n",
      "Epoch 2303: | Train Loss: 0.0053 | Val Loss: 8.7137 | Train Acc: 99.50| Val Acc: 61.27\n",
      "Epoch 2304: | Train Loss: 0.0055 | Val Loss: 8.6888 | Train Acc: 99.57| Val Acc: 61.60\n",
      "Epoch 2305: | Train Loss: 0.0053 | Val Loss: 8.6617 | Train Acc: 99.62| Val Acc: 61.69\n",
      "Epoch 2306: | Train Loss: 0.0058 | Val Loss: 8.6234 | Train Acc: 99.40| Val Acc: 61.09\n",
      "Epoch 2307: | Train Loss: 0.0040 | Val Loss: 8.6179 | Train Acc: 99.66| Val Acc: 61.38\n",
      "Epoch 2308: | Train Loss: 0.0046 | Val Loss: 8.5719 | Train Acc: 99.73| Val Acc: 61.27\n",
      "Epoch 2309: | Train Loss: 0.0068 | Val Loss: 8.5552 | Train Acc: 99.47| Val Acc: 61.37\n",
      "Epoch 2310: | Train Loss: 0.0059 | Val Loss: 8.5405 | Train Acc: 99.68| Val Acc: 61.66\n",
      "Epoch 2311: | Train Loss: 0.0052 | Val Loss: 8.5195 | Train Acc: 99.64| Val Acc: 61.06\n",
      "Epoch 2312: | Train Loss: 0.0098 | Val Loss: 8.5919 | Train Acc: 99.59| Val Acc: 60.86\n",
      "Epoch 2313: | Train Loss: 0.0043 | Val Loss: 8.6840 | Train Acc: 99.72| Val Acc: 60.75\n",
      "Epoch 2314: | Train Loss: 0.0052 | Val Loss: 8.7430 | Train Acc: 99.61| Val Acc: 61.14\n",
      "Epoch 2315: | Train Loss: 0.0052 | Val Loss: 8.8216 | Train Acc: 99.55| Val Acc: 60.75\n",
      "Epoch 2316: | Train Loss: 0.0053 | Val Loss: 8.8901 | Train Acc: 99.57| Val Acc: 60.95\n",
      "Epoch 2317: | Train Loss: 0.0088 | Val Loss: 8.7980 | Train Acc: 99.37| Val Acc: 60.97\n",
      "Epoch 2318: | Train Loss: 0.0051 | Val Loss: 8.9055 | Train Acc: 99.60| Val Acc: 60.85\n",
      "Epoch 2319: | Train Loss: 0.0050 | Val Loss: 8.8926 | Train Acc: 99.65| Val Acc: 60.85\n",
      "Epoch 2320: | Train Loss: 0.0067 | Val Loss: 8.8393 | Train Acc: 99.46| Val Acc: 60.95\n",
      "Epoch 2321: | Train Loss: 0.0053 | Val Loss: 8.8031 | Train Acc: 99.54| Val Acc: 61.25\n",
      "Epoch 2322: | Train Loss: 0.0046 | Val Loss: 8.8212 | Train Acc: 99.71| Val Acc: 61.26\n",
      "Epoch 2323: | Train Loss: 0.0053 | Val Loss: 8.8274 | Train Acc: 99.59| Val Acc: 61.75\n",
      "Epoch 2324: | Train Loss: 0.0043 | Val Loss: 8.7856 | Train Acc: 99.71| Val Acc: 61.74\n",
      "Epoch 2325: | Train Loss: 0.0053 | Val Loss: 8.7340 | Train Acc: 99.55| Val Acc: 62.05\n",
      "Epoch 2326: | Train Loss: 0.0082 | Val Loss: 8.7182 | Train Acc: 99.26| Val Acc: 62.17\n",
      "Epoch 2327: | Train Loss: 0.0068 | Val Loss: 8.6812 | Train Acc: 99.36| Val Acc: 62.18\n",
      "Epoch 2328: | Train Loss: 0.0060 | Val Loss: 8.6693 | Train Acc: 99.64| Val Acc: 61.78\n",
      "Epoch 2329: | Train Loss: 0.0051 | Val Loss: 8.6321 | Train Acc: 99.51| Val Acc: 61.87\n",
      "Epoch 2330: | Train Loss: 0.0052 | Val Loss: 8.6199 | Train Acc: 99.60| Val Acc: 61.57\n",
      "Epoch 2331: | Train Loss: 0.0049 | Val Loss: 8.6919 | Train Acc: 99.61| Val Acc: 61.97\n",
      "Epoch 2332: | Train Loss: 0.0057 | Val Loss: 8.7341 | Train Acc: 99.65| Val Acc: 62.30\n",
      "Epoch 2333: | Train Loss: 0.0049 | Val Loss: 8.8039 | Train Acc: 99.61| Val Acc: 62.19\n",
      "Epoch 2334: | Train Loss: 0.0050 | Val Loss: 8.8268 | Train Acc: 99.57| Val Acc: 62.19\n",
      "Epoch 2335: | Train Loss: 0.0488 | Val Loss: 8.8877 | Train Acc: 99.52| Val Acc: 61.57\n",
      "Epoch 2336: | Train Loss: 0.0115 | Val Loss: 8.9157 | Train Acc: 99.27| Val Acc: 61.64\n",
      "Epoch 2337: | Train Loss: 0.0257 | Val Loss: 8.8984 | Train Acc: 98.61| Val Acc: 62.15\n",
      "Epoch 2338: | Train Loss: 0.0209 | Val Loss: 8.8523 | Train Acc: 98.81| Val Acc: 61.84\n",
      "Epoch 2339: | Train Loss: 0.0140 | Val Loss: 8.7938 | Train Acc: 98.71| Val Acc: 61.81\n",
      "Epoch 2340: | Train Loss: 0.0162 | Val Loss: 8.7350 | Train Acc: 98.97| Val Acc: 62.30\n",
      "Epoch 2341: | Train Loss: 0.0150 | Val Loss: 8.7255 | Train Acc: 98.62| Val Acc: 62.72\n",
      "Epoch 2342: | Train Loss: 0.0116 | Val Loss: 8.6246 | Train Acc: 99.13| Val Acc: 62.03\n",
      "Epoch 2343: | Train Loss: 0.0118 | Val Loss: 8.5380 | Train Acc: 99.24| Val Acc: 62.16\n",
      "Epoch 2344: | Train Loss: 0.0104 | Val Loss: 8.5707 | Train Acc: 99.20| Val Acc: 62.16\n",
      "Epoch 2345: | Train Loss: 0.0130 | Val Loss: 8.5770 | Train Acc: 99.18| Val Acc: 62.26\n",
      "Epoch 2346: | Train Loss: 0.0122 | Val Loss: 8.5967 | Train Acc: 99.00| Val Acc: 61.97\n",
      "Epoch 2347: | Train Loss: 0.0073 | Val Loss: 8.6445 | Train Acc: 99.44| Val Acc: 62.07\n",
      "Epoch 2348: | Train Loss: 0.0084 | Val Loss: 8.7002 | Train Acc: 99.48| Val Acc: 61.36\n",
      "Epoch 2349: | Train Loss: 0.0084 | Val Loss: 8.7687 | Train Acc: 99.25| Val Acc: 61.25\n",
      "Epoch 2350: | Train Loss: 0.0095 | Val Loss: 8.7626 | Train Acc: 99.26| Val Acc: 61.57\n",
      "Epoch 2351: | Train Loss: 0.0099 | Val Loss: 8.7370 | Train Acc: 99.13| Val Acc: 61.88\n",
      "Epoch 2352: | Train Loss: 0.0062 | Val Loss: 8.7830 | Train Acc: 99.46| Val Acc: 62.19\n",
      "Epoch 2353: | Train Loss: 0.0089 | Val Loss: 8.8730 | Train Acc: 99.30| Val Acc: 62.18\n",
      "Epoch 2354: | Train Loss: 0.0162 | Val Loss: 8.9858 | Train Acc: 99.31| Val Acc: 61.66\n",
      "Epoch 2355: | Train Loss: 0.0113 | Val Loss: 8.9948 | Train Acc: 98.95| Val Acc: 61.54\n",
      "Epoch 2356: | Train Loss: 0.0101 | Val Loss: 8.9194 | Train Acc: 99.20| Val Acc: 61.82\n",
      "Epoch 2357: | Train Loss: 0.0101 | Val Loss: 8.8674 | Train Acc: 99.33| Val Acc: 62.04\n",
      "Epoch 2358: | Train Loss: 0.0090 | Val Loss: 8.7817 | Train Acc: 99.12| Val Acc: 62.45\n",
      "Epoch 2359: | Train Loss: 0.0130 | Val Loss: 8.8227 | Train Acc: 98.93| Val Acc: 62.14\n",
      "Epoch 2360: | Train Loss: 0.0104 | Val Loss: 8.8247 | Train Acc: 99.19| Val Acc: 61.73\n",
      "Epoch 2361: | Train Loss: 0.0074 | Val Loss: 8.8960 | Train Acc: 99.36| Val Acc: 61.64\n",
      "Epoch 2362: | Train Loss: 0.0085 | Val Loss: 8.8712 | Train Acc: 99.46| Val Acc: 60.95\n",
      "Epoch 2363: | Train Loss: 0.0102 | Val Loss: 8.8162 | Train Acc: 99.27| Val Acc: 61.14\n",
      "Epoch 2364: | Train Loss: 0.0091 | Val Loss: 8.7005 | Train Acc: 99.04| Val Acc: 61.63\n",
      "Epoch 2365: | Train Loss: 0.0075 | Val Loss: 8.7088 | Train Acc: 99.47| Val Acc: 61.65\n",
      "Epoch 2366: | Train Loss: 0.0081 | Val Loss: 8.7083 | Train Acc: 99.35| Val Acc: 61.74\n",
      "Epoch 2367: | Train Loss: 0.0108 | Val Loss: 8.7152 | Train Acc: 99.24| Val Acc: 62.06\n",
      "Epoch 2368: | Train Loss: 0.0072 | Val Loss: 8.7675 | Train Acc: 99.24| Val Acc: 62.45\n",
      "Epoch 2369: | Train Loss: 0.0094 | Val Loss: 8.8006 | Train Acc: 99.16| Val Acc: 62.06\n",
      "Epoch 2370: | Train Loss: 0.0084 | Val Loss: 8.7928 | Train Acc: 99.37| Val Acc: 61.76\n",
      "Epoch 2371: | Train Loss: 0.0049 | Val Loss: 8.7589 | Train Acc: 99.74| Val Acc: 61.64\n",
      "Epoch 2372: | Train Loss: 0.0075 | Val Loss: 8.7575 | Train Acc: 99.34| Val Acc: 61.64\n",
      "Epoch 2373: | Train Loss: 0.0066 | Val Loss: 8.7712 | Train Acc: 99.48| Val Acc: 61.25\n",
      "Epoch 2374: | Train Loss: 0.0061 | Val Loss: 8.7980 | Train Acc: 99.46| Val Acc: 61.34\n",
      "Epoch 2375: | Train Loss: 0.0067 | Val Loss: 8.8324 | Train Acc: 99.63| Val Acc: 61.35\n",
      "Epoch 2376: | Train Loss: 0.0066 | Val Loss: 8.8268 | Train Acc: 99.60| Val Acc: 61.66\n",
      "Epoch 2377: | Train Loss: 0.0069 | Val Loss: 8.7879 | Train Acc: 99.44| Val Acc: 61.96\n",
      "Epoch 2378: | Train Loss: 0.0085 | Val Loss: 8.7978 | Train Acc: 99.16| Val Acc: 62.15\n",
      "Epoch 2379: | Train Loss: 0.0075 | Val Loss: 8.8407 | Train Acc: 99.29| Val Acc: 62.05\n",
      "Epoch 2380: | Train Loss: 0.0082 | Val Loss: 8.8835 | Train Acc: 99.44| Val Acc: 62.15\n",
      "Epoch 2381: | Train Loss: 0.0078 | Val Loss: 8.9559 | Train Acc: 99.33| Val Acc: 62.06\n",
      "Epoch 2382: | Train Loss: 0.0062 | Val Loss: 8.9944 | Train Acc: 99.46| Val Acc: 62.17\n",
      "Epoch 2383: | Train Loss: 0.0060 | Val Loss: 8.9547 | Train Acc: 99.50| Val Acc: 62.27\n",
      "Epoch 2384: | Train Loss: 0.0072 | Val Loss: 8.8893 | Train Acc: 99.52| Val Acc: 62.28\n",
      "Epoch 2385: | Train Loss: 0.0057 | Val Loss: 8.8627 | Train Acc: 99.48| Val Acc: 61.99\n",
      "Epoch 2386: | Train Loss: 0.0068 | Val Loss: 8.8847 | Train Acc: 99.49| Val Acc: 61.89\n",
      "Epoch 2387: | Train Loss: 0.0079 | Val Loss: 8.9029 | Train Acc: 99.60| Val Acc: 61.88\n",
      "Epoch 2388: | Train Loss: 0.0081 | Val Loss: 8.9100 | Train Acc: 99.39| Val Acc: 61.25\n",
      "Epoch 2389: | Train Loss: 0.0074 | Val Loss: 8.9387 | Train Acc: 99.58| Val Acc: 61.34\n",
      "Epoch 2390: | Train Loss: 0.0066 | Val Loss: 8.9754 | Train Acc: 99.40| Val Acc: 61.65\n",
      "Epoch 2391: | Train Loss: 0.0058 | Val Loss: 8.9916 | Train Acc: 99.64| Val Acc: 61.85\n",
      "Epoch 2392: | Train Loss: 0.0050 | Val Loss: 8.9974 | Train Acc: 99.71| Val Acc: 61.84\n",
      "Epoch 2393: | Train Loss: 0.0079 | Val Loss: 8.8756 | Train Acc: 99.55| Val Acc: 61.74\n",
      "Epoch 2394: | Train Loss: 0.0048 | Val Loss: 8.8313 | Train Acc: 99.60| Val Acc: 61.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2395: | Train Loss: 0.0062 | Val Loss: 8.7957 | Train Acc: 99.45| Val Acc: 61.75\n",
      "Epoch 2396: | Train Loss: 0.0069 | Val Loss: 8.8221 | Train Acc: 99.44| Val Acc: 61.84\n",
      "Epoch 2397: | Train Loss: 0.0069 | Val Loss: 8.9111 | Train Acc: 99.57| Val Acc: 61.43\n",
      "Epoch 2398: | Train Loss: 0.0055 | Val Loss: 8.9255 | Train Acc: 99.70| Val Acc: 61.53\n",
      "Epoch 2399: | Train Loss: 0.0043 | Val Loss: 8.9100 | Train Acc: 99.58| Val Acc: 61.14\n",
      "Epoch 2400: | Train Loss: 0.0053 | Val Loss: 8.8641 | Train Acc: 99.63| Val Acc: 61.46\n",
      "Epoch 2401: | Train Loss: 0.0050 | Val Loss: 8.9042 | Train Acc: 99.71| Val Acc: 60.95\n",
      "Epoch 2402: | Train Loss: 0.0041 | Val Loss: 8.8860 | Train Acc: 99.90| Val Acc: 61.13\n",
      "Epoch 2403: | Train Loss: 0.0053 | Val Loss: 8.8551 | Train Acc: 99.70| Val Acc: 61.02\n",
      "Epoch 2404: | Train Loss: 0.0043 | Val Loss: 8.7905 | Train Acc: 99.79| Val Acc: 61.34\n",
      "Epoch 2405: | Train Loss: 0.0060 | Val Loss: 8.8057 | Train Acc: 99.60| Val Acc: 61.13\n",
      "Epoch 2406: | Train Loss: 0.0180 | Val Loss: 8.8974 | Train Acc: 99.23| Val Acc: 61.74\n",
      "Epoch 2407: | Train Loss: 0.0065 | Val Loss: 8.9997 | Train Acc: 99.35| Val Acc: 62.36\n",
      "Epoch 2408: | Train Loss: 0.0135 | Val Loss: 8.9381 | Train Acc: 99.17| Val Acc: 61.66\n",
      "Epoch 2409: | Train Loss: 0.0076 | Val Loss: 8.8457 | Train Acc: 99.29| Val Acc: 61.35\n",
      "Epoch 2410: | Train Loss: 0.0080 | Val Loss: 8.7762 | Train Acc: 99.35| Val Acc: 61.36\n",
      "Epoch 2411: | Train Loss: 0.0061 | Val Loss: 8.7333 | Train Acc: 99.44| Val Acc: 61.27\n",
      "Epoch 2412: | Train Loss: 0.0071 | Val Loss: 8.6674 | Train Acc: 99.32| Val Acc: 61.07\n",
      "Epoch 2413: | Train Loss: 0.0077 | Val Loss: 8.6508 | Train Acc: 99.45| Val Acc: 61.36\n",
      "Epoch 2414: | Train Loss: 0.0072 | Val Loss: 8.6315 | Train Acc: 99.38| Val Acc: 61.45\n",
      "Epoch 2415: | Train Loss: 0.0052 | Val Loss: 8.6426 | Train Acc: 99.63| Val Acc: 61.76\n",
      "Epoch 2416: | Train Loss: 0.0075 | Val Loss: 8.5904 | Train Acc: 99.40| Val Acc: 61.75\n",
      "Epoch 2417: | Train Loss: 0.0051 | Val Loss: 8.6333 | Train Acc: 99.67| Val Acc: 61.96\n",
      "Epoch 2418: | Train Loss: 0.0074 | Val Loss: 8.6578 | Train Acc: 99.34| Val Acc: 61.83\n",
      "Epoch 2419: | Train Loss: 0.0052 | Val Loss: 8.6944 | Train Acc: 99.45| Val Acc: 61.74\n",
      "Epoch 2420: | Train Loss: 0.0061 | Val Loss: 8.6967 | Train Acc: 99.68| Val Acc: 61.84\n",
      "Epoch 2421: | Train Loss: 0.0051 | Val Loss: 8.6647 | Train Acc: 99.63| Val Acc: 61.86\n",
      "Epoch 2422: | Train Loss: 0.0047 | Val Loss: 8.6096 | Train Acc: 99.70| Val Acc: 61.97\n",
      "Epoch 2423: | Train Loss: 0.0067 | Val Loss: 8.5962 | Train Acc: 99.38| Val Acc: 61.86\n",
      "Epoch 2424: | Train Loss: 0.0054 | Val Loss: 8.6092 | Train Acc: 99.48| Val Acc: 61.97\n",
      "Epoch 2425: | Train Loss: 0.0060 | Val Loss: 8.6520 | Train Acc: 99.47| Val Acc: 61.67\n",
      "Epoch 2426: | Train Loss: 0.0057 | Val Loss: 8.7281 | Train Acc: 99.54| Val Acc: 61.66\n",
      "Epoch 2427: | Train Loss: 0.0092 | Val Loss: 8.7796 | Train Acc: 99.26| Val Acc: 61.54\n",
      "Epoch 2428: | Train Loss: 0.0044 | Val Loss: 8.8586 | Train Acc: 99.57| Val Acc: 61.64\n",
      "Epoch 2429: | Train Loss: 0.0052 | Val Loss: 8.8741 | Train Acc: 99.63| Val Acc: 62.16\n",
      "Epoch 2430: | Train Loss: 0.0058 | Val Loss: 8.8460 | Train Acc: 99.58| Val Acc: 62.15\n",
      "Epoch 2431: | Train Loss: 0.0055 | Val Loss: 8.8069 | Train Acc: 99.60| Val Acc: 61.86\n",
      "Epoch 2432: | Train Loss: 0.0055 | Val Loss: 8.8169 | Train Acc: 99.50| Val Acc: 61.86\n",
      "Epoch 2433: | Train Loss: 0.0103 | Val Loss: 8.7907 | Train Acc: 99.47| Val Acc: 61.97\n",
      "Epoch 2434: | Train Loss: 0.0047 | Val Loss: 8.7685 | Train Acc: 99.67| Val Acc: 61.96\n",
      "Epoch 2435: | Train Loss: 0.0057 | Val Loss: 8.7505 | Train Acc: 99.60| Val Acc: 62.15\n",
      "Epoch 2436: | Train Loss: 0.0124 | Val Loss: 8.6992 | Train Acc: 99.64| Val Acc: 62.06\n",
      "Epoch 2437: | Train Loss: 0.0059 | Val Loss: 8.6479 | Train Acc: 99.38| Val Acc: 62.07\n",
      "Epoch 2438: | Train Loss: 0.0052 | Val Loss: 8.5511 | Train Acc: 99.67| Val Acc: 61.88\n",
      "Epoch 2439: | Train Loss: 0.0053 | Val Loss: 8.5267 | Train Acc: 99.61| Val Acc: 61.77\n",
      "Epoch 2440: | Train Loss: 0.0075 | Val Loss: 8.5752 | Train Acc: 99.33| Val Acc: 61.76\n",
      "Epoch 2441: | Train Loss: 0.0054 | Val Loss: 8.6065 | Train Acc: 99.68| Val Acc: 61.56\n",
      "Epoch 2442: | Train Loss: 0.0050 | Val Loss: 8.5916 | Train Acc: 99.71| Val Acc: 61.57\n",
      "Epoch 2443: | Train Loss: 0.0067 | Val Loss: 8.5617 | Train Acc: 99.34| Val Acc: 61.47\n",
      "Epoch 2444: | Train Loss: 0.0053 | Val Loss: 8.5541 | Train Acc: 99.66| Val Acc: 61.27\n",
      "Epoch 2445: | Train Loss: 0.0060 | Val Loss: 8.5282 | Train Acc: 99.41| Val Acc: 61.36\n",
      "Epoch 2446: | Train Loss: 0.0065 | Val Loss: 8.5160 | Train Acc: 99.52| Val Acc: 61.67\n",
      "Epoch 2447: | Train Loss: 0.0052 | Val Loss: 8.5684 | Train Acc: 99.64| Val Acc: 61.57\n",
      "Epoch 2448: | Train Loss: 0.0087 | Val Loss: 8.6196 | Train Acc: 99.29| Val Acc: 61.27\n",
      "Epoch 2449: | Train Loss: 0.0042 | Val Loss: 8.6957 | Train Acc: 99.74| Val Acc: 61.36\n",
      "Epoch 2450: | Train Loss: 0.0057 | Val Loss: 8.7280 | Train Acc: 99.48| Val Acc: 61.67\n",
      "Epoch 2451: | Train Loss: 0.0059 | Val Loss: 8.7086 | Train Acc: 99.51| Val Acc: 62.07\n",
      "Epoch 2452: | Train Loss: 0.0067 | Val Loss: 8.7373 | Train Acc: 99.44| Val Acc: 62.17\n",
      "Epoch 2453: | Train Loss: 0.0077 | Val Loss: 8.7479 | Train Acc: 99.44| Val Acc: 61.86\n",
      "Epoch 2454: | Train Loss: 0.0079 | Val Loss: 8.7094 | Train Acc: 99.60| Val Acc: 61.87\n",
      "Epoch 2455: | Train Loss: 0.0065 | Val Loss: 8.6448 | Train Acc: 99.60| Val Acc: 61.67\n",
      "Epoch 2456: | Train Loss: 0.0073 | Val Loss: 8.6033 | Train Acc: 99.60| Val Acc: 61.98\n",
      "Epoch 2457: | Train Loss: 0.0054 | Val Loss: 8.6033 | Train Acc: 99.59| Val Acc: 62.07\n",
      "Epoch 2458: | Train Loss: 0.0052 | Val Loss: 8.6219 | Train Acc: 99.56| Val Acc: 62.07\n",
      "Epoch 2459: | Train Loss: 0.0066 | Val Loss: 8.6287 | Train Acc: 99.40| Val Acc: 62.07\n",
      "Epoch 2460: | Train Loss: 0.0047 | Val Loss: 8.6422 | Train Acc: 99.68| Val Acc: 62.08\n",
      "Epoch 2461: | Train Loss: 0.0049 | Val Loss: 8.6397 | Train Acc: 99.59| Val Acc: 62.38\n",
      "Epoch 2462: | Train Loss: 0.0042 | Val Loss: 8.6620 | Train Acc: 99.71| Val Acc: 62.27\n",
      "Epoch 2463: | Train Loss: 0.0049 | Val Loss: 8.7116 | Train Acc: 99.71| Val Acc: 62.16\n",
      "Epoch 2464: | Train Loss: 0.0053 | Val Loss: 8.7219 | Train Acc: 99.66| Val Acc: 61.96\n",
      "Epoch 2465: | Train Loss: 0.0041 | Val Loss: 8.6840 | Train Acc: 99.76| Val Acc: 62.07\n",
      "Epoch 2466: | Train Loss: 0.0044 | Val Loss: 8.6704 | Train Acc: 99.71| Val Acc: 61.97\n",
      "Epoch 2467: | Train Loss: 0.0042 | Val Loss: 8.6644 | Train Acc: 99.66| Val Acc: 61.85\n",
      "Epoch 2468: | Train Loss: 0.0036 | Val Loss: 8.6428 | Train Acc: 99.76| Val Acc: 61.86\n",
      "Epoch 2469: | Train Loss: 0.0085 | Val Loss: 8.5969 | Train Acc: 99.71| Val Acc: 61.88\n",
      "Epoch 2470: | Train Loss: 0.0061 | Val Loss: 8.5606 | Train Acc: 99.70| Val Acc: 61.80\n",
      "Epoch 2471: | Train Loss: 0.0057 | Val Loss: 8.5131 | Train Acc: 99.57| Val Acc: 62.00\n",
      "Epoch 2472: | Train Loss: 0.0076 | Val Loss: 8.4375 | Train Acc: 99.44| Val Acc: 61.76\n",
      "Epoch 2473: | Train Loss: 0.0070 | Val Loss: 8.3671 | Train Acc: 99.40| Val Acc: 61.26\n",
      "Epoch 2474: | Train Loss: 0.0058 | Val Loss: 8.4903 | Train Acc: 99.55| Val Acc: 61.17\n",
      "Epoch 2475: | Train Loss: 0.0056 | Val Loss: 8.6001 | Train Acc: 99.42| Val Acc: 60.95\n",
      "Epoch 2476: | Train Loss: 0.0052 | Val Loss: 8.6132 | Train Acc: 99.67| Val Acc: 60.95\n",
      "Epoch 2477: | Train Loss: 0.0074 | Val Loss: 8.5825 | Train Acc: 99.58| Val Acc: 61.35\n",
      "Epoch 2478: | Train Loss: 0.0058 | Val Loss: 8.5433 | Train Acc: 99.44| Val Acc: 61.86\n",
      "Epoch 2479: | Train Loss: 0.0058 | Val Loss: 8.5641 | Train Acc: 99.63| Val Acc: 62.06\n",
      "Epoch 2480: | Train Loss: 0.0058 | Val Loss: 8.5453 | Train Acc: 99.50| Val Acc: 62.15\n",
      "Epoch 2481: | Train Loss: 0.0056 | Val Loss: 8.5475 | Train Acc: 99.46| Val Acc: 61.85\n",
      "Epoch 2482: | Train Loss: 0.0056 | Val Loss: 8.5780 | Train Acc: 99.61| Val Acc: 61.54\n",
      "Epoch 2483: | Train Loss: 0.0059 | Val Loss: 8.5250 | Train Acc: 99.58| Val Acc: 61.85\n",
      "Epoch 2484: | Train Loss: 0.0053 | Val Loss: 8.5108 | Train Acc: 99.54| Val Acc: 61.85\n",
      "Epoch 2485: | Train Loss: 0.0062 | Val Loss: 8.5392 | Train Acc: 99.70| Val Acc: 62.46\n",
      "Epoch 2486: | Train Loss: 0.0057 | Val Loss: 8.5573 | Train Acc: 99.59| Val Acc: 62.46\n",
      "Epoch 2487: | Train Loss: 0.0047 | Val Loss: 8.6061 | Train Acc: 99.61| Val Acc: 62.06\n",
      "Epoch 2488: | Train Loss: 0.0042 | Val Loss: 8.5809 | Train Acc: 99.55| Val Acc: 62.06\n",
      "Epoch 2489: | Train Loss: 0.0050 | Val Loss: 8.5655 | Train Acc: 99.63| Val Acc: 61.76\n",
      "Epoch 2490: | Train Loss: 0.0043 | Val Loss: 8.6326 | Train Acc: 99.63| Val Acc: 61.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2491: | Train Loss: 0.0046 | Val Loss: 8.6457 | Train Acc: 99.71| Val Acc: 61.76\n",
      "Epoch 2492: | Train Loss: 0.0045 | Val Loss: 8.7044 | Train Acc: 99.66| Val Acc: 61.87\n",
      "Epoch 2493: | Train Loss: 0.0039 | Val Loss: 8.6985 | Train Acc: 99.64| Val Acc: 61.96\n",
      "Epoch 2494: | Train Loss: 0.0053 | Val Loss: 8.7049 | Train Acc: 99.57| Val Acc: 62.06\n",
      "Epoch 2495: | Train Loss: 0.0060 | Val Loss: 8.7486 | Train Acc: 99.38| Val Acc: 62.07\n",
      "Epoch 2496: | Train Loss: 0.0053 | Val Loss: 8.7586 | Train Acc: 99.49| Val Acc: 61.87\n",
      "Epoch 2497: | Train Loss: 0.0076 | Val Loss: 8.7935 | Train Acc: 99.49| Val Acc: 61.66\n",
      "Epoch 2498: | Train Loss: 0.0055 | Val Loss: 8.7879 | Train Acc: 99.62| Val Acc: 61.44\n",
      "Epoch 2499: | Train Loss: 0.0042 | Val Loss: 8.7717 | Train Acc: 99.79| Val Acc: 61.55\n",
      "Epoch 2500: | Train Loss: 0.0047 | Val Loss: 8.7003 | Train Acc: 99.70| Val Acc: 61.67\n",
      "Epoch 2501: | Train Loss: 0.0061 | Val Loss: 8.6923 | Train Acc: 99.73| Val Acc: 61.67\n",
      "Epoch 2502: | Train Loss: 0.0039 | Val Loss: 8.7045 | Train Acc: 99.51| Val Acc: 61.67\n",
      "Epoch 2503: | Train Loss: 0.0052 | Val Loss: 8.6549 | Train Acc: 99.74| Val Acc: 61.76\n",
      "Epoch 2504: | Train Loss: 0.0058 | Val Loss: 8.6297 | Train Acc: 99.42| Val Acc: 61.96\n",
      "Epoch 2505: | Train Loss: 0.0052 | Val Loss: 8.6462 | Train Acc: 99.63| Val Acc: 61.96\n",
      "Epoch 2506: | Train Loss: 0.0045 | Val Loss: 8.6806 | Train Acc: 99.72| Val Acc: 61.74\n",
      "Epoch 2507: | Train Loss: 0.0061 | Val Loss: 8.7570 | Train Acc: 99.52| Val Acc: 61.97\n",
      "Epoch 2508: | Train Loss: 0.0055 | Val Loss: 8.7877 | Train Acc: 99.58| Val Acc: 61.77\n",
      "Epoch 2509: | Train Loss: 0.0049 | Val Loss: 8.8161 | Train Acc: 99.80| Val Acc: 61.76\n",
      "Epoch 2510: | Train Loss: 0.0036 | Val Loss: 8.8136 | Train Acc: 99.75| Val Acc: 61.88\n",
      "Epoch 2511: | Train Loss: 0.0029 | Val Loss: 8.7967 | Train Acc: 99.90| Val Acc: 61.58\n",
      "Epoch 2512: | Train Loss: 0.0039 | Val Loss: 8.7214 | Train Acc: 99.65| Val Acc: 61.48\n",
      "Epoch 2513: | Train Loss: 0.0053 | Val Loss: 8.6740 | Train Acc: 99.54| Val Acc: 61.37\n",
      "Epoch 2514: | Train Loss: 0.0044 | Val Loss: 8.6671 | Train Acc: 99.55| Val Acc: 61.57\n",
      "Epoch 2515: | Train Loss: 0.0043 | Val Loss: 8.6643 | Train Acc: 99.80| Val Acc: 61.58\n",
      "Epoch 2516: | Train Loss: 0.0050 | Val Loss: 8.6788 | Train Acc: 99.52| Val Acc: 61.27\n",
      "Epoch 2517: | Train Loss: 0.0043 | Val Loss: 8.6563 | Train Acc: 99.67| Val Acc: 61.17\n",
      "Epoch 2518: | Train Loss: 0.0060 | Val Loss: 8.6522 | Train Acc: 99.65| Val Acc: 61.06\n",
      "Epoch 2519: | Train Loss: 0.0046 | Val Loss: 8.6811 | Train Acc: 99.62| Val Acc: 61.16\n",
      "Epoch 2520: | Train Loss: 0.0044 | Val Loss: 8.6558 | Train Acc: 99.71| Val Acc: 61.36\n",
      "Epoch 2521: | Train Loss: 0.0046 | Val Loss: 8.6952 | Train Acc: 99.62| Val Acc: 61.35\n",
      "Epoch 2522: | Train Loss: 0.0057 | Val Loss: 8.7173 | Train Acc: 99.60| Val Acc: 61.36\n",
      "Epoch 2523: | Train Loss: 0.0052 | Val Loss: 8.7312 | Train Acc: 99.66| Val Acc: 61.37\n",
      "Epoch 2524: | Train Loss: 0.0037 | Val Loss: 8.7198 | Train Acc: 99.71| Val Acc: 61.18\n",
      "Epoch 2525: | Train Loss: 0.0045 | Val Loss: 8.7205 | Train Acc: 99.61| Val Acc: 61.47\n",
      "Epoch 2526: | Train Loss: 0.0039 | Val Loss: 8.7210 | Train Acc: 99.70| Val Acc: 61.37\n",
      "Epoch 2527: | Train Loss: 0.0050 | Val Loss: 8.7387 | Train Acc: 99.66| Val Acc: 61.57\n",
      "Epoch 2528: | Train Loss: 0.0051 | Val Loss: 8.7219 | Train Acc: 99.77| Val Acc: 61.76\n",
      "Epoch 2529: | Train Loss: 0.0045 | Val Loss: 8.7375 | Train Acc: 99.62| Val Acc: 61.56\n",
      "Epoch 2530: | Train Loss: 0.0031 | Val Loss: 8.7155 | Train Acc: 99.89| Val Acc: 61.96\n",
      "Epoch 2531: | Train Loss: 0.0037 | Val Loss: 8.7042 | Train Acc: 99.77| Val Acc: 61.55\n",
      "Epoch 2532: | Train Loss: 0.0058 | Val Loss: 8.7263 | Train Acc: 99.50| Val Acc: 61.96\n",
      "Epoch 2533: | Train Loss: 0.0048 | Val Loss: 8.7069 | Train Acc: 99.60| Val Acc: 62.15\n",
      "Epoch 2534: | Train Loss: 0.0036 | Val Loss: 8.6555 | Train Acc: 99.72| Val Acc: 61.75\n",
      "Epoch 2535: | Train Loss: 0.0043 | Val Loss: 8.6292 | Train Acc: 99.70| Val Acc: 61.75\n",
      "Epoch 2536: | Train Loss: 0.0046 | Val Loss: 8.6444 | Train Acc: 99.68| Val Acc: 61.85\n",
      "Epoch 2537: | Train Loss: 0.0031 | Val Loss: 8.7297 | Train Acc: 99.80| Val Acc: 61.55\n",
      "Epoch 2538: | Train Loss: 0.0041 | Val Loss: 8.7540 | Train Acc: 99.66| Val Acc: 62.16\n",
      "Epoch 2539: | Train Loss: 0.0033 | Val Loss: 8.7362 | Train Acc: 99.84| Val Acc: 62.37\n",
      "Epoch 2540: | Train Loss: 0.0047 | Val Loss: 8.7281 | Train Acc: 99.64| Val Acc: 62.16\n",
      "Epoch 2541: | Train Loss: 0.0049 | Val Loss: 8.7375 | Train Acc: 99.53| Val Acc: 62.57\n",
      "Epoch 2542: | Train Loss: 0.0027 | Val Loss: 8.6966 | Train Acc: 99.84| Val Acc: 62.16\n",
      "Epoch 2543: | Train Loss: 0.0048 | Val Loss: 8.6953 | Train Acc: 99.70| Val Acc: 62.46\n",
      "Epoch 2544: | Train Loss: 0.0051 | Val Loss: 8.6957 | Train Acc: 99.63| Val Acc: 62.37\n",
      "Epoch 2545: | Train Loss: 0.0049 | Val Loss: 8.7197 | Train Acc: 99.61| Val Acc: 62.37\n",
      "Epoch 2546: | Train Loss: 0.0044 | Val Loss: 8.6877 | Train Acc: 99.80| Val Acc: 62.46\n",
      "Epoch 2547: | Train Loss: 0.0044 | Val Loss: 8.6929 | Train Acc: 99.66| Val Acc: 62.38\n",
      "Epoch 2548: | Train Loss: 0.0046 | Val Loss: 8.6573 | Train Acc: 99.66| Val Acc: 62.58\n",
      "Epoch 2549: | Train Loss: 0.0040 | Val Loss: 8.6448 | Train Acc: 99.57| Val Acc: 62.18\n",
      "Epoch 2550: | Train Loss: 0.0042 | Val Loss: 8.6397 | Train Acc: 99.63| Val Acc: 61.97\n",
      "Epoch 2551: | Train Loss: 0.0055 | Val Loss: 8.6424 | Train Acc: 99.57| Val Acc: 62.18\n",
      "Epoch 2552: | Train Loss: 0.0037 | Val Loss: 8.5938 | Train Acc: 99.70| Val Acc: 61.67\n",
      "Epoch 2553: | Train Loss: 0.0055 | Val Loss: 8.4952 | Train Acc: 99.61| Val Acc: 61.88\n",
      "Epoch 2554: | Train Loss: 0.0060 | Val Loss: 8.5250 | Train Acc: 99.75| Val Acc: 61.76\n",
      "Epoch 2555: | Train Loss: 0.0046 | Val Loss: 8.5189 | Train Acc: 99.55| Val Acc: 61.67\n",
      "Epoch 2556: | Train Loss: 0.0061 | Val Loss: 8.4641 | Train Acc: 99.65| Val Acc: 61.88\n",
      "Epoch 2557: | Train Loss: 0.0049 | Val Loss: 8.4808 | Train Acc: 99.72| Val Acc: 61.76\n",
      "Epoch 2558: | Train Loss: 0.0038 | Val Loss: 8.5118 | Train Acc: 99.74| Val Acc: 61.88\n",
      "Epoch 2559: | Train Loss: 0.0066 | Val Loss: 8.5628 | Train Acc: 99.77| Val Acc: 62.38\n",
      "Epoch 2560: | Train Loss: 0.0041 | Val Loss: 8.5880 | Train Acc: 99.67| Val Acc: 62.18\n",
      "Epoch 2561: | Train Loss: 0.0046 | Val Loss: 8.5558 | Train Acc: 99.80| Val Acc: 62.39\n",
      "Epoch 2562: | Train Loss: 0.0033 | Val Loss: 8.5213 | Train Acc: 99.77| Val Acc: 62.18\n",
      "Epoch 2563: | Train Loss: 0.0040 | Val Loss: 8.5270 | Train Acc: 99.67| Val Acc: 61.88\n",
      "Epoch 2564: | Train Loss: 0.0034 | Val Loss: 8.5450 | Train Acc: 99.77| Val Acc: 61.67\n",
      "Epoch 2565: | Train Loss: 0.0046 | Val Loss: 8.5717 | Train Acc: 99.55| Val Acc: 61.26\n",
      "Epoch 2566: | Train Loss: 0.0058 | Val Loss: 8.5762 | Train Acc: 99.55| Val Acc: 61.35\n",
      "Epoch 2567: | Train Loss: 0.0048 | Val Loss: 8.6072 | Train Acc: 99.65| Val Acc: 61.57\n",
      "Epoch 2568: | Train Loss: 0.0041 | Val Loss: 8.6356 | Train Acc: 99.68| Val Acc: 61.58\n",
      "Epoch 2569: | Train Loss: 0.0031 | Val Loss: 8.6477 | Train Acc: 99.77| Val Acc: 61.36\n",
      "Epoch 2570: | Train Loss: 0.0047 | Val Loss: 8.6835 | Train Acc: 99.67| Val Acc: 61.66\n",
      "Epoch 2571: | Train Loss: 0.0049 | Val Loss: 8.7145 | Train Acc: 99.60| Val Acc: 61.45\n",
      "Epoch 2572: | Train Loss: 0.0053 | Val Loss: 8.6999 | Train Acc: 99.66| Val Acc: 61.35\n",
      "Epoch 2573: | Train Loss: 0.0047 | Val Loss: 8.6925 | Train Acc: 99.62| Val Acc: 61.45\n",
      "Epoch 2574: | Train Loss: 0.0038 | Val Loss: 8.6314 | Train Acc: 99.74| Val Acc: 61.15\n",
      "Epoch 2575: | Train Loss: 0.0035 | Val Loss: 8.6304 | Train Acc: 99.84| Val Acc: 61.25\n",
      "Epoch 2576: | Train Loss: 0.0048 | Val Loss: 8.6264 | Train Acc: 99.75| Val Acc: 61.35\n",
      "Epoch 2577: | Train Loss: 0.0053 | Val Loss: 8.6846 | Train Acc: 99.49| Val Acc: 61.35\n",
      "Epoch 2578: | Train Loss: 0.0052 | Val Loss: 8.6896 | Train Acc: 99.63| Val Acc: 61.45\n",
      "Epoch 2579: | Train Loss: 0.0038 | Val Loss: 8.7137 | Train Acc: 99.80| Val Acc: 61.35\n",
      "Epoch 2580: | Train Loss: 0.0039 | Val Loss: 8.6528 | Train Acc: 99.74| Val Acc: 60.94\n",
      "Epoch 2581: | Train Loss: 0.0045 | Val Loss: 8.6824 | Train Acc: 99.62| Val Acc: 61.24\n",
      "Epoch 2582: | Train Loss: 0.0036 | Val Loss: 8.6746 | Train Acc: 99.66| Val Acc: 61.04\n",
      "Epoch 2583: | Train Loss: 0.0041 | Val Loss: 8.7004 | Train Acc: 99.76| Val Acc: 61.03\n",
      "Epoch 2584: | Train Loss: 0.0047 | Val Loss: 8.7169 | Train Acc: 99.57| Val Acc: 60.94\n",
      "Epoch 2585: | Train Loss: 0.0043 | Val Loss: 8.7389 | Train Acc: 99.79| Val Acc: 60.75\n",
      "Epoch 2586: | Train Loss: 0.0045 | Val Loss: 8.7178 | Train Acc: 99.56| Val Acc: 61.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2587: | Train Loss: 0.0037 | Val Loss: 8.6966 | Train Acc: 99.81| Val Acc: 61.35\n",
      "Epoch 2588: | Train Loss: 0.0057 | Val Loss: 8.6688 | Train Acc: 99.57| Val Acc: 61.45\n",
      "Epoch 2589: | Train Loss: 0.0040 | Val Loss: 8.6408 | Train Acc: 99.74| Val Acc: 61.47\n",
      "Epoch 2590: | Train Loss: 0.0054 | Val Loss: 8.6204 | Train Acc: 99.62| Val Acc: 61.47\n",
      "Epoch 2591: | Train Loss: 0.0034 | Val Loss: 8.6208 | Train Acc: 99.87| Val Acc: 61.75\n",
      "Epoch 2592: | Train Loss: 0.0050 | Val Loss: 8.6115 | Train Acc: 99.61| Val Acc: 61.65\n",
      "Epoch 2593: | Train Loss: 0.0039 | Val Loss: 8.6170 | Train Acc: 99.60| Val Acc: 61.55\n",
      "Epoch 2594: | Train Loss: 0.0052 | Val Loss: 8.6942 | Train Acc: 99.60| Val Acc: 61.83\n",
      "Epoch 2595: | Train Loss: 0.0058 | Val Loss: 8.7411 | Train Acc: 99.53| Val Acc: 61.83\n",
      "Epoch 2596: | Train Loss: 0.0034 | Val Loss: 8.8335 | Train Acc: 99.77| Val Acc: 61.83\n",
      "Epoch 2597: | Train Loss: 0.0049 | Val Loss: 8.8248 | Train Acc: 99.60| Val Acc: 61.65\n",
      "Epoch 2598: | Train Loss: 0.0048 | Val Loss: 8.8741 | Train Acc: 99.43| Val Acc: 61.35\n",
      "Epoch 2599: | Train Loss: 0.0038 | Val Loss: 8.9245 | Train Acc: 99.79| Val Acc: 61.35\n",
      "Epoch 2600: | Train Loss: 0.0053 | Val Loss: 8.9734 | Train Acc: 99.51| Val Acc: 61.46\n",
      "Epoch 2601: | Train Loss: 0.0034 | Val Loss: 8.9861 | Train Acc: 99.68| Val Acc: 61.05\n",
      "Epoch 2602: | Train Loss: 0.0045 | Val Loss: 8.9853 | Train Acc: 99.64| Val Acc: 61.13\n",
      "Epoch 2603: | Train Loss: 0.0047 | Val Loss: 8.9934 | Train Acc: 99.66| Val Acc: 61.44\n",
      "Epoch 2604: | Train Loss: 0.0043 | Val Loss: 8.9887 | Train Acc: 99.68| Val Acc: 61.33\n",
      "Epoch 2605: | Train Loss: 0.0036 | Val Loss: 8.9959 | Train Acc: 99.74| Val Acc: 61.44\n",
      "Epoch 2606: | Train Loss: 0.0032 | Val Loss: 8.9587 | Train Acc: 99.90| Val Acc: 61.25\n",
      "Epoch 2607: | Train Loss: 0.0034 | Val Loss: 8.9315 | Train Acc: 99.77| Val Acc: 61.27\n",
      "Epoch 2608: | Train Loss: 0.0044 | Val Loss: 9.0025 | Train Acc: 99.59| Val Acc: 60.85\n",
      "Epoch 2609: | Train Loss: 0.0046 | Val Loss: 8.9304 | Train Acc: 99.67| Val Acc: 61.24\n",
      "Epoch 2610: | Train Loss: 0.0041 | Val Loss: 8.8680 | Train Acc: 99.54| Val Acc: 61.25\n",
      "Epoch 2611: | Train Loss: 0.0052 | Val Loss: 8.8560 | Train Acc: 99.58| Val Acc: 61.27\n",
      "Epoch 2612: | Train Loss: 0.0041 | Val Loss: 8.7896 | Train Acc: 99.70| Val Acc: 61.36\n",
      "Epoch 2613: | Train Loss: 0.0037 | Val Loss: 8.7698 | Train Acc: 99.68| Val Acc: 61.56\n",
      "Epoch 2614: | Train Loss: 0.0073 | Val Loss: 8.7555 | Train Acc: 99.65| Val Acc: 61.66\n",
      "Epoch 2615: | Train Loss: 0.0044 | Val Loss: 8.7921 | Train Acc: 99.57| Val Acc: 61.45\n",
      "Epoch 2616: | Train Loss: 0.0039 | Val Loss: 8.7995 | Train Acc: 99.66| Val Acc: 61.46\n",
      "Epoch 2617: | Train Loss: 0.0052 | Val Loss: 8.8357 | Train Acc: 99.73| Val Acc: 61.76\n",
      "Epoch 2618: | Train Loss: 0.0046 | Val Loss: 8.8244 | Train Acc: 99.70| Val Acc: 61.34\n",
      "Epoch 2619: | Train Loss: 0.0035 | Val Loss: 8.8838 | Train Acc: 99.80| Val Acc: 61.67\n",
      "Epoch 2620: | Train Loss: 0.0065 | Val Loss: 8.9087 | Train Acc: 99.61| Val Acc: 61.46\n",
      "Epoch 2621: | Train Loss: 0.0033 | Val Loss: 8.9304 | Train Acc: 99.75| Val Acc: 61.25\n",
      "Epoch 2622: | Train Loss: 0.0078 | Val Loss: 8.9298 | Train Acc: 99.60| Val Acc: 61.45\n",
      "Epoch 2623: | Train Loss: 0.0042 | Val Loss: 8.8830 | Train Acc: 99.73| Val Acc: 61.66\n",
      "Epoch 2624: | Train Loss: 0.0035 | Val Loss: 8.8327 | Train Acc: 99.63| Val Acc: 61.46\n",
      "Epoch 2625: | Train Loss: 0.0049 | Val Loss: 8.7724 | Train Acc: 99.64| Val Acc: 61.67\n",
      "Epoch 2626: | Train Loss: 0.0042 | Val Loss: 8.7743 | Train Acc: 99.66| Val Acc: 61.58\n",
      "Epoch 2627: | Train Loss: 0.0040 | Val Loss: 8.7661 | Train Acc: 99.68| Val Acc: 61.48\n",
      "Epoch 2628: | Train Loss: 0.0053 | Val Loss: 8.7810 | Train Acc: 99.57| Val Acc: 61.48\n",
      "Epoch 2629: | Train Loss: 0.0044 | Val Loss: 8.7959 | Train Acc: 99.80| Val Acc: 61.27\n",
      "Epoch 2630: | Train Loss: 0.0035 | Val Loss: 8.7897 | Train Acc: 99.86| Val Acc: 60.96\n",
      "Epoch 2631: | Train Loss: 0.0042 | Val Loss: 8.8006 | Train Acc: 99.71| Val Acc: 61.25\n",
      "Epoch 2632: | Train Loss: 0.0047 | Val Loss: 8.7623 | Train Acc: 99.61| Val Acc: 61.25\n",
      "Epoch 2633: | Train Loss: 0.0042 | Val Loss: 8.7288 | Train Acc: 99.61| Val Acc: 61.36\n",
      "Epoch 2634: | Train Loss: 0.0044 | Val Loss: 8.7042 | Train Acc: 99.68| Val Acc: 61.27\n",
      "Epoch 2635: | Train Loss: 0.0054 | Val Loss: 8.7078 | Train Acc: 99.61| Val Acc: 61.28\n",
      "Epoch 2636: | Train Loss: 0.0049 | Val Loss: 8.7079 | Train Acc: 99.55| Val Acc: 61.07\n",
      "Epoch 2637: | Train Loss: 0.0031 | Val Loss: 8.7695 | Train Acc: 99.79| Val Acc: 61.18\n",
      "Epoch 2638: | Train Loss: 0.0037 | Val Loss: 8.8303 | Train Acc: 99.84| Val Acc: 61.17\n",
      "Epoch 2639: | Train Loss: 0.0035 | Val Loss: 8.8613 | Train Acc: 99.66| Val Acc: 61.27\n",
      "Epoch 2640: | Train Loss: 0.0034 | Val Loss: 8.8748 | Train Acc: 99.77| Val Acc: 61.27\n",
      "Epoch 2641: | Train Loss: 0.0055 | Val Loss: 8.8680 | Train Acc: 99.71| Val Acc: 61.36\n",
      "Epoch 2642: | Train Loss: 0.0034 | Val Loss: 8.8524 | Train Acc: 99.70| Val Acc: 61.35\n",
      "Epoch 2643: | Train Loss: 0.0047 | Val Loss: 8.8501 | Train Acc: 99.66| Val Acc: 61.45\n",
      "Epoch 2644: | Train Loss: 0.0057 | Val Loss: 8.8588 | Train Acc: 99.54| Val Acc: 61.44\n",
      "Epoch 2645: | Train Loss: 0.0038 | Val Loss: 8.8507 | Train Acc: 99.80| Val Acc: 61.53\n",
      "Epoch 2646: | Train Loss: 0.0038 | Val Loss: 8.8258 | Train Acc: 99.74| Val Acc: 61.41\n",
      "Epoch 2647: | Train Loss: 0.0038 | Val Loss: 8.8356 | Train Acc: 99.65| Val Acc: 61.71\n",
      "Epoch 2648: | Train Loss: 0.0040 | Val Loss: 8.8827 | Train Acc: 99.77| Val Acc: 61.61\n",
      "Epoch 2649: | Train Loss: 0.0054 | Val Loss: 8.9112 | Train Acc: 99.71| Val Acc: 61.11\n",
      "Epoch 2650: | Train Loss: 0.0047 | Val Loss: 8.9155 | Train Acc: 99.71| Val Acc: 61.24\n",
      "Epoch 2651: | Train Loss: 0.0046 | Val Loss: 8.9930 | Train Acc: 99.66| Val Acc: 61.13\n",
      "Epoch 2652: | Train Loss: 0.0044 | Val Loss: 9.0521 | Train Acc: 99.59| Val Acc: 61.12\n",
      "Epoch 2653: | Train Loss: 0.0042 | Val Loss: 9.0681 | Train Acc: 99.73| Val Acc: 61.45\n",
      "Epoch 2654: | Train Loss: 0.0040 | Val Loss: 9.0377 | Train Acc: 99.66| Val Acc: 61.56\n",
      "Epoch 2655: | Train Loss: 0.0050 | Val Loss: 9.0001 | Train Acc: 99.55| Val Acc: 61.67\n",
      "Epoch 2656: | Train Loss: 0.0044 | Val Loss: 9.0277 | Train Acc: 99.60| Val Acc: 61.27\n",
      "Epoch 2657: | Train Loss: 0.0041 | Val Loss: 9.0374 | Train Acc: 99.70| Val Acc: 60.76\n",
      "Epoch 2658: | Train Loss: 0.0050 | Val Loss: 9.1179 | Train Acc: 99.70| Val Acc: 61.04\n",
      "Epoch 2659: | Train Loss: 0.0046 | Val Loss: 9.1849 | Train Acc: 99.71| Val Acc: 61.04\n",
      "Epoch 2660: | Train Loss: 0.0051 | Val Loss: 9.1388 | Train Acc: 99.49| Val Acc: 61.25\n",
      "Epoch 2661: | Train Loss: 0.0030 | Val Loss: 9.1663 | Train Acc: 99.73| Val Acc: 61.34\n",
      "Epoch 2662: | Train Loss: 0.0038 | Val Loss: 9.1741 | Train Acc: 99.73| Val Acc: 61.44\n",
      "Epoch 2663: | Train Loss: 0.0034 | Val Loss: 9.1750 | Train Acc: 99.80| Val Acc: 61.15\n",
      "Epoch 2664: | Train Loss: 0.0037 | Val Loss: 9.1716 | Train Acc: 99.74| Val Acc: 61.25\n",
      "Epoch 2665: | Train Loss: 0.0045 | Val Loss: 9.1420 | Train Acc: 99.64| Val Acc: 61.56\n",
      "Epoch 2666: | Train Loss: 0.0045 | Val Loss: 9.0683 | Train Acc: 99.70| Val Acc: 61.26\n",
      "Epoch 2667: | Train Loss: 0.0032 | Val Loss: 9.0067 | Train Acc: 99.66| Val Acc: 61.35\n",
      "Epoch 2668: | Train Loss: 0.0039 | Val Loss: 8.9493 | Train Acc: 99.65| Val Acc: 61.26\n",
      "Epoch 2669: | Train Loss: 0.0028 | Val Loss: 8.9736 | Train Acc: 99.84| Val Acc: 60.95\n",
      "Epoch 2670: | Train Loss: 0.0062 | Val Loss: 8.9459 | Train Acc: 99.53| Val Acc: 60.75\n",
      "Epoch 2671: | Train Loss: 0.0044 | Val Loss: 8.8922 | Train Acc: 99.54| Val Acc: 61.04\n",
      "Epoch 2672: | Train Loss: 0.0049 | Val Loss: 8.9336 | Train Acc: 99.64| Val Acc: 60.94\n",
      "Epoch 2673: | Train Loss: 0.0075 | Val Loss: 8.9549 | Train Acc: 99.86| Val Acc: 61.67\n",
      "Epoch 2674: | Train Loss: 0.0052 | Val Loss: 8.9894 | Train Acc: 99.64| Val Acc: 61.57\n",
      "Epoch 2675: | Train Loss: 0.0058 | Val Loss: 8.9613 | Train Acc: 99.64| Val Acc: 61.67\n",
      "Epoch 2676: | Train Loss: 0.0047 | Val Loss: 8.9075 | Train Acc: 99.66| Val Acc: 61.15\n",
      "Epoch 2677: | Train Loss: 0.0037 | Val Loss: 8.8866 | Train Acc: 99.80| Val Acc: 61.05\n",
      "Epoch 2678: | Train Loss: 0.0046 | Val Loss: 8.8601 | Train Acc: 99.70| Val Acc: 61.14\n",
      "Epoch 2679: | Train Loss: 0.0045 | Val Loss: 8.8725 | Train Acc: 99.70| Val Acc: 61.02\n",
      "Epoch 2680: | Train Loss: 0.0078 | Val Loss: 8.8588 | Train Acc: 99.66| Val Acc: 60.83\n",
      "Epoch 2681: | Train Loss: 0.0052 | Val Loss: 8.7871 | Train Acc: 99.55| Val Acc: 61.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2682: | Train Loss: 0.0065 | Val Loss: 8.7912 | Train Acc: 99.48| Val Acc: 60.83\n",
      "Epoch 2683: | Train Loss: 0.0033 | Val Loss: 8.8388 | Train Acc: 99.74| Val Acc: 60.84\n",
      "Epoch 2684: | Train Loss: 0.0078 | Val Loss: 8.8016 | Train Acc: 99.49| Val Acc: 61.26\n",
      "Epoch 2685: | Train Loss: 0.0046 | Val Loss: 8.7541 | Train Acc: 99.73| Val Acc: 61.16\n",
      "Epoch 2686: | Train Loss: 0.0038 | Val Loss: 8.6955 | Train Acc: 99.65| Val Acc: 60.65\n",
      "Epoch 2687: | Train Loss: 0.0040 | Val Loss: 8.7252 | Train Acc: 99.70| Val Acc: 60.95\n",
      "Epoch 2688: | Train Loss: 0.0052 | Val Loss: 8.8562 | Train Acc: 99.60| Val Acc: 61.47\n",
      "Epoch 2689: | Train Loss: 0.0088 | Val Loss: 8.9056 | Train Acc: 99.60| Val Acc: 60.86\n",
      "Epoch 2690: | Train Loss: 0.0046 | Val Loss: 8.9260 | Train Acc: 99.62| Val Acc: 60.74\n",
      "Epoch 2691: | Train Loss: 0.0036 | Val Loss: 8.9208 | Train Acc: 99.77| Val Acc: 61.24\n",
      "Epoch 2692: | Train Loss: 0.0051 | Val Loss: 8.9144 | Train Acc: 99.63| Val Acc: 61.34\n",
      "Epoch 2693: | Train Loss: 0.0047 | Val Loss: 8.8956 | Train Acc: 99.74| Val Acc: 60.95\n",
      "Epoch 2694: | Train Loss: 0.0045 | Val Loss: 8.8644 | Train Acc: 99.68| Val Acc: 60.86\n",
      "Epoch 2695: | Train Loss: 0.0048 | Val Loss: 8.8598 | Train Acc: 99.67| Val Acc: 60.96\n",
      "Epoch 2696: | Train Loss: 0.0040 | Val Loss: 8.8282 | Train Acc: 99.66| Val Acc: 61.18\n",
      "Epoch 2697: | Train Loss: 0.0052 | Val Loss: 8.8319 | Train Acc: 99.54| Val Acc: 61.27\n",
      "Epoch 2698: | Train Loss: 0.0041 | Val Loss: 8.8074 | Train Acc: 99.67| Val Acc: 61.27\n",
      "Epoch 2699: | Train Loss: 0.0028 | Val Loss: 8.8423 | Train Acc: 99.81| Val Acc: 61.59\n",
      "Epoch 2700: | Train Loss: 0.0043 | Val Loss: 8.8207 | Train Acc: 99.71| Val Acc: 61.49\n",
      "Epoch 2701: | Train Loss: 0.0044 | Val Loss: 8.8184 | Train Acc: 99.61| Val Acc: 61.39\n",
      "Epoch 2702: | Train Loss: 0.0031 | Val Loss: 8.8180 | Train Acc: 99.87| Val Acc: 61.48\n",
      "Epoch 2703: | Train Loss: 0.0046 | Val Loss: 8.8173 | Train Acc: 99.71| Val Acc: 61.28\n",
      "Epoch 2704: | Train Loss: 0.0033 | Val Loss: 8.8397 | Train Acc: 99.90| Val Acc: 61.38\n",
      "Epoch 2705: | Train Loss: 0.0032 | Val Loss: 8.9076 | Train Acc: 99.80| Val Acc: 61.27\n",
      "Epoch 2706: | Train Loss: 0.0041 | Val Loss: 8.9235 | Train Acc: 99.67| Val Acc: 61.17\n",
      "Epoch 2707: | Train Loss: 0.0056 | Val Loss: 8.9280 | Train Acc: 99.68| Val Acc: 61.36\n",
      "Epoch 2708: | Train Loss: 0.0058 | Val Loss: 8.9912 | Train Acc: 99.36| Val Acc: 61.17\n",
      "Epoch 2709: | Train Loss: 0.0033 | Val Loss: 8.9694 | Train Acc: 99.66| Val Acc: 61.26\n",
      "Epoch 2710: | Train Loss: 0.0041 | Val Loss: 9.0086 | Train Acc: 99.65| Val Acc: 61.45\n",
      "Epoch 2711: | Train Loss: 0.0047 | Val Loss: 8.9746 | Train Acc: 99.64| Val Acc: 61.37\n",
      "Epoch 2712: | Train Loss: 0.0033 | Val Loss: 8.9795 | Train Acc: 99.77| Val Acc: 61.36\n",
      "Epoch 2713: | Train Loss: 0.0034 | Val Loss: 8.9789 | Train Acc: 99.79| Val Acc: 61.27\n",
      "Epoch 2714: | Train Loss: 0.0047 | Val Loss: 8.9739 | Train Acc: 99.60| Val Acc: 61.27\n",
      "Epoch 2715: | Train Loss: 0.0040 | Val Loss: 8.9983 | Train Acc: 99.71| Val Acc: 61.27\n",
      "Epoch 2716: | Train Loss: 0.0053 | Val Loss: 8.9804 | Train Acc: 99.77| Val Acc: 60.96\n",
      "Epoch 2717: | Train Loss: 0.0057 | Val Loss: 8.9321 | Train Acc: 99.73| Val Acc: 60.95\n",
      "Epoch 2718: | Train Loss: 0.0043 | Val Loss: 8.9738 | Train Acc: 99.74| Val Acc: 61.14\n",
      "Epoch 2719: | Train Loss: 0.0036 | Val Loss: 8.9608 | Train Acc: 99.72| Val Acc: 61.14\n",
      "Epoch 2720: | Train Loss: 0.0037 | Val Loss: 8.9223 | Train Acc: 99.81| Val Acc: 61.34\n",
      "Epoch 2721: | Train Loss: 0.0050 | Val Loss: 8.8856 | Train Acc: 99.59| Val Acc: 61.57\n",
      "Epoch 2722: | Train Loss: 0.0038 | Val Loss: 8.8700 | Train Acc: 99.74| Val Acc: 61.56\n",
      "Epoch 2723: | Train Loss: 0.0052 | Val Loss: 8.8912 | Train Acc: 99.63| Val Acc: 61.66\n",
      "Epoch 2724: | Train Loss: 0.0043 | Val Loss: 8.9613 | Train Acc: 99.70| Val Acc: 62.07\n",
      "Epoch 2725: | Train Loss: 0.0033 | Val Loss: 8.9855 | Train Acc: 99.77| Val Acc: 62.18\n",
      "Epoch 2726: | Train Loss: 0.0042 | Val Loss: 9.0158 | Train Acc: 99.77| Val Acc: 61.78\n",
      "Epoch 2727: | Train Loss: 0.0044 | Val Loss: 9.0362 | Train Acc: 99.74| Val Acc: 61.67\n",
      "Epoch 2728: | Train Loss: 0.0038 | Val Loss: 9.1053 | Train Acc: 99.71| Val Acc: 61.67\n",
      "Epoch 2729: | Train Loss: 0.0032 | Val Loss: 9.0709 | Train Acc: 99.84| Val Acc: 61.67\n",
      "Epoch 2730: | Train Loss: 0.0042 | Val Loss: 9.0873 | Train Acc: 99.79| Val Acc: 61.67\n",
      "Epoch 2731: | Train Loss: 0.0025 | Val Loss: 9.0889 | Train Acc: 99.84| Val Acc: 61.56\n",
      "Epoch 2732: | Train Loss: 0.0034 | Val Loss: 9.0450 | Train Acc: 99.80| Val Acc: 61.76\n",
      "Epoch 2733: | Train Loss: 0.0024 | Val Loss: 9.0245 | Train Acc: 99.83| Val Acc: 61.67\n",
      "Epoch 2734: | Train Loss: 0.0029 | Val Loss: 9.0181 | Train Acc: 99.75| Val Acc: 61.77\n",
      "Epoch 2735: | Train Loss: 0.0032 | Val Loss: 9.0420 | Train Acc: 99.71| Val Acc: 61.78\n",
      "Epoch 2736: | Train Loss: 0.0049 | Val Loss: 9.1049 | Train Acc: 99.97| Val Acc: 61.78\n",
      "Epoch 2737: | Train Loss: 0.0046 | Val Loss: 9.0471 | Train Acc: 99.53| Val Acc: 61.79\n",
      "Epoch 2738: | Train Loss: 0.0029 | Val Loss: 8.9903 | Train Acc: 99.75| Val Acc: 61.67\n",
      "Epoch 2739: | Train Loss: 0.0036 | Val Loss: 9.0081 | Train Acc: 99.63| Val Acc: 61.77\n",
      "Epoch 2740: | Train Loss: 0.0036 | Val Loss: 9.0021 | Train Acc: 99.74| Val Acc: 61.58\n",
      "Epoch 2741: | Train Loss: 0.0039 | Val Loss: 9.0191 | Train Acc: 99.74| Val Acc: 61.58\n",
      "Epoch 2742: | Train Loss: 0.0057 | Val Loss: 8.9464 | Train Acc: 99.76| Val Acc: 61.69\n",
      "Epoch 2743: | Train Loss: 0.0041 | Val Loss: 8.9207 | Train Acc: 99.73| Val Acc: 61.49\n",
      "Epoch 2744: | Train Loss: 0.0040 | Val Loss: 8.8896 | Train Acc: 99.66| Val Acc: 61.49\n",
      "Epoch 2745: | Train Loss: 0.0029 | Val Loss: 8.9228 | Train Acc: 99.83| Val Acc: 61.69\n",
      "Epoch 2746: | Train Loss: 0.0040 | Val Loss: 8.9622 | Train Acc: 99.72| Val Acc: 62.18\n",
      "Epoch 2747: | Train Loss: 0.0040 | Val Loss: 8.9394 | Train Acc: 99.76| Val Acc: 61.67\n",
      "Epoch 2748: | Train Loss: 0.0032 | Val Loss: 8.9078 | Train Acc: 99.80| Val Acc: 62.18\n",
      "Epoch 2749: | Train Loss: 0.0045 | Val Loss: 8.8972 | Train Acc: 99.77| Val Acc: 61.87\n",
      "Epoch 2750: | Train Loss: 0.0034 | Val Loss: 8.9034 | Train Acc: 99.83| Val Acc: 62.07\n",
      "Epoch 2751: | Train Loss: 0.0049 | Val Loss: 8.9126 | Train Acc: 99.51| Val Acc: 62.07\n",
      "Epoch 2752: | Train Loss: 0.0042 | Val Loss: 8.9288 | Train Acc: 99.73| Val Acc: 61.75\n",
      "Epoch 2753: | Train Loss: 0.0035 | Val Loss: 8.9110 | Train Acc: 99.79| Val Acc: 61.86\n",
      "Epoch 2754: | Train Loss: 0.0040 | Val Loss: 8.9202 | Train Acc: 99.80| Val Acc: 61.99\n",
      "Epoch 2755: | Train Loss: 0.0044 | Val Loss: 8.9341 | Train Acc: 99.60| Val Acc: 62.10\n",
      "Epoch 2756: | Train Loss: 0.0023 | Val Loss: 9.0272 | Train Acc: 99.90| Val Acc: 62.00\n",
      "Epoch 2757: | Train Loss: 0.0040 | Val Loss: 9.0596 | Train Acc: 99.63| Val Acc: 62.08\n",
      "Epoch 2758: | Train Loss: 0.0041 | Val Loss: 9.0758 | Train Acc: 99.65| Val Acc: 62.20\n",
      "Epoch 2759: | Train Loss: 0.0030 | Val Loss: 9.0774 | Train Acc: 99.86| Val Acc: 61.79\n",
      "Epoch 2760: | Train Loss: 0.0041 | Val Loss: 9.0892 | Train Acc: 99.80| Val Acc: 61.79\n",
      "Epoch 2761: | Train Loss: 0.0034 | Val Loss: 9.1070 | Train Acc: 99.70| Val Acc: 61.59\n",
      "Epoch 2762: | Train Loss: 0.0041 | Val Loss: 9.1434 | Train Acc: 99.76| Val Acc: 61.59\n",
      "Epoch 2763: | Train Loss: 0.0052 | Val Loss: 9.1638 | Train Acc: 99.70| Val Acc: 61.16\n",
      "Epoch 2764: | Train Loss: 0.0033 | Val Loss: 9.1853 | Train Acc: 99.87| Val Acc: 61.25\n",
      "Epoch 2765: | Train Loss: 0.0027 | Val Loss: 9.1766 | Train Acc: 99.90| Val Acc: 61.34\n",
      "Epoch 2766: | Train Loss: 0.0040 | Val Loss: 9.1558 | Train Acc: 99.63| Val Acc: 61.55\n",
      "Epoch 2767: | Train Loss: 0.0042 | Val Loss: 9.1767 | Train Acc: 99.71| Val Acc: 61.67\n",
      "Epoch 2768: | Train Loss: 0.0032 | Val Loss: 9.1376 | Train Acc: 99.87| Val Acc: 61.67\n",
      "Epoch 2769: | Train Loss: 0.0043 | Val Loss: 9.0837 | Train Acc: 99.65| Val Acc: 61.67\n",
      "Epoch 2770: | Train Loss: 0.0054 | Val Loss: 9.0160 | Train Acc: 99.71| Val Acc: 61.37\n",
      "Epoch 2771: | Train Loss: 0.0029 | Val Loss: 9.0192 | Train Acc: 99.83| Val Acc: 61.27\n",
      "Epoch 2772: | Train Loss: 0.0044 | Val Loss: 8.9997 | Train Acc: 99.67| Val Acc: 61.36\n",
      "Epoch 2773: | Train Loss: 0.0032 | Val Loss: 9.0239 | Train Acc: 99.78| Val Acc: 61.56\n",
      "Epoch 2774: | Train Loss: 0.0054 | Val Loss: 9.0618 | Train Acc: 99.79| Val Acc: 61.85\n",
      "Epoch 2775: | Train Loss: 0.0039 | Val Loss: 9.0732 | Train Acc: 99.77| Val Acc: 61.77\n",
      "Epoch 2776: | Train Loss: 0.0041 | Val Loss: 9.0851 | Train Acc: 99.74| Val Acc: 61.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2777: | Train Loss: 0.0046 | Val Loss: 9.1602 | Train Acc: 99.70| Val Acc: 61.67\n",
      "Epoch 2778: | Train Loss: 0.0051 | Val Loss: 9.2282 | Train Acc: 99.64| Val Acc: 61.95\n",
      "Epoch 2779: | Train Loss: 0.0043 | Val Loss: 9.2554 | Train Acc: 99.61| Val Acc: 61.96\n",
      "Epoch 2780: | Train Loss: 0.0049 | Val Loss: 9.2432 | Train Acc: 99.68| Val Acc: 61.86\n",
      "Epoch 2781: | Train Loss: 0.0033 | Val Loss: 9.2431 | Train Acc: 99.80| Val Acc: 61.55\n",
      "Epoch 2782: | Train Loss: 0.0051 | Val Loss: 9.2761 | Train Acc: 99.58| Val Acc: 61.75\n",
      "Epoch 2783: | Train Loss: 0.0036 | Val Loss: 9.2292 | Train Acc: 99.71| Val Acc: 61.96\n",
      "Epoch 2784: | Train Loss: 0.0041 | Val Loss: 9.1808 | Train Acc: 99.67| Val Acc: 62.27\n",
      "Epoch 2785: | Train Loss: 0.0054 | Val Loss: 9.2230 | Train Acc: 99.65| Val Acc: 61.77\n",
      "Epoch 2786: | Train Loss: 0.0034 | Val Loss: 9.1948 | Train Acc: 99.73| Val Acc: 61.58\n",
      "Epoch 2787: | Train Loss: 0.0037 | Val Loss: 9.1367 | Train Acc: 99.67| Val Acc: 61.89\n",
      "Epoch 2788: | Train Loss: 0.0035 | Val Loss: 9.0840 | Train Acc: 99.77| Val Acc: 61.90\n",
      "Epoch 2789: | Train Loss: 0.0042 | Val Loss: 9.0284 | Train Acc: 99.80| Val Acc: 61.57\n",
      "Epoch 2790: | Train Loss: 0.0035 | Val Loss: 8.9966 | Train Acc: 99.73| Val Acc: 61.26\n",
      "Epoch 2791: | Train Loss: 0.0037 | Val Loss: 9.0670 | Train Acc: 99.68| Val Acc: 61.57\n",
      "Epoch 2792: | Train Loss: 0.0052 | Val Loss: 9.0318 | Train Acc: 99.65| Val Acc: 61.67\n",
      "Epoch 2793: | Train Loss: 0.0038 | Val Loss: 9.0044 | Train Acc: 99.74| Val Acc: 61.58\n",
      "Epoch 2794: | Train Loss: 0.0032 | Val Loss: 8.9858 | Train Acc: 99.71| Val Acc: 61.37\n",
      "Epoch 2795: | Train Loss: 0.0033 | Val Loss: 9.0047 | Train Acc: 99.93| Val Acc: 61.68\n",
      "Epoch 2796: | Train Loss: 0.0036 | Val Loss: 8.9946 | Train Acc: 99.70| Val Acc: 61.35\n",
      "Epoch 2797: | Train Loss: 0.0052 | Val Loss: 9.0474 | Train Acc: 99.50| Val Acc: 61.75\n",
      "Epoch 2798: | Train Loss: 0.0046 | Val Loss: 9.0395 | Train Acc: 99.72| Val Acc: 61.56\n",
      "Epoch 2799: | Train Loss: 0.0052 | Val Loss: 9.0518 | Train Acc: 99.46| Val Acc: 61.57\n",
      "Epoch 2800: | Train Loss: 0.0033 | Val Loss: 9.0194 | Train Acc: 99.84| Val Acc: 61.75\n",
      "Epoch 2801: | Train Loss: 0.0041 | Val Loss: 9.0454 | Train Acc: 99.71| Val Acc: 62.06\n",
      "Epoch 2802: | Train Loss: 0.0037 | Val Loss: 9.0409 | Train Acc: 99.70| Val Acc: 61.74\n",
      "Epoch 2803: | Train Loss: 0.0035 | Val Loss: 9.0092 | Train Acc: 99.74| Val Acc: 61.44\n",
      "Epoch 2804: | Train Loss: 0.0035 | Val Loss: 8.9897 | Train Acc: 99.77| Val Acc: 61.55\n",
      "Epoch 2805: | Train Loss: 0.0042 | Val Loss: 9.0081 | Train Acc: 99.70| Val Acc: 61.15\n",
      "Epoch 2806: | Train Loss: 0.0044 | Val Loss: 9.0420 | Train Acc: 99.78| Val Acc: 61.05\n",
      "Epoch 2807: | Train Loss: 0.0034 | Val Loss: 9.0473 | Train Acc: 99.68| Val Acc: 61.15\n",
      "Epoch 2808: | Train Loss: 0.0040 | Val Loss: 9.0574 | Train Acc: 99.75| Val Acc: 61.35\n",
      "Epoch 2809: | Train Loss: 0.0037 | Val Loss: 9.0684 | Train Acc: 99.72| Val Acc: 61.45\n",
      "Epoch 2810: | Train Loss: 0.0037 | Val Loss: 9.1075 | Train Acc: 99.75| Val Acc: 61.25\n",
      "Epoch 2811: | Train Loss: 0.0036 | Val Loss: 9.0548 | Train Acc: 99.76| Val Acc: 61.46\n",
      "Epoch 2812: | Train Loss: 0.0035 | Val Loss: 9.0310 | Train Acc: 99.84| Val Acc: 61.46\n",
      "Epoch 2813: | Train Loss: 0.0036 | Val Loss: 8.9721 | Train Acc: 99.85| Val Acc: 61.66\n",
      "Epoch 2814: | Train Loss: 0.0044 | Val Loss: 8.9576 | Train Acc: 99.73| Val Acc: 61.46\n",
      "Epoch 2815: | Train Loss: 0.0049 | Val Loss: 8.9867 | Train Acc: 99.66| Val Acc: 61.56\n",
      "Epoch 2816: | Train Loss: 0.0031 | Val Loss: 8.9541 | Train Acc: 99.80| Val Acc: 61.66\n",
      "Epoch 2817: | Train Loss: 0.0024 | Val Loss: 8.9146 | Train Acc: 99.80| Val Acc: 61.64\n",
      "Epoch 2818: | Train Loss: 0.0047 | Val Loss: 8.8951 | Train Acc: 99.74| Val Acc: 61.54\n",
      "Epoch 2819: | Train Loss: 0.0044 | Val Loss: 8.9317 | Train Acc: 99.66| Val Acc: 61.95\n",
      "Epoch 2820: | Train Loss: 0.0036 | Val Loss: 8.9581 | Train Acc: 99.73| Val Acc: 61.57\n",
      "Epoch 2821: | Train Loss: 0.0034 | Val Loss: 9.0711 | Train Acc: 99.57| Val Acc: 61.46\n",
      "Epoch 2822: | Train Loss: 0.0040 | Val Loss: 9.1018 | Train Acc: 99.66| Val Acc: 61.36\n",
      "Epoch 2823: | Train Loss: 0.0029 | Val Loss: 9.1442 | Train Acc: 99.84| Val Acc: 61.47\n",
      "Epoch 2824: | Train Loss: 0.0027 | Val Loss: 9.0923 | Train Acc: 99.87| Val Acc: 61.37\n",
      "Epoch 2825: | Train Loss: 0.0028 | Val Loss: 9.0421 | Train Acc: 99.80| Val Acc: 61.18\n",
      "Epoch 2826: | Train Loss: 0.0042 | Val Loss: 8.9913 | Train Acc: 99.65| Val Acc: 61.28\n",
      "Epoch 2827: | Train Loss: 0.0035 | Val Loss: 9.0027 | Train Acc: 99.74| Val Acc: 61.48\n",
      "Epoch 2828: | Train Loss: 0.0038 | Val Loss: 9.0203 | Train Acc: 99.76| Val Acc: 61.59\n",
      "Epoch 2829: | Train Loss: 0.0031 | Val Loss: 9.0195 | Train Acc: 99.77| Val Acc: 61.59\n",
      "Epoch 2830: | Train Loss: 0.0046 | Val Loss: 9.0497 | Train Acc: 99.55| Val Acc: 61.58\n",
      "Epoch 2831: | Train Loss: 0.0029 | Val Loss: 9.0708 | Train Acc: 99.86| Val Acc: 61.58\n",
      "Epoch 2832: | Train Loss: 0.0036 | Val Loss: 9.1027 | Train Acc: 99.77| Val Acc: 61.46\n",
      "Epoch 2833: | Train Loss: 0.0035 | Val Loss: 9.1233 | Train Acc: 99.70| Val Acc: 61.76\n",
      "Epoch 2834: | Train Loss: 0.0042 | Val Loss: 9.0615 | Train Acc: 99.76| Val Acc: 61.56\n",
      "Epoch 2835: | Train Loss: 0.0027 | Val Loss: 9.0812 | Train Acc: 99.88| Val Acc: 61.47\n",
      "Epoch 2836: | Train Loss: 0.0039 | Val Loss: 9.0818 | Train Acc: 99.68| Val Acc: 61.57\n",
      "Epoch 2837: | Train Loss: 0.0049 | Val Loss: 9.0883 | Train Acc: 99.64| Val Acc: 61.16\n",
      "Epoch 2838: | Train Loss: 0.0049 | Val Loss: 9.0640 | Train Acc: 99.67| Val Acc: 61.57\n",
      "Epoch 2839: | Train Loss: 0.0045 | Val Loss: 9.0776 | Train Acc: 99.71| Val Acc: 61.46\n",
      "Epoch 2840: | Train Loss: 0.0037 | Val Loss: 9.1362 | Train Acc: 99.74| Val Acc: 61.46\n",
      "Epoch 2841: | Train Loss: 0.0026 | Val Loss: 9.0754 | Train Acc: 99.87| Val Acc: 61.37\n",
      "Epoch 2842: | Train Loss: 0.0045 | Val Loss: 9.0061 | Train Acc: 99.63| Val Acc: 61.27\n",
      "Epoch 2843: | Train Loss: 0.0038 | Val Loss: 8.9787 | Train Acc: 99.79| Val Acc: 61.39\n",
      "Epoch 2844: | Train Loss: 0.0037 | Val Loss: 8.9986 | Train Acc: 99.74| Val Acc: 61.27\n",
      "Epoch 2845: | Train Loss: 0.0087 | Val Loss: 9.0872 | Train Acc: 99.74| Val Acc: 61.78\n",
      "Epoch 2846: | Train Loss: 0.0034 | Val Loss: 9.1496 | Train Acc: 99.79| Val Acc: 62.07\n",
      "Epoch 2847: | Train Loss: 0.0136 | Val Loss: 9.2577 | Train Acc: 99.47| Val Acc: 61.87\n",
      "Epoch 2848: | Train Loss: 0.0055 | Val Loss: 9.2185 | Train Acc: 99.57| Val Acc: 61.27\n",
      "Epoch 2849: | Train Loss: 0.0052 | Val Loss: 9.2032 | Train Acc: 99.64| Val Acc: 61.16\n",
      "Epoch 2850: | Train Loss: 0.0059 | Val Loss: 9.1215 | Train Acc: 99.43| Val Acc: 60.66\n",
      "Epoch 2851: | Train Loss: 0.0035 | Val Loss: 9.0404 | Train Acc: 99.77| Val Acc: 60.68\n",
      "Epoch 2852: | Train Loss: 0.0054 | Val Loss: 9.0155 | Train Acc: 99.54| Val Acc: 60.66\n",
      "Epoch 2853: | Train Loss: 0.0051 | Val Loss: 9.0105 | Train Acc: 99.61| Val Acc: 60.87\n",
      "Epoch 2854: | Train Loss: 0.0033 | Val Loss: 9.0221 | Train Acc: 99.70| Val Acc: 61.07\n",
      "Epoch 2855: | Train Loss: 0.0060 | Val Loss: 8.9247 | Train Acc: 99.53| Val Acc: 61.26\n",
      "Epoch 2856: | Train Loss: 0.0043 | Val Loss: 8.8771 | Train Acc: 99.68| Val Acc: 61.36\n",
      "Epoch 2857: | Train Loss: 0.0058 | Val Loss: 8.8752 | Train Acc: 99.57| Val Acc: 61.06\n",
      "Epoch 2858: | Train Loss: 0.0055 | Val Loss: 8.8950 | Train Acc: 99.59| Val Acc: 61.26\n",
      "Epoch 2859: | Train Loss: 0.0036 | Val Loss: 8.9440 | Train Acc: 99.74| Val Acc: 61.37\n",
      "Epoch 2860: | Train Loss: 0.0025 | Val Loss: 8.9755 | Train Acc: 99.76| Val Acc: 60.96\n",
      "Epoch 2861: | Train Loss: 0.0057 | Val Loss: 8.9954 | Train Acc: 99.49| Val Acc: 60.76\n",
      "Epoch 2862: | Train Loss: 0.0040 | Val Loss: 9.0359 | Train Acc: 99.66| Val Acc: 61.27\n",
      "Epoch 2863: | Train Loss: 0.0040 | Val Loss: 9.0556 | Train Acc: 99.64| Val Acc: 60.96\n",
      "Epoch 2864: | Train Loss: 0.0059 | Val Loss: 9.0403 | Train Acc: 99.61| Val Acc: 60.97\n",
      "Epoch 2865: | Train Loss: 0.0032 | Val Loss: 8.9745 | Train Acc: 99.84| Val Acc: 61.08\n",
      "Epoch 2866: | Train Loss: 0.0032 | Val Loss: 8.9471 | Train Acc: 99.80| Val Acc: 61.08\n",
      "Epoch 2867: | Train Loss: 0.0045 | Val Loss: 8.8987 | Train Acc: 99.54| Val Acc: 61.07\n",
      "Epoch 2868: | Train Loss: 0.0037 | Val Loss: 8.8895 | Train Acc: 99.76| Val Acc: 61.47\n",
      "Epoch 2869: | Train Loss: 0.0041 | Val Loss: 8.9038 | Train Acc: 99.64| Val Acc: 61.48\n",
      "Epoch 2870: | Train Loss: 0.0042 | Val Loss: 8.8886 | Train Acc: 99.70| Val Acc: 61.78\n",
      "Epoch 2871: | Train Loss: 0.0053 | Val Loss: 8.9867 | Train Acc: 99.62| Val Acc: 60.96\n",
      "Epoch 2872: | Train Loss: 0.0032 | Val Loss: 9.0549 | Train Acc: 99.79| Val Acc: 60.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2873: | Train Loss: 0.0044 | Val Loss: 9.0948 | Train Acc: 99.67| Val Acc: 61.26\n",
      "Epoch 2874: | Train Loss: 0.0101 | Val Loss: 9.0090 | Train Acc: 99.58| Val Acc: 60.95\n",
      "Epoch 2875: | Train Loss: 0.0057 | Val Loss: 8.9373 | Train Acc: 99.64| Val Acc: 61.37\n",
      "Epoch 2876: | Train Loss: 0.0026 | Val Loss: 8.9349 | Train Acc: 99.92| Val Acc: 61.37\n",
      "Epoch 2877: | Train Loss: 0.0047 | Val Loss: 8.9185 | Train Acc: 99.74| Val Acc: 61.28\n",
      "Epoch 2878: | Train Loss: 0.0029 | Val Loss: 8.9378 | Train Acc: 99.79| Val Acc: 61.28\n",
      "Epoch 2879: | Train Loss: 0.0036 | Val Loss: 8.9362 | Train Acc: 99.67| Val Acc: 61.47\n",
      "Epoch 2880: | Train Loss: 0.0035 | Val Loss: 8.9718 | Train Acc: 99.84| Val Acc: 61.17\n",
      "Epoch 2881: | Train Loss: 0.0038 | Val Loss: 8.9520 | Train Acc: 99.73| Val Acc: 61.17\n",
      "Epoch 2882: | Train Loss: 0.0047 | Val Loss: 9.0041 | Train Acc: 99.67| Val Acc: 61.47\n",
      "Epoch 2883: | Train Loss: 0.0047 | Val Loss: 8.9959 | Train Acc: 99.74| Val Acc: 61.26\n",
      "Epoch 2884: | Train Loss: 0.0030 | Val Loss: 9.0005 | Train Acc: 99.83| Val Acc: 61.26\n",
      "Epoch 2885: | Train Loss: 0.0035 | Val Loss: 8.9965 | Train Acc: 99.73| Val Acc: 61.06\n",
      "Epoch 2886: | Train Loss: 0.0044 | Val Loss: 8.9803 | Train Acc: 99.43| Val Acc: 61.36\n",
      "Epoch 2887: | Train Loss: 0.0054 | Val Loss: 9.0402 | Train Acc: 99.53| Val Acc: 61.27\n",
      "Epoch 2888: | Train Loss: 0.0043 | Val Loss: 9.0796 | Train Acc: 99.63| Val Acc: 61.08\n",
      "Epoch 2889: | Train Loss: 0.0039 | Val Loss: 9.0455 | Train Acc: 99.70| Val Acc: 61.27\n",
      "Epoch 2890: | Train Loss: 0.0033 | Val Loss: 9.0551 | Train Acc: 99.78| Val Acc: 61.37\n",
      "Epoch 2891: | Train Loss: 0.0039 | Val Loss: 9.0699 | Train Acc: 99.77| Val Acc: 60.97\n",
      "Epoch 2892: | Train Loss: 0.0042 | Val Loss: 9.0763 | Train Acc: 99.58| Val Acc: 60.97\n",
      "Epoch 2893: | Train Loss: 0.0039 | Val Loss: 9.1358 | Train Acc: 99.76| Val Acc: 61.27\n",
      "Epoch 2894: | Train Loss: 0.0053 | Val Loss: 9.1442 | Train Acc: 99.68| Val Acc: 61.07\n",
      "Epoch 2895: | Train Loss: 0.0035 | Val Loss: 9.1530 | Train Acc: 99.90| Val Acc: 61.07\n",
      "Epoch 2896: | Train Loss: 0.0054 | Val Loss: 9.1536 | Train Acc: 99.72| Val Acc: 61.18\n",
      "Epoch 2897: | Train Loss: 0.0033 | Val Loss: 9.1380 | Train Acc: 99.83| Val Acc: 60.97\n",
      "Epoch 2898: | Train Loss: 0.0036 | Val Loss: 9.1364 | Train Acc: 99.68| Val Acc: 60.87\n",
      "Epoch 2899: | Train Loss: 0.0041 | Val Loss: 9.1383 | Train Acc: 99.66| Val Acc: 60.87\n",
      "Epoch 2900: | Train Loss: 0.0047 | Val Loss: 9.2274 | Train Acc: 99.58| Val Acc: 60.97\n",
      "Epoch 2901: | Train Loss: 0.0048 | Val Loss: 9.2863 | Train Acc: 99.48| Val Acc: 61.18\n",
      "Epoch 2902: | Train Loss: 0.0052 | Val Loss: 9.3579 | Train Acc: 99.41| Val Acc: 61.48\n",
      "Epoch 2903: | Train Loss: 0.0049 | Val Loss: 9.3679 | Train Acc: 99.73| Val Acc: 61.28\n",
      "Epoch 2904: | Train Loss: 0.0045 | Val Loss: 9.3318 | Train Acc: 99.84| Val Acc: 61.08\n",
      "Epoch 2905: | Train Loss: 0.0035 | Val Loss: 9.2518 | Train Acc: 99.77| Val Acc: 61.27\n",
      "Epoch 2906: | Train Loss: 0.0044 | Val Loss: 9.2434 | Train Acc: 99.60| Val Acc: 61.18\n",
      "Epoch 2907: | Train Loss: 0.0035 | Val Loss: 9.2081 | Train Acc: 99.79| Val Acc: 60.98\n",
      "Epoch 2908: | Train Loss: 0.0038 | Val Loss: 9.1734 | Train Acc: 99.68| Val Acc: 60.98\n",
      "Epoch 2909: | Train Loss: 0.0035 | Val Loss: 9.2004 | Train Acc: 99.68| Val Acc: 61.19\n",
      "Epoch 2910: | Train Loss: 0.0058 | Val Loss: 9.2132 | Train Acc: 99.48| Val Acc: 61.50\n",
      "Epoch 2911: | Train Loss: 0.0035 | Val Loss: 9.1958 | Train Acc: 99.77| Val Acc: 61.50\n",
      "Epoch 2912: | Train Loss: 0.0029 | Val Loss: 9.1913 | Train Acc: 99.72| Val Acc: 61.60\n",
      "Epoch 2913: | Train Loss: 0.0035 | Val Loss: 9.2036 | Train Acc: 99.83| Val Acc: 61.39\n",
      "Epoch 2914: | Train Loss: 0.0040 | Val Loss: 9.2452 | Train Acc: 99.63| Val Acc: 61.38\n",
      "Epoch 2915: | Train Loss: 0.0036 | Val Loss: 9.2152 | Train Acc: 99.83| Val Acc: 61.27\n",
      "Epoch 2916: | Train Loss: 0.0033 | Val Loss: 9.2001 | Train Acc: 99.77| Val Acc: 61.27\n",
      "Epoch 2917: | Train Loss: 0.0029 | Val Loss: 9.1930 | Train Acc: 99.66| Val Acc: 61.17\n",
      "Epoch 2918: | Train Loss: 0.0040 | Val Loss: 9.1702 | Train Acc: 99.72| Val Acc: 61.27\n",
      "Epoch 2919: | Train Loss: 0.0054 | Val Loss: 9.1661 | Train Acc: 99.57| Val Acc: 61.67\n",
      "Epoch 2920: | Train Loss: 0.0036 | Val Loss: 9.1931 | Train Acc: 99.70| Val Acc: 61.67\n",
      "Epoch 2921: | Train Loss: 0.0075 | Val Loss: 9.1068 | Train Acc: 99.44| Val Acc: 61.77\n",
      "Epoch 2922: | Train Loss: 0.0041 | Val Loss: 9.1173 | Train Acc: 99.62| Val Acc: 61.66\n",
      "Epoch 2923: | Train Loss: 0.0047 | Val Loss: 9.1492 | Train Acc: 99.59| Val Acc: 61.55\n",
      "Epoch 2924: | Train Loss: 0.0046 | Val Loss: 9.2165 | Train Acc: 99.67| Val Acc: 61.56\n",
      "Epoch 2925: | Train Loss: 0.0036 | Val Loss: 9.2582 | Train Acc: 99.77| Val Acc: 61.45\n",
      "Epoch 2926: | Train Loss: 0.0030 | Val Loss: 9.2914 | Train Acc: 99.83| Val Acc: 61.45\n",
      "Epoch 2927: | Train Loss: 0.0039 | Val Loss: 9.3231 | Train Acc: 99.68| Val Acc: 61.35\n",
      "Epoch 2928: | Train Loss: 0.0029 | Val Loss: 9.3117 | Train Acc: 99.80| Val Acc: 61.56\n",
      "Epoch 2929: | Train Loss: 0.0034 | Val Loss: 9.2405 | Train Acc: 99.84| Val Acc: 61.35\n",
      "Epoch 2930: | Train Loss: 0.0027 | Val Loss: 9.2056 | Train Acc: 99.83| Val Acc: 61.34\n",
      "Epoch 2931: | Train Loss: 0.0052 | Val Loss: 9.1248 | Train Acc: 99.73| Val Acc: 61.76\n",
      "Epoch 2932: | Train Loss: 0.0036 | Val Loss: 9.1030 | Train Acc: 99.71| Val Acc: 61.76\n",
      "Epoch 2933: | Train Loss: 0.0037 | Val Loss: 9.1023 | Train Acc: 99.73| Val Acc: 61.67\n",
      "Epoch 2934: | Train Loss: 0.0034 | Val Loss: 9.0846 | Train Acc: 99.76| Val Acc: 61.57\n",
      "Epoch 2935: | Train Loss: 0.0046 | Val Loss: 9.1282 | Train Acc: 99.63| Val Acc: 61.46\n",
      "Epoch 2936: | Train Loss: 0.0049 | Val Loss: 9.1476 | Train Acc: 99.63| Val Acc: 61.27\n",
      "Epoch 2937: | Train Loss: 0.0040 | Val Loss: 9.1619 | Train Acc: 99.68| Val Acc: 61.17\n",
      "Epoch 2938: | Train Loss: 0.0038 | Val Loss: 9.1567 | Train Acc: 99.71| Val Acc: 60.95\n",
      "Epoch 2939: | Train Loss: 0.0033 | Val Loss: 9.1677 | Train Acc: 99.84| Val Acc: 60.95\n",
      "Epoch 2940: | Train Loss: 0.0040 | Val Loss: 9.1427 | Train Acc: 99.66| Val Acc: 61.06\n",
      "Epoch 2941: | Train Loss: 0.0043 | Val Loss: 9.1406 | Train Acc: 99.66| Val Acc: 61.18\n",
      "Epoch 2942: | Train Loss: 0.0051 | Val Loss: 9.1798 | Train Acc: 99.63| Val Acc: 61.27\n",
      "Epoch 2943: | Train Loss: 0.0036 | Val Loss: 9.1289 | Train Acc: 99.75| Val Acc: 61.27\n",
      "Epoch 2944: | Train Loss: 0.0044 | Val Loss: 9.0924 | Train Acc: 99.77| Val Acc: 60.86\n",
      "Epoch 2945: | Train Loss: 0.0047 | Val Loss: 9.1148 | Train Acc: 99.66| Val Acc: 61.15\n",
      "Epoch 2946: | Train Loss: 0.0053 | Val Loss: 9.0575 | Train Acc: 99.77| Val Acc: 61.26\n",
      "Epoch 2947: | Train Loss: 0.0031 | Val Loss: 9.0034 | Train Acc: 99.81| Val Acc: 61.17\n",
      "Epoch 2948: | Train Loss: 0.0034 | Val Loss: 9.0087 | Train Acc: 99.68| Val Acc: 61.16\n",
      "Epoch 2949: | Train Loss: 0.0033 | Val Loss: 9.0409 | Train Acc: 99.80| Val Acc: 61.06\n",
      "Epoch 2950: | Train Loss: 0.0044 | Val Loss: 9.0272 | Train Acc: 99.67| Val Acc: 61.37\n",
      "Epoch 2951: | Train Loss: 0.0044 | Val Loss: 9.0333 | Train Acc: 99.68| Val Acc: 61.06\n",
      "Epoch 2952: | Train Loss: 0.0040 | Val Loss: 9.0746 | Train Acc: 99.73| Val Acc: 60.96\n",
      "Epoch 2953: | Train Loss: 0.0042 | Val Loss: 9.1122 | Train Acc: 99.73| Val Acc: 61.26\n",
      "Epoch 2954: | Train Loss: 0.0035 | Val Loss: 9.1702 | Train Acc: 99.77| Val Acc: 61.67\n",
      "Epoch 2955: | Train Loss: 0.0052 | Val Loss: 9.2065 | Train Acc: 99.63| Val Acc: 61.47\n",
      "Epoch 2956: | Train Loss: 0.0020 | Val Loss: 9.2343 | Train Acc: 99.89| Val Acc: 61.27\n",
      "Epoch 2957: | Train Loss: 0.0040 | Val Loss: 9.2454 | Train Acc: 99.67| Val Acc: 61.27\n",
      "Epoch 2958: | Train Loss: 0.0036 | Val Loss: 9.2212 | Train Acc: 99.73| Val Acc: 61.17\n",
      "Epoch 2959: | Train Loss: 0.0031 | Val Loss: 9.1872 | Train Acc: 99.77| Val Acc: 61.17\n",
      "Epoch 2960: | Train Loss: 0.0048 | Val Loss: 9.1863 | Train Acc: 99.67| Val Acc: 61.08\n",
      "Epoch 2961: | Train Loss: 0.0040 | Val Loss: 9.1585 | Train Acc: 99.71| Val Acc: 60.98\n",
      "Epoch 2962: | Train Loss: 0.0033 | Val Loss: 9.1841 | Train Acc: 99.66| Val Acc: 60.97\n",
      "Epoch 2963: | Train Loss: 0.0030 | Val Loss: 9.2257 | Train Acc: 99.77| Val Acc: 61.07\n",
      "Epoch 2964: | Train Loss: 0.0041 | Val Loss: 9.2444 | Train Acc: 99.71| Val Acc: 60.77\n",
      "Epoch 2965: | Train Loss: 0.0048 | Val Loss: 9.2368 | Train Acc: 99.57| Val Acc: 61.07\n",
      "Epoch 2966: | Train Loss: 0.0050 | Val Loss: 9.2998 | Train Acc: 99.52| Val Acc: 61.17\n",
      "Epoch 2967: | Train Loss: 0.0031 | Val Loss: 9.3206 | Train Acc: 99.68| Val Acc: 60.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2968: | Train Loss: 0.0036 | Val Loss: 9.3504 | Train Acc: 99.71| Val Acc: 60.87\n",
      "Epoch 2969: | Train Loss: 0.0027 | Val Loss: 9.3259 | Train Acc: 99.87| Val Acc: 60.87\n",
      "Epoch 2970: | Train Loss: 0.0045 | Val Loss: 9.2614 | Train Acc: 99.64| Val Acc: 60.96\n",
      "Epoch 2971: | Train Loss: 0.0044 | Val Loss: 9.2679 | Train Acc: 99.71| Val Acc: 60.46\n",
      "Epoch 2972: | Train Loss: 0.0058 | Val Loss: 9.2052 | Train Acc: 99.59| Val Acc: 60.36\n",
      "Epoch 2973: | Train Loss: 0.0049 | Val Loss: 9.2138 | Train Acc: 99.66| Val Acc: 60.45\n",
      "Epoch 2974: | Train Loss: 0.0057 | Val Loss: 9.2501 | Train Acc: 99.60| Val Acc: 60.45\n",
      "Epoch 2975: | Train Loss: 0.0033 | Val Loss: 9.2514 | Train Acc: 99.89| Val Acc: 60.55\n",
      "Epoch 2976: | Train Loss: 0.0052 | Val Loss: 9.1786 | Train Acc: 99.58| Val Acc: 60.56\n",
      "Epoch 2977: | Train Loss: 0.0038 | Val Loss: 9.1584 | Train Acc: 99.71| Val Acc: 60.67\n",
      "Epoch 2978: | Train Loss: 0.0044 | Val Loss: 9.1408 | Train Acc: 99.76| Val Acc: 60.57\n",
      "Epoch 2979: | Train Loss: 0.0045 | Val Loss: 9.1670 | Train Acc: 99.66| Val Acc: 60.68\n",
      "Epoch 2980: | Train Loss: 0.0026 | Val Loss: 9.1708 | Train Acc: 99.87| Val Acc: 60.78\n",
      "Epoch 2981: | Train Loss: 0.0050 | Val Loss: 9.1750 | Train Acc: 99.63| Val Acc: 60.78\n",
      "Epoch 2982: | Train Loss: 0.0034 | Val Loss: 9.1903 | Train Acc: 99.72| Val Acc: 61.19\n",
      "Epoch 2983: | Train Loss: 0.0030 | Val Loss: 9.1486 | Train Acc: 99.84| Val Acc: 61.19\n",
      "Epoch 2984: | Train Loss: 0.0026 | Val Loss: 9.1736 | Train Acc: 99.84| Val Acc: 61.08\n",
      "Epoch 2985: | Train Loss: 0.0024 | Val Loss: 9.1699 | Train Acc: 99.93| Val Acc: 61.19\n",
      "Epoch 2986: | Train Loss: 0.0025 | Val Loss: 9.1565 | Train Acc: 99.93| Val Acc: 61.19\n",
      "Epoch 2987: | Train Loss: 0.0045 | Val Loss: 9.1954 | Train Acc: 99.65| Val Acc: 61.08\n",
      "Epoch 2988: | Train Loss: 0.0036 | Val Loss: 9.2844 | Train Acc: 99.76| Val Acc: 60.87\n",
      "Epoch 2989: | Train Loss: 0.0036 | Val Loss: 9.2439 | Train Acc: 99.77| Val Acc: 60.87\n",
      "Epoch 2990: | Train Loss: 0.0037 | Val Loss: 9.2274 | Train Acc: 99.77| Val Acc: 60.67\n",
      "Epoch 2991: | Train Loss: 0.0054 | Val Loss: 9.2699 | Train Acc: 99.51| Val Acc: 60.76\n",
      "Epoch 2992: | Train Loss: 0.0029 | Val Loss: 9.3336 | Train Acc: 99.72| Val Acc: 60.66\n",
      "Epoch 2993: | Train Loss: 0.0043 | Val Loss: 9.3686 | Train Acc: 99.77| Val Acc: 60.66\n",
      "Epoch 2994: | Train Loss: 0.0067 | Val Loss: 9.3633 | Train Acc: 99.46| Val Acc: 60.96\n",
      "Epoch 2995: | Train Loss: 0.0063 | Val Loss: 9.3803 | Train Acc: 99.55| Val Acc: 61.06\n",
      "Epoch 2996: | Train Loss: 0.0031 | Val Loss: 9.3817 | Train Acc: 99.87| Val Acc: 60.86\n",
      "Epoch 2997: | Train Loss: 0.0025 | Val Loss: 9.3851 | Train Acc: 99.81| Val Acc: 60.85\n",
      "Epoch 2998: | Train Loss: 0.0036 | Val Loss: 9.3796 | Train Acc: 99.79| Val Acc: 61.06\n",
      "Epoch 2999: | Train Loss: 0.0040 | Val Loss: 9.3708 | Train Acc: 99.70| Val Acc: 61.16\n",
      "Epoch 3000: | Train Loss: 0.0033 | Val Loss: 9.3592 | Train Acc: 99.83| Val Acc: 61.16\n",
      "Epoch 3001: | Train Loss: 0.0045 | Val Loss: 9.3368 | Train Acc: 99.68| Val Acc: 61.18\n",
      "Epoch 3002: | Train Loss: 0.0040 | Val Loss: 9.2947 | Train Acc: 99.68| Val Acc: 61.06\n",
      "Epoch 3003: | Train Loss: 0.0034 | Val Loss: 9.3084 | Train Acc: 99.74| Val Acc: 61.06\n",
      "Epoch 3004: | Train Loss: 0.0025 | Val Loss: 9.3166 | Train Acc: 99.90| Val Acc: 61.38\n",
      "Epoch 3005: | Train Loss: 0.0023 | Val Loss: 9.3198 | Train Acc: 99.87| Val Acc: 61.08\n",
      "Epoch 3006: | Train Loss: 0.0032 | Val Loss: 9.3077 | Train Acc: 99.83| Val Acc: 61.49\n",
      "Epoch 3007: | Train Loss: 0.0022 | Val Loss: 9.2574 | Train Acc: 99.90| Val Acc: 61.28\n",
      "Epoch 3008: | Train Loss: 0.0038 | Val Loss: 9.2424 | Train Acc: 99.74| Val Acc: 61.77\n",
      "Epoch 3009: | Train Loss: 0.0047 | Val Loss: 9.2320 | Train Acc: 99.64| Val Acc: 61.77\n",
      "Epoch 3010: | Train Loss: 0.0051 | Val Loss: 9.2362 | Train Acc: 99.64| Val Acc: 61.58\n",
      "Epoch 3011: | Train Loss: 0.0036 | Val Loss: 9.2913 | Train Acc: 99.68| Val Acc: 61.68\n",
      "Epoch 3012: | Train Loss: 0.0035 | Val Loss: 9.3343 | Train Acc: 99.72| Val Acc: 61.79\n",
      "Epoch 3013: | Train Loss: 0.0036 | Val Loss: 9.3570 | Train Acc: 99.65| Val Acc: 61.59\n",
      "Epoch 3014: | Train Loss: 0.0047 | Val Loss: 9.4233 | Train Acc: 99.68| Val Acc: 61.69\n",
      "Epoch 3015: | Train Loss: 0.0039 | Val Loss: 9.4249 | Train Acc: 99.67| Val Acc: 61.49\n",
      "Epoch 3016: | Train Loss: 0.0052 | Val Loss: 9.3986 | Train Acc: 99.64| Val Acc: 61.50\n",
      "Epoch 3017: | Train Loss: 0.0038 | Val Loss: 9.4452 | Train Acc: 99.73| Val Acc: 61.28\n",
      "Epoch 3018: | Train Loss: 0.0030 | Val Loss: 9.4172 | Train Acc: 99.87| Val Acc: 61.49\n",
      "Epoch 3019: | Train Loss: 0.0029 | Val Loss: 9.3513 | Train Acc: 99.79| Val Acc: 61.59\n",
      "Epoch 3020: | Train Loss: 0.0040 | Val Loss: 9.3566 | Train Acc: 99.70| Val Acc: 61.58\n",
      "Epoch 3021: | Train Loss: 0.0035 | Val Loss: 9.3159 | Train Acc: 99.77| Val Acc: 61.58\n",
      "Epoch 3022: | Train Loss: 0.0040 | Val Loss: 9.2850 | Train Acc: 99.61| Val Acc: 61.47\n",
      "Epoch 3023: | Train Loss: 0.0031 | Val Loss: 9.2656 | Train Acc: 99.87| Val Acc: 61.59\n",
      "Epoch 3024: | Train Loss: 0.0033 | Val Loss: 9.2759 | Train Acc: 99.76| Val Acc: 61.49\n",
      "Epoch 3025: | Train Loss: 0.0033 | Val Loss: 9.2149 | Train Acc: 99.83| Val Acc: 61.59\n",
      "Epoch 3026: | Train Loss: 0.0040 | Val Loss: 9.1883 | Train Acc: 99.61| Val Acc: 61.59\n",
      "Epoch 3027: | Train Loss: 0.0030 | Val Loss: 9.1462 | Train Acc: 99.86| Val Acc: 61.69\n",
      "Epoch 3028: | Train Loss: 0.0031 | Val Loss: 9.1216 | Train Acc: 99.80| Val Acc: 61.49\n",
      "Epoch 3029: | Train Loss: 0.0038 | Val Loss: 9.1080 | Train Acc: 99.74| Val Acc: 61.67\n",
      "Epoch 3030: | Train Loss: 0.0033 | Val Loss: 9.1694 | Train Acc: 99.80| Val Acc: 61.67\n",
      "Epoch 3031: | Train Loss: 0.0025 | Val Loss: 9.2251 | Train Acc: 99.90| Val Acc: 61.77\n",
      "Epoch 3032: | Train Loss: 0.0032 | Val Loss: 9.2551 | Train Acc: 99.64| Val Acc: 61.57\n",
      "Epoch 3033: | Train Loss: 0.0033 | Val Loss: 9.2693 | Train Acc: 99.68| Val Acc: 61.77\n",
      "Epoch 3034: | Train Loss: 0.0040 | Val Loss: 9.2531 | Train Acc: 99.70| Val Acc: 61.86\n",
      "Epoch 3035: | Train Loss: 0.0037 | Val Loss: 9.2243 | Train Acc: 99.74| Val Acc: 61.56\n",
      "Epoch 3036: | Train Loss: 0.0062 | Val Loss: 9.1821 | Train Acc: 99.58| Val Acc: 61.35\n",
      "Epoch 3037: | Train Loss: 0.0032 | Val Loss: 9.1857 | Train Acc: 99.80| Val Acc: 61.16\n",
      "Epoch 3038: | Train Loss: 0.0033 | Val Loss: 9.2108 | Train Acc: 99.71| Val Acc: 61.05\n",
      "Epoch 3039: | Train Loss: 0.0027 | Val Loss: 9.2279 | Train Acc: 99.84| Val Acc: 61.15\n",
      "Epoch 3040: | Train Loss: 0.0048 | Val Loss: 9.2039 | Train Acc: 99.68| Val Acc: 61.15\n",
      "Epoch 3041: | Train Loss: 0.0041 | Val Loss: 9.1771 | Train Acc: 99.73| Val Acc: 61.17\n",
      "Epoch 3042: | Train Loss: 0.0032 | Val Loss: 9.1740 | Train Acc: 99.84| Val Acc: 61.07\n",
      "Epoch 3043: | Train Loss: 0.0032 | Val Loss: 9.1236 | Train Acc: 99.77| Val Acc: 60.87\n",
      "Epoch 3044: | Train Loss: 0.0025 | Val Loss: 9.1641 | Train Acc: 99.93| Val Acc: 60.98\n",
      "Epoch 3045: | Train Loss: 0.0034 | Val Loss: 9.1955 | Train Acc: 99.76| Val Acc: 61.27\n",
      "Epoch 3046: | Train Loss: 0.0027 | Val Loss: 9.2598 | Train Acc: 99.87| Val Acc: 60.96\n",
      "Epoch 3047: | Train Loss: 0.0027 | Val Loss: 9.3082 | Train Acc: 99.86| Val Acc: 60.97\n",
      "Epoch 3048: | Train Loss: 0.0035 | Val Loss: 9.3273 | Train Acc: 99.80| Val Acc: 60.88\n",
      "Epoch 3049: | Train Loss: 0.0024 | Val Loss: 9.3923 | Train Acc: 99.87| Val Acc: 61.20\n",
      "Epoch 3050: | Train Loss: 0.0028 | Val Loss: 9.3506 | Train Acc: 99.84| Val Acc: 61.09\n",
      "Epoch 3051: | Train Loss: 0.0032 | Val Loss: 9.3300 | Train Acc: 99.76| Val Acc: 61.08\n",
      "Epoch 3052: | Train Loss: 0.0039 | Val Loss: 9.3169 | Train Acc: 99.74| Val Acc: 61.07\n",
      "Epoch 3053: | Train Loss: 0.0032 | Val Loss: 9.3213 | Train Acc: 99.87| Val Acc: 61.18\n",
      "Epoch 3054: | Train Loss: 0.0025 | Val Loss: 9.3495 | Train Acc: 99.87| Val Acc: 60.96\n",
      "Epoch 3055: | Train Loss: 0.0041 | Val Loss: 9.3748 | Train Acc: 99.64| Val Acc: 60.86\n",
      "Epoch 3056: | Train Loss: 0.0031 | Val Loss: 9.3826 | Train Acc: 99.84| Val Acc: 60.65\n",
      "Epoch 3057: | Train Loss: 0.0041 | Val Loss: 9.3586 | Train Acc: 99.60| Val Acc: 60.77\n",
      "Epoch 3058: | Train Loss: 0.0051 | Val Loss: 9.3998 | Train Acc: 99.66| Val Acc: 60.56\n",
      "Epoch 3059: | Train Loss: 0.0041 | Val Loss: 9.4355 | Train Acc: 99.66| Val Acc: 60.97\n",
      "Epoch 3060: | Train Loss: 0.0030 | Val Loss: 9.4516 | Train Acc: 99.76| Val Acc: 60.97\n",
      "Epoch 3061: | Train Loss: 0.0043 | Val Loss: 9.4850 | Train Acc: 99.74| Val Acc: 60.87\n",
      "Epoch 3062: | Train Loss: 0.0033 | Val Loss: 9.5324 | Train Acc: 99.70| Val Acc: 60.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3063: | Train Loss: 0.0033 | Val Loss: 9.5423 | Train Acc: 99.84| Val Acc: 60.87\n",
      "Epoch 3064: | Train Loss: 0.0032 | Val Loss: 9.5370 | Train Acc: 99.66| Val Acc: 60.78\n",
      "Epoch 3065: | Train Loss: 0.0033 | Val Loss: 9.5676 | Train Acc: 99.84| Val Acc: 60.88\n",
      "Epoch 3066: | Train Loss: 0.0031 | Val Loss: 9.5735 | Train Acc: 99.84| Val Acc: 60.88\n",
      "Epoch 3067: | Train Loss: 0.0039 | Val Loss: 9.5199 | Train Acc: 99.70| Val Acc: 61.19\n",
      "Epoch 3068: | Train Loss: 0.0030 | Val Loss: 9.5018 | Train Acc: 99.74| Val Acc: 61.29\n",
      "Epoch 3069: | Train Loss: 0.0036 | Val Loss: 9.5013 | Train Acc: 99.63| Val Acc: 61.08\n",
      "Epoch 3070: | Train Loss: 0.0032 | Val Loss: 9.4446 | Train Acc: 99.75| Val Acc: 61.18\n",
      "Epoch 3071: | Train Loss: 0.0044 | Val Loss: 9.4209 | Train Acc: 99.66| Val Acc: 61.08\n",
      "Epoch 3072: | Train Loss: 0.0033 | Val Loss: 9.4002 | Train Acc: 99.79| Val Acc: 60.87\n",
      "Epoch 3073: | Train Loss: 0.0031 | Val Loss: 9.3901 | Train Acc: 99.74| Val Acc: 60.87\n",
      "Epoch 3074: | Train Loss: 0.0029 | Val Loss: 9.3896 | Train Acc: 99.79| Val Acc: 60.96\n",
      "Epoch 3075: | Train Loss: 0.0033 | Val Loss: 9.3839 | Train Acc: 99.86| Val Acc: 60.96\n",
      "Epoch 3076: | Train Loss: 0.0035 | Val Loss: 9.4286 | Train Acc: 99.70| Val Acc: 61.16\n",
      "Epoch 3077: | Train Loss: 0.0045 | Val Loss: 9.4583 | Train Acc: 99.80| Val Acc: 60.86\n",
      "Epoch 3078: | Train Loss: 0.0041 | Val Loss: 9.3960 | Train Acc: 99.62| Val Acc: 60.86\n",
      "Epoch 3079: | Train Loss: 0.0030 | Val Loss: 9.3925 | Train Acc: 99.76| Val Acc: 60.87\n",
      "Epoch 3080: | Train Loss: 0.0030 | Val Loss: 9.4016 | Train Acc: 99.87| Val Acc: 60.97\n",
      "Epoch 3081: | Train Loss: 0.0025 | Val Loss: 9.4743 | Train Acc: 99.87| Val Acc: 60.98\n",
      "Epoch 3082: | Train Loss: 0.0026 | Val Loss: 9.4703 | Train Acc: 99.84| Val Acc: 61.07\n",
      "Epoch 3083: | Train Loss: 0.0030 | Val Loss: 9.4468 | Train Acc: 99.86| Val Acc: 61.07\n",
      "Epoch 3084: | Train Loss: 0.0027 | Val Loss: 9.4253 | Train Acc: 99.79| Val Acc: 61.27\n",
      "Epoch 3085: | Train Loss: 0.0035 | Val Loss: 9.3799 | Train Acc: 99.73| Val Acc: 60.87\n",
      "Epoch 3086: | Train Loss: 0.0051 | Val Loss: 9.2907 | Train Acc: 99.74| Val Acc: 61.09\n",
      "Epoch 3087: | Train Loss: 0.0030 | Val Loss: 9.2758 | Train Acc: 99.76| Val Acc: 60.80\n",
      "Epoch 3088: | Train Loss: 0.0047 | Val Loss: 9.3430 | Train Acc: 99.59| Val Acc: 61.19\n",
      "Epoch 3089: | Train Loss: 0.0027 | Val Loss: 9.3691 | Train Acc: 99.78| Val Acc: 60.87\n",
      "Epoch 3090: | Train Loss: 0.0046 | Val Loss: 9.3969 | Train Acc: 99.75| Val Acc: 61.07\n",
      "Epoch 3091: | Train Loss: 0.0054 | Val Loss: 9.4016 | Train Acc: 99.46| Val Acc: 60.78\n",
      "Epoch 3092: | Train Loss: 0.0026 | Val Loss: 9.4202 | Train Acc: 99.90| Val Acc: 60.68\n",
      "Epoch 3093: | Train Loss: 0.0030 | Val Loss: 9.4120 | Train Acc: 99.89| Val Acc: 60.78\n",
      "Epoch 3094: | Train Loss: 0.0032 | Val Loss: 9.4399 | Train Acc: 99.86| Val Acc: 60.67\n",
      "Epoch 3095: | Train Loss: 0.0022 | Val Loss: 9.4579 | Train Acc: 99.83| Val Acc: 60.55\n",
      "Epoch 3096: | Train Loss: 0.0034 | Val Loss: 9.5405 | Train Acc: 99.85| Val Acc: 60.65\n",
      "Epoch 3097: | Train Loss: 0.0033 | Val Loss: 9.5966 | Train Acc: 99.77| Val Acc: 60.95\n",
      "Epoch 3098: | Train Loss: 0.0040 | Val Loss: 9.5719 | Train Acc: 99.70| Val Acc: 60.75\n",
      "Epoch 3099: | Train Loss: 0.0043 | Val Loss: 9.5873 | Train Acc: 99.77| Val Acc: 60.87\n",
      "Epoch 3100: | Train Loss: 0.0042 | Val Loss: 9.6231 | Train Acc: 99.70| Val Acc: 60.88\n",
      "Epoch 3101: | Train Loss: 0.0025 | Val Loss: 9.6147 | Train Acc: 99.89| Val Acc: 60.78\n",
      "Epoch 3102: | Train Loss: 0.0038 | Val Loss: 9.6014 | Train Acc: 99.60| Val Acc: 60.88\n",
      "Epoch 3103: | Train Loss: 0.0039 | Val Loss: 9.5791 | Train Acc: 99.73| Val Acc: 60.88\n",
      "Epoch 3104: | Train Loss: 0.0040 | Val Loss: 9.5432 | Train Acc: 99.71| Val Acc: 60.78\n",
      "Epoch 3105: | Train Loss: 0.0039 | Val Loss: 9.5211 | Train Acc: 99.76| Val Acc: 60.78\n",
      "Epoch 3106: | Train Loss: 0.0024 | Val Loss: 9.4612 | Train Acc: 99.90| Val Acc: 60.56\n",
      "Epoch 3107: | Train Loss: 0.0062 | Val Loss: 9.4731 | Train Acc: 99.71| Val Acc: 60.47\n",
      "Epoch 3108: | Train Loss: 0.0035 | Val Loss: 9.4740 | Train Acc: 99.75| Val Acc: 60.57\n",
      "Epoch 3109: | Train Loss: 0.0040 | Val Loss: 9.4788 | Train Acc: 99.70| Val Acc: 60.47\n",
      "Epoch 3110: | Train Loss: 0.0029 | Val Loss: 9.4549 | Train Acc: 99.87| Val Acc: 60.46\n",
      "Epoch 3111: | Train Loss: 0.0026 | Val Loss: 9.4734 | Train Acc: 99.79| Val Acc: 60.46\n",
      "Epoch 3112: | Train Loss: 0.0038 | Val Loss: 9.4982 | Train Acc: 99.67| Val Acc: 60.55\n",
      "Epoch 3113: | Train Loss: 0.0041 | Val Loss: 9.5234 | Train Acc: 99.78| Val Acc: 60.66\n",
      "Epoch 3114: | Train Loss: 0.0039 | Val Loss: 9.4607 | Train Acc: 99.66| Val Acc: 60.55\n",
      "Epoch 3115: | Train Loss: 0.0029 | Val Loss: 9.4357 | Train Acc: 99.80| Val Acc: 60.56\n",
      "Epoch 3116: | Train Loss: 0.0029 | Val Loss: 9.4125 | Train Acc: 99.70| Val Acc: 60.55\n",
      "Epoch 3117: | Train Loss: 0.0031 | Val Loss: 9.3649 | Train Acc: 99.77| Val Acc: 60.75\n",
      "Epoch 3118: | Train Loss: 0.0028 | Val Loss: 9.3493 | Train Acc: 99.90| Val Acc: 60.76\n",
      "Epoch 3119: | Train Loss: 0.0039 | Val Loss: 9.3692 | Train Acc: 99.73| Val Acc: 60.76\n",
      "Epoch 3120: | Train Loss: 0.0039 | Val Loss: 9.3799 | Train Acc: 99.70| Val Acc: 61.27\n",
      "Epoch 3121: | Train Loss: 0.0049 | Val Loss: 9.4640 | Train Acc: 99.63| Val Acc: 61.48\n",
      "Epoch 3122: | Train Loss: 0.0033 | Val Loss: 9.4940 | Train Acc: 99.73| Val Acc: 61.67\n",
      "Epoch 3123: | Train Loss: 0.0043 | Val Loss: 9.5037 | Train Acc: 99.65| Val Acc: 61.36\n",
      "Epoch 3124: | Train Loss: 0.0032 | Val Loss: 9.5835 | Train Acc: 99.77| Val Acc: 61.27\n",
      "Epoch 3125: | Train Loss: 0.0035 | Val Loss: 9.5874 | Train Acc: 99.72| Val Acc: 61.47\n",
      "Epoch 3126: | Train Loss: 0.0029 | Val Loss: 9.5480 | Train Acc: 99.87| Val Acc: 61.57\n",
      "Epoch 3127: | Train Loss: 0.0028 | Val Loss: 9.5804 | Train Acc: 99.84| Val Acc: 61.97\n",
      "Epoch 3128: | Train Loss: 0.0042 | Val Loss: 9.5993 | Train Acc: 99.66| Val Acc: 61.67\n",
      "Epoch 3129: | Train Loss: 0.0038 | Val Loss: 9.6026 | Train Acc: 99.80| Val Acc: 61.87\n",
      "Epoch 3130: | Train Loss: 0.0039 | Val Loss: 9.5928 | Train Acc: 99.58| Val Acc: 61.67\n",
      "Epoch 3131: | Train Loss: 0.0028 | Val Loss: 9.5514 | Train Acc: 99.73| Val Acc: 61.36\n",
      "Epoch 3132: | Train Loss: 0.0031 | Val Loss: 9.5507 | Train Acc: 99.83| Val Acc: 61.66\n",
      "Epoch 3133: | Train Loss: 0.0037 | Val Loss: 9.5717 | Train Acc: 99.65| Val Acc: 61.46\n",
      "Epoch 3134: | Train Loss: 0.0032 | Val Loss: 9.6385 | Train Acc: 99.77| Val Acc: 61.76\n",
      "Epoch 3135: | Train Loss: 0.0032 | Val Loss: 9.6025 | Train Acc: 99.76| Val Acc: 61.37\n",
      "Epoch 3136: | Train Loss: 0.0032 | Val Loss: 9.5502 | Train Acc: 99.80| Val Acc: 61.48\n",
      "Epoch 3137: | Train Loss: 0.0053 | Val Loss: 9.5114 | Train Acc: 99.44| Val Acc: 61.67\n",
      "Epoch 3138: | Train Loss: 0.0040 | Val Loss: 9.5120 | Train Acc: 99.74| Val Acc: 61.67\n",
      "Epoch 3139: | Train Loss: 0.0030 | Val Loss: 9.5102 | Train Acc: 99.83| Val Acc: 61.58\n",
      "Epoch 3140: | Train Loss: 0.0027 | Val Loss: 9.5068 | Train Acc: 99.72| Val Acc: 61.48\n",
      "Epoch 3141: | Train Loss: 0.0025 | Val Loss: 9.4860 | Train Acc: 99.84| Val Acc: 61.58\n",
      "Epoch 3142: | Train Loss: 0.0039 | Val Loss: 9.4533 | Train Acc: 99.74| Val Acc: 61.46\n",
      "Epoch 3143: | Train Loss: 0.0020 | Val Loss: 9.4639 | Train Acc: 99.86| Val Acc: 61.57\n",
      "Epoch 3144: | Train Loss: 0.0037 | Val Loss: 9.4775 | Train Acc: 99.72| Val Acc: 61.57\n",
      "Epoch 3145: | Train Loss: 0.0031 | Val Loss: 9.4995 | Train Acc: 99.88| Val Acc: 61.26\n",
      "Epoch 3146: | Train Loss: 0.0029 | Val Loss: 9.5040 | Train Acc: 99.83| Val Acc: 61.15\n",
      "Epoch 3147: | Train Loss: 0.0031 | Val Loss: 9.4908 | Train Acc: 99.83| Val Acc: 61.36\n",
      "Epoch 3148: | Train Loss: 0.0024 | Val Loss: 9.4844 | Train Acc: 99.86| Val Acc: 61.16\n",
      "Epoch 3149: | Train Loss: 0.0030 | Val Loss: 9.4983 | Train Acc: 99.90| Val Acc: 61.15\n",
      "Epoch 3150: | Train Loss: 0.0028 | Val Loss: 9.4981 | Train Acc: 99.79| Val Acc: 61.15\n",
      "Epoch 3151: | Train Loss: 0.0026 | Val Loss: 9.5474 | Train Acc: 99.87| Val Acc: 61.03\n",
      "Epoch 3152: | Train Loss: 0.0025 | Val Loss: 9.5589 | Train Acc: 99.90| Val Acc: 61.36\n",
      "Epoch 3153: | Train Loss: 0.0029 | Val Loss: 9.5575 | Train Acc: 99.79| Val Acc: 61.27\n",
      "Epoch 3154: | Train Loss: 0.0029 | Val Loss: 9.5503 | Train Acc: 99.62| Val Acc: 61.17\n",
      "Epoch 3155: | Train Loss: 0.0024 | Val Loss: 9.5323 | Train Acc: 99.93| Val Acc: 61.27\n",
      "Epoch 3156: | Train Loss: 0.0031 | Val Loss: 9.5752 | Train Acc: 99.81| Val Acc: 61.27\n",
      "Epoch 3157: | Train Loss: 0.0034 | Val Loss: 9.5844 | Train Acc: 99.74| Val Acc: 61.17\n",
      "Epoch 3158: | Train Loss: 0.0037 | Val Loss: 9.6568 | Train Acc: 99.79| Val Acc: 61.27\n",
      "Epoch 3159: | Train Loss: 0.0024 | Val Loss: 9.7197 | Train Acc: 99.86| Val Acc: 60.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3160: | Train Loss: 0.0036 | Val Loss: 9.7429 | Train Acc: 99.68| Val Acc: 60.96\n",
      "Epoch 3161: | Train Loss: 0.0039 | Val Loss: 9.7092 | Train Acc: 99.77| Val Acc: 60.87\n",
      "Epoch 3162: | Train Loss: 0.0030 | Val Loss: 9.6846 | Train Acc: 99.79| Val Acc: 60.95\n",
      "Epoch 3163: | Train Loss: 0.0032 | Val Loss: 9.6113 | Train Acc: 99.71| Val Acc: 61.16\n",
      "Epoch 3164: | Train Loss: 0.0037 | Val Loss: 9.6111 | Train Acc: 99.80| Val Acc: 61.16\n",
      "Epoch 3165: | Train Loss: 0.0032 | Val Loss: 9.6093 | Train Acc: 99.79| Val Acc: 61.08\n",
      "Epoch 3166: | Train Loss: 0.0027 | Val Loss: 9.6030 | Train Acc: 99.80| Val Acc: 61.08\n",
      "Epoch 3167: | Train Loss: 0.0025 | Val Loss: 9.5646 | Train Acc: 99.87| Val Acc: 61.08\n",
      "Epoch 3168: | Train Loss: 0.0041 | Val Loss: 9.5224 | Train Acc: 99.80| Val Acc: 61.38\n",
      "Epoch 3169: | Train Loss: 0.0032 | Val Loss: 9.4938 | Train Acc: 99.62| Val Acc: 61.38\n",
      "Epoch 3170: | Train Loss: 0.0036 | Val Loss: 9.4568 | Train Acc: 99.77| Val Acc: 60.97\n",
      "Epoch 3171: | Train Loss: 0.0020 | Val Loss: 9.3835 | Train Acc: 99.93| Val Acc: 61.18\n",
      "Epoch 3172: | Train Loss: 0.0030 | Val Loss: 9.3361 | Train Acc: 99.79| Val Acc: 61.07\n",
      "Epoch 3173: | Train Loss: 0.0034 | Val Loss: 9.3618 | Train Acc: 99.84| Val Acc: 60.86\n",
      "Epoch 3174: | Train Loss: 0.0026 | Val Loss: 9.3758 | Train Acc: 99.90| Val Acc: 60.96\n",
      "Epoch 3175: | Train Loss: 0.0031 | Val Loss: 9.3589 | Train Acc: 99.80| Val Acc: 61.27\n",
      "Epoch 3176: | Train Loss: 0.0025 | Val Loss: 9.3582 | Train Acc: 99.93| Val Acc: 61.27\n",
      "Epoch 3177: | Train Loss: 0.0068 | Val Loss: 9.3410 | Train Acc: 99.87| Val Acc: 61.08\n",
      "Epoch 3178: | Train Loss: 0.0034 | Val Loss: 9.3556 | Train Acc: 99.79| Val Acc: 61.07\n",
      "Epoch 3179: | Train Loss: 0.0030 | Val Loss: 9.3200 | Train Acc: 99.70| Val Acc: 61.27\n",
      "Epoch 3180: | Train Loss: 0.0033 | Val Loss: 9.3718 | Train Acc: 99.71| Val Acc: 61.27\n",
      "Epoch 3181: | Train Loss: 0.0041 | Val Loss: 9.3869 | Train Acc: 99.68| Val Acc: 61.27\n",
      "Epoch 3182: | Train Loss: 0.0030 | Val Loss: 9.3951 | Train Acc: 99.73| Val Acc: 60.97\n",
      "Epoch 3183: | Train Loss: 0.0026 | Val Loss: 9.4024 | Train Acc: 99.69| Val Acc: 61.07\n",
      "Epoch 3184: | Train Loss: 0.0046 | Val Loss: 9.4273 | Train Acc: 99.53| Val Acc: 61.18\n",
      "Epoch 3185: | Train Loss: 0.0029 | Val Loss: 9.4776 | Train Acc: 99.74| Val Acc: 60.77\n",
      "Epoch 3186: | Train Loss: 0.0039 | Val Loss: 9.5002 | Train Acc: 99.70| Val Acc: 60.76\n",
      "Epoch 3187: | Train Loss: 0.0025 | Val Loss: 9.5008 | Train Acc: 99.77| Val Acc: 60.86\n",
      "Epoch 3188: | Train Loss: 0.0051 | Val Loss: 9.4933 | Train Acc: 99.77| Val Acc: 60.96\n",
      "Epoch 3189: | Train Loss: 0.0039 | Val Loss: 9.5299 | Train Acc: 99.74| Val Acc: 60.96\n",
      "Epoch 3190: | Train Loss: 0.0027 | Val Loss: 9.5420 | Train Acc: 99.89| Val Acc: 60.76\n",
      "Epoch 3191: | Train Loss: 0.0032 | Val Loss: 9.5365 | Train Acc: 99.76| Val Acc: 60.87\n",
      "Epoch 3192: | Train Loss: 0.0034 | Val Loss: 9.5592 | Train Acc: 99.72| Val Acc: 60.86\n",
      "Epoch 3193: | Train Loss: 0.0029 | Val Loss: 9.4892 | Train Acc: 99.87| Val Acc: 60.76\n",
      "Epoch 3194: | Train Loss: 0.0030 | Val Loss: 9.4857 | Train Acc: 99.81| Val Acc: 60.88\n",
      "Epoch 3195: | Train Loss: 0.0032 | Val Loss: 9.4204 | Train Acc: 99.64| Val Acc: 60.88\n",
      "Epoch 3196: | Train Loss: 0.0053 | Val Loss: 9.4071 | Train Acc: 99.60| Val Acc: 61.29\n",
      "Epoch 3197: | Train Loss: 0.0038 | Val Loss: 9.3402 | Train Acc: 99.80| Val Acc: 61.08\n",
      "Epoch 3198: | Train Loss: 0.0033 | Val Loss: 9.3130 | Train Acc: 99.74| Val Acc: 60.87\n",
      "Epoch 3199: | Train Loss: 0.0040 | Val Loss: 9.2790 | Train Acc: 99.60| Val Acc: 60.97\n",
      "Epoch 3200: | Train Loss: 0.0031 | Val Loss: 9.2657 | Train Acc: 99.75| Val Acc: 60.87\n",
      "Epoch 3201: | Train Loss: 0.0034 | Val Loss: 9.3323 | Train Acc: 99.73| Val Acc: 61.09\n",
      "Epoch 3202: | Train Loss: 0.0036 | Val Loss: 9.3645 | Train Acc: 99.71| Val Acc: 61.08\n",
      "Epoch 3203: | Train Loss: 0.0033 | Val Loss: 9.4209 | Train Acc: 99.75| Val Acc: 61.19\n",
      "Epoch 3204: | Train Loss: 0.0025 | Val Loss: 9.4239 | Train Acc: 99.90| Val Acc: 61.19\n",
      "Epoch 3205: | Train Loss: 0.0021 | Val Loss: 9.4280 | Train Acc: 99.89| Val Acc: 61.19\n",
      "Epoch 3206: | Train Loss: 0.0029 | Val Loss: 9.4461 | Train Acc: 99.80| Val Acc: 60.87\n",
      "Epoch 3207: | Train Loss: 0.0038 | Val Loss: 9.4551 | Train Acc: 99.76| Val Acc: 60.56\n",
      "Epoch 3208: | Train Loss: 0.0029 | Val Loss: 9.4717 | Train Acc: 99.76| Val Acc: 60.78\n",
      "Epoch 3209: | Train Loss: 0.0029 | Val Loss: 9.4747 | Train Acc: 99.79| Val Acc: 60.98\n",
      "Epoch 3210: | Train Loss: 0.0038 | Val Loss: 9.4484 | Train Acc: 99.74| Val Acc: 61.09\n",
      "Epoch 3211: | Train Loss: 0.0031 | Val Loss: 9.4721 | Train Acc: 99.79| Val Acc: 60.98\n",
      "Epoch 3212: | Train Loss: 0.0037 | Val Loss: 9.4472 | Train Acc: 99.70| Val Acc: 61.19\n",
      "Epoch 3213: | Train Loss: 0.0033 | Val Loss: 9.4430 | Train Acc: 99.80| Val Acc: 61.40\n",
      "Epoch 3214: | Train Loss: 0.0049 | Val Loss: 9.4510 | Train Acc: 99.66| Val Acc: 61.18\n",
      "Epoch 3215: | Train Loss: 0.0027 | Val Loss: 9.4024 | Train Acc: 99.79| Val Acc: 61.18\n",
      "Epoch 3216: | Train Loss: 0.0037 | Val Loss: 9.4164 | Train Acc: 99.68| Val Acc: 61.37\n",
      "Epoch 3217: | Train Loss: 0.0023 | Val Loss: 9.4326 | Train Acc: 99.87| Val Acc: 61.37\n",
      "Epoch 3218: | Train Loss: 0.0036 | Val Loss: 9.4581 | Train Acc: 99.86| Val Acc: 61.27\n",
      "Epoch 3219: | Train Loss: 0.0043 | Val Loss: 9.5142 | Train Acc: 99.71| Val Acc: 61.06\n",
      "Epoch 3220: | Train Loss: 0.0022 | Val Loss: 9.5599 | Train Acc: 99.86| Val Acc: 61.06\n",
      "Epoch 3221: | Train Loss: 0.0104 | Val Loss: 9.6168 | Train Acc: 99.73| Val Acc: 61.47\n",
      "Epoch 3222: | Train Loss: 0.0033 | Val Loss: 9.6213 | Train Acc: 99.73| Val Acc: 61.46\n",
      "Epoch 3223: | Train Loss: 0.0044 | Val Loss: 9.6029 | Train Acc: 99.70| Val Acc: 61.27\n",
      "Epoch 3224: | Train Loss: 0.0035 | Val Loss: 9.6121 | Train Acc: 99.79| Val Acc: 61.17\n",
      "Epoch 3225: | Train Loss: 0.0025 | Val Loss: 9.5837 | Train Acc: 99.87| Val Acc: 61.37\n",
      "Epoch 3226: | Train Loss: 0.0026 | Val Loss: 9.5157 | Train Acc: 99.81| Val Acc: 61.37\n",
      "Epoch 3227: | Train Loss: 0.0067 | Val Loss: 9.5763 | Train Acc: 99.67| Val Acc: 61.38\n",
      "Epoch 3228: | Train Loss: 0.0035 | Val Loss: 9.6085 | Train Acc: 99.74| Val Acc: 61.18\n",
      "Epoch 3229: | Train Loss: 0.0039 | Val Loss: 9.6193 | Train Acc: 99.48| Val Acc: 61.38\n",
      "Epoch 3230: | Train Loss: 0.0035 | Val Loss: 9.6601 | Train Acc: 99.75| Val Acc: 61.38\n",
      "Epoch 3231: | Train Loss: 0.0036 | Val Loss: 9.6285 | Train Acc: 99.67| Val Acc: 61.08\n",
      "Epoch 3232: | Train Loss: 0.0036 | Val Loss: 9.5808 | Train Acc: 99.76| Val Acc: 60.96\n",
      "Epoch 3233: | Train Loss: 0.0045 | Val Loss: 9.5691 | Train Acc: 99.62| Val Acc: 61.19\n",
      "Epoch 3234: | Train Loss: 0.0030 | Val Loss: 9.5716 | Train Acc: 99.68| Val Acc: 61.19\n",
      "Epoch 3235: | Train Loss: 0.0046 | Val Loss: 9.5582 | Train Acc: 99.71| Val Acc: 61.29\n",
      "Epoch 3236: | Train Loss: 0.0033 | Val Loss: 9.5560 | Train Acc: 99.89| Val Acc: 61.60\n",
      "Epoch 3237: | Train Loss: 0.0046 | Val Loss: 9.5260 | Train Acc: 99.77| Val Acc: 61.60\n",
      "Epoch 3238: | Train Loss: 0.0036 | Val Loss: 9.5350 | Train Acc: 99.79| Val Acc: 61.40\n",
      "Epoch 3239: | Train Loss: 0.0030 | Val Loss: 9.5418 | Train Acc: 99.75| Val Acc: 61.39\n",
      "Epoch 3240: | Train Loss: 0.0037 | Val Loss: 9.5199 | Train Acc: 99.67| Val Acc: 61.59\n",
      "Epoch 3241: | Train Loss: 0.0044 | Val Loss: 9.5975 | Train Acc: 99.60| Val Acc: 61.39\n",
      "Epoch 3242: | Train Loss: 0.0025 | Val Loss: 9.5412 | Train Acc: 99.90| Val Acc: 61.18\n",
      "Epoch 3243: | Train Loss: 0.0044 | Val Loss: 9.5782 | Train Acc: 99.59| Val Acc: 61.27\n",
      "Epoch 3244: | Train Loss: 0.0023 | Val Loss: 9.5836 | Train Acc: 99.85| Val Acc: 61.27\n",
      "Epoch 3245: | Train Loss: 0.0035 | Val Loss: 9.6094 | Train Acc: 99.75| Val Acc: 61.27\n",
      "Epoch 3246: | Train Loss: 0.0034 | Val Loss: 9.5866 | Train Acc: 99.71| Val Acc: 61.17\n",
      "Epoch 3247: | Train Loss: 0.0034 | Val Loss: 9.5837 | Train Acc: 99.71| Val Acc: 61.18\n",
      "Epoch 3248: | Train Loss: 0.0022 | Val Loss: 9.6095 | Train Acc: 99.87| Val Acc: 61.18\n",
      "Epoch 3249: | Train Loss: 0.0043 | Val Loss: 9.5816 | Train Acc: 99.78| Val Acc: 61.19\n",
      "Epoch 3250: | Train Loss: 0.0034 | Val Loss: 9.5691 | Train Acc: 99.67| Val Acc: 61.38\n",
      "Epoch 3251: | Train Loss: 0.0033 | Val Loss: 9.5907 | Train Acc: 99.76| Val Acc: 61.58\n",
      "Epoch 3252: | Train Loss: 0.0025 | Val Loss: 9.5514 | Train Acc: 99.84| Val Acc: 61.38\n",
      "Epoch 3253: | Train Loss: 0.0028 | Val Loss: 9.5605 | Train Acc: 99.73| Val Acc: 61.38\n",
      "Epoch 3254: | Train Loss: 0.0035 | Val Loss: 9.5365 | Train Acc: 99.63| Val Acc: 61.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3255: | Train Loss: 0.0040 | Val Loss: 9.5494 | Train Acc: 99.80| Val Acc: 61.48\n",
      "Epoch 3256: | Train Loss: 0.0036 | Val Loss: 9.4798 | Train Acc: 99.73| Val Acc: 61.48\n",
      "Epoch 3257: | Train Loss: 0.0024 | Val Loss: 9.5184 | Train Acc: 99.84| Val Acc: 61.58\n",
      "Epoch 3258: | Train Loss: 0.0030 | Val Loss: 9.5336 | Train Acc: 99.64| Val Acc: 61.58\n",
      "Epoch 3259: | Train Loss: 0.0029 | Val Loss: 9.5186 | Train Acc: 99.79| Val Acc: 61.48\n",
      "Epoch 3260: | Train Loss: 0.0063 | Val Loss: 9.6063 | Train Acc: 99.77| Val Acc: 61.99\n",
      "Epoch 3261: | Train Loss: 0.0026 | Val Loss: 9.6553 | Train Acc: 99.84| Val Acc: 61.80\n",
      "Epoch 3262: | Train Loss: 0.0035 | Val Loss: 9.6496 | Train Acc: 99.78| Val Acc: 61.70\n",
      "Epoch 3263: | Train Loss: 0.0029 | Val Loss: 9.6452 | Train Acc: 99.79| Val Acc: 61.49\n",
      "Epoch 3264: | Train Loss: 0.0035 | Val Loss: 9.5890 | Train Acc: 99.79| Val Acc: 61.38\n",
      "Epoch 3265: | Train Loss: 0.0027 | Val Loss: 9.5865 | Train Acc: 99.86| Val Acc: 61.17\n",
      "Epoch 3266: | Train Loss: 0.0029 | Val Loss: 9.6582 | Train Acc: 99.84| Val Acc: 61.37\n",
      "Epoch 3267: | Train Loss: 0.0033 | Val Loss: 9.6396 | Train Acc: 99.79| Val Acc: 61.27\n",
      "Epoch 3268: | Train Loss: 0.0042 | Val Loss: 9.5173 | Train Acc: 99.81| Val Acc: 61.58\n",
      "Epoch 3269: | Train Loss: 0.0027 | Val Loss: 9.4455 | Train Acc: 99.80| Val Acc: 61.68\n",
      "Epoch 3270: | Train Loss: 0.0039 | Val Loss: 9.4438 | Train Acc: 99.70| Val Acc: 61.68\n",
      "Epoch 3271: | Train Loss: 0.0035 | Val Loss: 9.4087 | Train Acc: 99.67| Val Acc: 61.69\n",
      "Epoch 3272: | Train Loss: 0.0033 | Val Loss: 9.3416 | Train Acc: 99.76| Val Acc: 61.48\n",
      "Epoch 3273: | Train Loss: 0.0029 | Val Loss: 9.3359 | Train Acc: 99.86| Val Acc: 61.57\n",
      "Epoch 3274: | Train Loss: 0.0037 | Val Loss: 9.3432 | Train Acc: 99.76| Val Acc: 61.86\n",
      "Epoch 3275: | Train Loss: 0.0054 | Val Loss: 9.3588 | Train Acc: 99.63| Val Acc: 61.57\n",
      "Epoch 3276: | Train Loss: 0.0025 | Val Loss: 9.4145 | Train Acc: 99.87| Val Acc: 61.35\n",
      "Epoch 3277: | Train Loss: 0.0061 | Val Loss: 9.4353 | Train Acc: 99.71| Val Acc: 61.36\n",
      "Epoch 3278: | Train Loss: 0.0028 | Val Loss: 9.4792 | Train Acc: 99.90| Val Acc: 61.57\n",
      "Epoch 3279: | Train Loss: 0.0076 | Val Loss: 9.4982 | Train Acc: 99.70| Val Acc: 61.36\n",
      "Epoch 3280: | Train Loss: 0.0025 | Val Loss: 9.4833 | Train Acc: 99.73| Val Acc: 61.46\n",
      "Epoch 3281: | Train Loss: 0.0039 | Val Loss: 9.4995 | Train Acc: 99.71| Val Acc: 61.36\n",
      "Epoch 3282: | Train Loss: 0.0040 | Val Loss: 9.4976 | Train Acc: 99.58| Val Acc: 61.35\n",
      "Epoch 3283: | Train Loss: 0.0031 | Val Loss: 9.4978 | Train Acc: 99.84| Val Acc: 61.46\n",
      "Epoch 3284: | Train Loss: 0.0033 | Val Loss: 9.5598 | Train Acc: 99.75| Val Acc: 61.77\n",
      "Epoch 3285: | Train Loss: 0.0050 | Val Loss: 9.5975 | Train Acc: 99.57| Val Acc: 61.36\n",
      "Epoch 3286: | Train Loss: 0.0043 | Val Loss: 9.5658 | Train Acc: 99.64| Val Acc: 61.27\n",
      "Epoch 3287: | Train Loss: 0.0044 | Val Loss: 9.5688 | Train Acc: 99.66| Val Acc: 61.15\n",
      "Epoch 3288: | Train Loss: 0.0025 | Val Loss: 9.5779 | Train Acc: 99.78| Val Acc: 61.15\n",
      "Epoch 3289: | Train Loss: 0.0047 | Val Loss: 9.5969 | Train Acc: 99.59| Val Acc: 61.16\n",
      "Epoch 3290: | Train Loss: 0.0033 | Val Loss: 9.6182 | Train Acc: 99.73| Val Acc: 61.26\n",
      "Epoch 3291: | Train Loss: 0.0044 | Val Loss: 9.6463 | Train Acc: 99.76| Val Acc: 61.57\n",
      "Epoch 3292: | Train Loss: 0.0040 | Val Loss: 9.6084 | Train Acc: 99.65| Val Acc: 61.66\n",
      "Epoch 3293: | Train Loss: 0.0034 | Val Loss: 9.5650 | Train Acc: 99.63| Val Acc: 61.56\n",
      "Epoch 3294: | Train Loss: 0.0042 | Val Loss: 9.5742 | Train Acc: 99.73| Val Acc: 61.45\n",
      "Epoch 3295: | Train Loss: 0.0041 | Val Loss: 9.5733 | Train Acc: 99.57| Val Acc: 61.27\n",
      "Epoch 3296: | Train Loss: 0.0025 | Val Loss: 9.5524 | Train Acc: 99.86| Val Acc: 61.27\n",
      "Epoch 3297: | Train Loss: 0.0040 | Val Loss: 9.5984 | Train Acc: 99.80| Val Acc: 61.27\n",
      "Epoch 3298: | Train Loss: 0.0029 | Val Loss: 9.5964 | Train Acc: 99.72| Val Acc: 61.27\n",
      "Epoch 3299: | Train Loss: 0.0040 | Val Loss: 9.6049 | Train Acc: 99.61| Val Acc: 61.27\n",
      "Epoch 3300: | Train Loss: 0.0031 | Val Loss: 9.5911 | Train Acc: 99.80| Val Acc: 61.27\n",
      "Epoch 3301: | Train Loss: 0.0026 | Val Loss: 9.5760 | Train Acc: 99.76| Val Acc: 61.38\n",
      "Epoch 3302: | Train Loss: 0.0039 | Val Loss: 9.5652 | Train Acc: 99.71| Val Acc: 61.60\n",
      "Epoch 3303: | Train Loss: 0.0036 | Val Loss: 9.5274 | Train Acc: 99.76| Val Acc: 61.59\n",
      "Epoch 3304: | Train Loss: 0.0036 | Val Loss: 9.5484 | Train Acc: 99.74| Val Acc: 60.98\n",
      "Epoch 3305: | Train Loss: 0.0023 | Val Loss: 9.5394 | Train Acc: 99.93| Val Acc: 60.98\n",
      "Epoch 3306: | Train Loss: 0.0025 | Val Loss: 9.5399 | Train Acc: 99.89| Val Acc: 60.98\n",
      "Epoch 3307: | Train Loss: 0.0045 | Val Loss: 9.5429 | Train Acc: 99.60| Val Acc: 61.18\n",
      "Epoch 3308: | Train Loss: 0.0032 | Val Loss: 9.5742 | Train Acc: 99.77| Val Acc: 61.18\n",
      "Epoch 3309: | Train Loss: 0.0033 | Val Loss: 9.5655 | Train Acc: 99.76| Val Acc: 61.39\n",
      "Epoch 3310: | Train Loss: 0.0025 | Val Loss: 9.5760 | Train Acc: 99.84| Val Acc: 61.28\n",
      "Epoch 3311: | Train Loss: 0.0038 | Val Loss: 9.5345 | Train Acc: 99.79| Val Acc: 61.48\n",
      "Epoch 3312: | Train Loss: 0.0040 | Val Loss: 9.5825 | Train Acc: 99.71| Val Acc: 60.97\n",
      "Epoch 3313: | Train Loss: 0.0034 | Val Loss: 9.6446 | Train Acc: 99.68| Val Acc: 61.17\n",
      "Epoch 3314: | Train Loss: 0.0035 | Val Loss: 9.6359 | Train Acc: 99.76| Val Acc: 61.35\n",
      "Epoch 3315: | Train Loss: 0.0038 | Val Loss: 9.6513 | Train Acc: 99.87| Val Acc: 61.56\n",
      "Epoch 3316: | Train Loss: 0.0077 | Val Loss: 9.6486 | Train Acc: 99.67| Val Acc: 61.67\n",
      "Epoch 3317: | Train Loss: 0.0034 | Val Loss: 9.6358 | Train Acc: 99.73| Val Acc: 61.35\n",
      "Epoch 3318: | Train Loss: 0.0034 | Val Loss: 9.6368 | Train Acc: 99.69| Val Acc: 61.46\n",
      "Epoch 3319: | Train Loss: 0.0023 | Val Loss: 9.5696 | Train Acc: 99.93| Val Acc: 61.17\n",
      "Epoch 3320: | Train Loss: 0.0041 | Val Loss: 9.5398 | Train Acc: 99.73| Val Acc: 61.07\n",
      "Epoch 3321: | Train Loss: 0.0042 | Val Loss: 9.5371 | Train Acc: 99.73| Val Acc: 61.06\n",
      "Epoch 3322: | Train Loss: 0.0035 | Val Loss: 9.5333 | Train Acc: 99.74| Val Acc: 61.16\n",
      "Epoch 3323: | Train Loss: 0.0027 | Val Loss: 9.5268 | Train Acc: 99.76| Val Acc: 60.98\n",
      "Epoch 3324: | Train Loss: 0.0022 | Val Loss: 9.5070 | Train Acc: 99.97| Val Acc: 61.28\n",
      "Epoch 3325: | Train Loss: 0.0049 | Val Loss: 9.4976 | Train Acc: 99.63| Val Acc: 61.08\n",
      "Epoch 3326: | Train Loss: 0.0045 | Val Loss: 9.4698 | Train Acc: 99.62| Val Acc: 61.08\n",
      "Epoch 3327: | Train Loss: 0.0024 | Val Loss: 9.4860 | Train Acc: 99.87| Val Acc: 61.27\n",
      "Epoch 3328: | Train Loss: 0.0032 | Val Loss: 9.4190 | Train Acc: 99.84| Val Acc: 61.37\n",
      "Epoch 3329: | Train Loss: 0.0039 | Val Loss: 9.3869 | Train Acc: 99.80| Val Acc: 61.37\n",
      "Epoch 3330: | Train Loss: 0.0021 | Val Loss: 9.3894 | Train Acc: 99.87| Val Acc: 61.36\n",
      "Epoch 3331: | Train Loss: 0.0034 | Val Loss: 9.3775 | Train Acc: 99.63| Val Acc: 61.27\n",
      "Epoch 3332: | Train Loss: 0.0044 | Val Loss: 9.4524 | Train Acc: 99.70| Val Acc: 61.16\n",
      "Epoch 3333: | Train Loss: 0.0037 | Val Loss: 9.4933 | Train Acc: 99.70| Val Acc: 61.16\n",
      "Epoch 3334: | Train Loss: 0.0033 | Val Loss: 9.4819 | Train Acc: 99.80| Val Acc: 61.17\n",
      "Epoch 3335: | Train Loss: 0.0031 | Val Loss: 9.4834 | Train Acc: 99.76| Val Acc: 61.27\n",
      "Epoch 3336: | Train Loss: 0.0052 | Val Loss: 9.4886 | Train Acc: 99.51| Val Acc: 61.47\n",
      "Epoch 3337: | Train Loss: 0.0024 | Val Loss: 9.5349 | Train Acc: 99.80| Val Acc: 61.68\n",
      "Epoch 3338: | Train Loss: 0.0043 | Val Loss: 9.5139 | Train Acc: 99.80| Val Acc: 61.48\n",
      "Epoch 3339: | Train Loss: 0.0023 | Val Loss: 9.4915 | Train Acc: 99.84| Val Acc: 61.58\n",
      "Epoch 3340: | Train Loss: 0.0026 | Val Loss: 9.4916 | Train Acc: 99.83| Val Acc: 61.58\n",
      "Epoch 3341: | Train Loss: 0.0047 | Val Loss: 9.4618 | Train Acc: 99.60| Val Acc: 61.47\n",
      "Epoch 3342: | Train Loss: 0.0040 | Val Loss: 9.4437 | Train Acc: 99.73| Val Acc: 61.27\n",
      "Epoch 3343: | Train Loss: 0.0029 | Val Loss: 9.4485 | Train Acc: 99.74| Val Acc: 61.38\n",
      "Epoch 3344: | Train Loss: 0.0038 | Val Loss: 9.4560 | Train Acc: 99.60| Val Acc: 61.48\n",
      "Epoch 3345: | Train Loss: 0.0028 | Val Loss: 9.4925 | Train Acc: 99.83| Val Acc: 61.27\n",
      "Epoch 3346: | Train Loss: 0.0023 | Val Loss: 9.4889 | Train Acc: 99.93| Val Acc: 61.38\n",
      "Epoch 3347: | Train Loss: 0.0027 | Val Loss: 9.4954 | Train Acc: 99.80| Val Acc: 61.48\n",
      "Epoch 3348: | Train Loss: 0.0033 | Val Loss: 9.5322 | Train Acc: 99.81| Val Acc: 61.38\n",
      "Epoch 3349: | Train Loss: 0.0032 | Val Loss: 9.5124 | Train Acc: 99.87| Val Acc: 61.47\n",
      "Epoch 3350: | Train Loss: 0.0029 | Val Loss: 9.4999 | Train Acc: 99.80| Val Acc: 61.57\n",
      "Epoch 3351: | Train Loss: 0.0033 | Val Loss: 9.4653 | Train Acc: 99.67| Val Acc: 61.67\n",
      "Epoch 3352: | Train Loss: 0.0049 | Val Loss: 9.5002 | Train Acc: 99.66| Val Acc: 61.58\n",
      "Epoch 3353: | Train Loss: 0.0023 | Val Loss: 9.4549 | Train Acc: 99.90| Val Acc: 61.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3354: | Train Loss: 0.0021 | Val Loss: 9.4284 | Train Acc: 99.93| Val Acc: 61.38\n",
      "Epoch 3355: | Train Loss: 0.0043 | Val Loss: 9.4489 | Train Acc: 99.70| Val Acc: 61.49\n",
      "Epoch 3356: | Train Loss: 0.0027 | Val Loss: 9.5422 | Train Acc: 99.76| Val Acc: 61.59\n",
      "Epoch 3357: | Train Loss: 0.0037 | Val Loss: 9.6053 | Train Acc: 99.77| Val Acc: 61.68\n",
      "Epoch 3358: | Train Loss: 0.0034 | Val Loss: 9.6170 | Train Acc: 99.78| Val Acc: 61.48\n",
      "Epoch 3359: | Train Loss: 0.0032 | Val Loss: 9.5919 | Train Acc: 99.73| Val Acc: 61.27\n",
      "Epoch 3360: | Train Loss: 0.0032 | Val Loss: 9.5524 | Train Acc: 99.84| Val Acc: 60.95\n",
      "Epoch 3361: | Train Loss: 0.0035 | Val Loss: 9.6241 | Train Acc: 99.66| Val Acc: 61.27\n",
      "Epoch 3362: | Train Loss: 0.0029 | Val Loss: 9.6148 | Train Acc: 99.77| Val Acc: 61.17\n",
      "Epoch 3363: | Train Loss: 0.0045 | Val Loss: 9.5856 | Train Acc: 99.63| Val Acc: 61.27\n",
      "Epoch 3364: | Train Loss: 0.0030 | Val Loss: 9.5549 | Train Acc: 99.79| Val Acc: 61.47\n",
      "Epoch 3365: | Train Loss: 0.0035 | Val Loss: 9.5490 | Train Acc: 99.66| Val Acc: 61.48\n",
      "Epoch 3366: | Train Loss: 0.0026 | Val Loss: 9.5433 | Train Acc: 99.80| Val Acc: 61.49\n",
      "Epoch 3367: | Train Loss: 0.0045 | Val Loss: 9.5208 | Train Acc: 99.74| Val Acc: 61.48\n",
      "Epoch 3368: | Train Loss: 0.0041 | Val Loss: 9.5004 | Train Acc: 99.70| Val Acc: 61.27\n",
      "Epoch 3369: | Train Loss: 0.0029 | Val Loss: 9.4941 | Train Acc: 99.80| Val Acc: 61.38\n",
      "Epoch 3370: | Train Loss: 0.0024 | Val Loss: 9.4852 | Train Acc: 99.77| Val Acc: 61.19\n",
      "Epoch 3371: | Train Loss: 0.0037 | Val Loss: 9.4864 | Train Acc: 99.71| Val Acc: 61.18\n",
      "Epoch 3372: | Train Loss: 0.0044 | Val Loss: 9.4675 | Train Acc: 99.66| Val Acc: 61.18\n",
      "Epoch 3373: | Train Loss: 0.0029 | Val Loss: 9.4737 | Train Acc: 99.78| Val Acc: 61.18\n",
      "Epoch 3374: | Train Loss: 0.0037 | Val Loss: 9.4616 | Train Acc: 99.71| Val Acc: 61.47\n",
      "Epoch 3375: | Train Loss: 0.0030 | Val Loss: 9.4597 | Train Acc: 99.87| Val Acc: 61.27\n",
      "Epoch 3376: | Train Loss: 0.0029 | Val Loss: 9.4463 | Train Acc: 99.75| Val Acc: 61.38\n",
      "Epoch 3377: | Train Loss: 0.0021 | Val Loss: 9.4536 | Train Acc: 99.89| Val Acc: 61.28\n",
      "Epoch 3378: | Train Loss: 0.0044 | Val Loss: 9.4434 | Train Acc: 99.54| Val Acc: 61.49\n",
      "Epoch 3379: | Train Loss: 0.0030 | Val Loss: 9.5092 | Train Acc: 99.63| Val Acc: 61.48\n",
      "Epoch 3380: | Train Loss: 0.0032 | Val Loss: 9.5163 | Train Acc: 99.68| Val Acc: 61.27\n",
      "Epoch 3381: | Train Loss: 0.0039 | Val Loss: 9.4982 | Train Acc: 99.66| Val Acc: 61.39\n",
      "Epoch 3382: | Train Loss: 0.0035 | Val Loss: 9.5122 | Train Acc: 99.73| Val Acc: 61.59\n",
      "Epoch 3383: | Train Loss: 0.0031 | Val Loss: 9.5019 | Train Acc: 99.65| Val Acc: 61.58\n",
      "Epoch 3384: | Train Loss: 0.0034 | Val Loss: 9.5292 | Train Acc: 99.59| Val Acc: 61.78\n",
      "Epoch 3385: | Train Loss: 0.0041 | Val Loss: 9.5835 | Train Acc: 99.71| Val Acc: 61.57\n",
      "Epoch 3386: | Train Loss: 0.0026 | Val Loss: 9.6563 | Train Acc: 99.87| Val Acc: 61.47\n",
      "Epoch 3387: | Train Loss: 0.0025 | Val Loss: 9.6477 | Train Acc: 99.84| Val Acc: 61.37\n",
      "Epoch 3388: | Train Loss: 0.0017 | Val Loss: 9.6750 | Train Acc: 99.89| Val Acc: 61.38\n",
      "Epoch 3389: | Train Loss: 0.0027 | Val Loss: 9.6500 | Train Acc: 99.80| Val Acc: 61.59\n",
      "Epoch 3390: | Train Loss: 0.0021 | Val Loss: 9.6335 | Train Acc: 99.85| Val Acc: 61.48\n",
      "Epoch 3391: | Train Loss: 0.0031 | Val Loss: 9.5444 | Train Acc: 99.84| Val Acc: 61.68\n",
      "Epoch 3392: | Train Loss: 0.0039 | Val Loss: 9.5276 | Train Acc: 99.74| Val Acc: 61.88\n",
      "Epoch 3393: | Train Loss: 0.0020 | Val Loss: 9.4695 | Train Acc: 99.84| Val Acc: 61.78\n",
      "Epoch 3394: | Train Loss: 0.0039 | Val Loss: 9.4433 | Train Acc: 99.65| Val Acc: 61.69\n",
      "Epoch 3395: | Train Loss: 0.0028 | Val Loss: 9.5189 | Train Acc: 99.83| Val Acc: 61.90\n",
      "Epoch 3396: | Train Loss: 0.0036 | Val Loss: 9.5197 | Train Acc: 99.76| Val Acc: 61.59\n",
      "Epoch 3397: | Train Loss: 0.0030 | Val Loss: 9.5296 | Train Acc: 99.79| Val Acc: 61.70\n",
      "Epoch 3398: | Train Loss: 0.0032 | Val Loss: 9.5216 | Train Acc: 99.80| Val Acc: 61.91\n",
      "Epoch 3399: | Train Loss: 0.0037 | Val Loss: 9.4855 | Train Acc: 99.70| Val Acc: 61.79\n",
      "Epoch 3400: | Train Loss: 0.0025 | Val Loss: 9.4664 | Train Acc: 99.80| Val Acc: 61.99\n",
      "Epoch 3401: | Train Loss: 0.0024 | Val Loss: 9.4745 | Train Acc: 99.80| Val Acc: 61.78\n",
      "Epoch 3402: | Train Loss: 0.0029 | Val Loss: 9.4829 | Train Acc: 99.80| Val Acc: 61.89\n",
      "Epoch 3403: | Train Loss: 0.0036 | Val Loss: 9.4659 | Train Acc: 99.67| Val Acc: 61.68\n",
      "Epoch 3404: | Train Loss: 0.0027 | Val Loss: 9.4816 | Train Acc: 99.71| Val Acc: 61.79\n",
      "Epoch 3405: | Train Loss: 0.0044 | Val Loss: 9.4727 | Train Acc: 99.62| Val Acc: 61.88\n",
      "Epoch 3406: | Train Loss: 0.0030 | Val Loss: 9.4800 | Train Acc: 99.77| Val Acc: 61.68\n",
      "Epoch 3407: | Train Loss: 0.0029 | Val Loss: 9.5059 | Train Acc: 99.80| Val Acc: 61.48\n",
      "Epoch 3408: | Train Loss: 0.0035 | Val Loss: 9.5255 | Train Acc: 99.74| Val Acc: 61.58\n",
      "Epoch 3409: | Train Loss: 0.0025 | Val Loss: 9.5349 | Train Acc: 99.87| Val Acc: 61.68\n",
      "Epoch 3410: | Train Loss: 0.0030 | Val Loss: 9.5190 | Train Acc: 99.74| Val Acc: 61.78\n",
      "Epoch 3411: | Train Loss: 0.0036 | Val Loss: 9.5361 | Train Acc: 99.79| Val Acc: 61.58\n",
      "Epoch 3412: | Train Loss: 0.0022 | Val Loss: 9.5209 | Train Acc: 99.84| Val Acc: 61.77\n",
      "Epoch 3413: | Train Loss: 0.0031 | Val Loss: 9.5533 | Train Acc: 99.75| Val Acc: 61.77\n",
      "Epoch 3414: | Train Loss: 0.0028 | Val Loss: 9.5577 | Train Acc: 99.74| Val Acc: 61.58\n",
      "Epoch 3415: | Train Loss: 0.0026 | Val Loss: 9.5558 | Train Acc: 99.79| Val Acc: 61.68\n",
      "Epoch 3416: | Train Loss: 0.0030 | Val Loss: 9.5051 | Train Acc: 99.79| Val Acc: 61.58\n",
      "Epoch 3417: | Train Loss: 0.0035 | Val Loss: 9.5187 | Train Acc: 99.75| Val Acc: 61.58\n",
      "Epoch 3418: | Train Loss: 0.0027 | Val Loss: 9.5254 | Train Acc: 99.74| Val Acc: 61.58\n",
      "Epoch 3419: | Train Loss: 0.0046 | Val Loss: 9.4904 | Train Acc: 99.60| Val Acc: 61.38\n",
      "Epoch 3420: | Train Loss: 0.0026 | Val Loss: 9.4564 | Train Acc: 99.86| Val Acc: 61.48\n",
      "Epoch 3421: | Train Loss: 0.0040 | Val Loss: 9.4044 | Train Acc: 99.79| Val Acc: 61.29\n",
      "Epoch 3422: | Train Loss: 0.0031 | Val Loss: 9.3820 | Train Acc: 99.74| Val Acc: 61.49\n",
      "Epoch 3423: | Train Loss: 0.0020 | Val Loss: 9.4073 | Train Acc: 99.74| Val Acc: 61.19\n",
      "Epoch 3424: | Train Loss: 0.0021 | Val Loss: 9.4369 | Train Acc: 99.97| Val Acc: 61.28\n",
      "Epoch 3425: | Train Loss: 0.0032 | Val Loss: 9.3942 | Train Acc: 99.64| Val Acc: 61.38\n",
      "Epoch 3426: | Train Loss: 0.0031 | Val Loss: 9.3942 | Train Acc: 99.80| Val Acc: 61.26\n",
      "Epoch 3427: | Train Loss: 0.0027 | Val Loss: 9.3734 | Train Acc: 99.70| Val Acc: 61.16\n",
      "Epoch 3428: | Train Loss: 0.0025 | Val Loss: 9.3655 | Train Acc: 99.90| Val Acc: 61.47\n",
      "Epoch 3429: | Train Loss: 0.0041 | Val Loss: 9.3846 | Train Acc: 99.71| Val Acc: 61.16\n",
      "Epoch 3430: | Train Loss: 0.0033 | Val Loss: 9.4149 | Train Acc: 99.77| Val Acc: 61.46\n",
      "Epoch 3431: | Train Loss: 0.0040 | Val Loss: 9.4090 | Train Acc: 99.76| Val Acc: 61.68\n",
      "Epoch 3432: | Train Loss: 0.0052 | Val Loss: 9.4068 | Train Acc: 99.55| Val Acc: 61.59\n",
      "Epoch 3433: | Train Loss: 0.0032 | Val Loss: 9.4418 | Train Acc: 99.72| Val Acc: 61.48\n",
      "Epoch 3434: | Train Loss: 0.0035 | Val Loss: 9.4925 | Train Acc: 99.87| Val Acc: 61.58\n",
      "Epoch 3435: | Train Loss: 0.0033 | Val Loss: 9.4634 | Train Acc: 99.76| Val Acc: 61.08\n",
      "Epoch 3436: | Train Loss: 0.0028 | Val Loss: 9.4832 | Train Acc: 99.77| Val Acc: 61.48\n",
      "Epoch 3437: | Train Loss: 0.0028 | Val Loss: 9.4742 | Train Acc: 99.84| Val Acc: 61.68\n",
      "Epoch 3438: | Train Loss: 0.0025 | Val Loss: 9.4979 | Train Acc: 99.80| Val Acc: 61.59\n",
      "Epoch 3439: | Train Loss: 0.0027 | Val Loss: 9.4988 | Train Acc: 99.76| Val Acc: 61.38\n",
      "Epoch 3440: | Train Loss: 0.0039 | Val Loss: 9.5140 | Train Acc: 99.86| Val Acc: 61.38\n",
      "Epoch 3441: | Train Loss: 0.0041 | Val Loss: 9.5362 | Train Acc: 99.77| Val Acc: 61.48\n",
      "Epoch 3442: | Train Loss: 0.0028 | Val Loss: 9.5613 | Train Acc: 99.80| Val Acc: 61.48\n",
      "Epoch 3443: | Train Loss: 0.0026 | Val Loss: 9.6149 | Train Acc: 99.80| Val Acc: 61.58\n",
      "Epoch 3444: | Train Loss: 0.0022 | Val Loss: 9.6602 | Train Acc: 99.87| Val Acc: 61.27\n",
      "Epoch 3445: | Train Loss: 0.0034 | Val Loss: 9.6627 | Train Acc: 99.78| Val Acc: 61.27\n",
      "Epoch 3446: | Train Loss: 0.0028 | Val Loss: 9.7002 | Train Acc: 99.79| Val Acc: 61.37\n",
      "Epoch 3447: | Train Loss: 0.0026 | Val Loss: 9.6801 | Train Acc: 99.86| Val Acc: 61.37\n",
      "Epoch 3448: | Train Loss: 0.0031 | Val Loss: 9.6775 | Train Acc: 99.71| Val Acc: 61.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3449: | Train Loss: 0.0029 | Val Loss: 9.6858 | Train Acc: 99.86| Val Acc: 61.47\n",
      "Epoch 3450: | Train Loss: 0.0026 | Val Loss: 9.7240 | Train Acc: 99.84| Val Acc: 61.46\n",
      "Epoch 3451: | Train Loss: 0.0029 | Val Loss: 9.6742 | Train Acc: 99.77| Val Acc: 61.35\n",
      "Epoch 3452: | Train Loss: 0.0025 | Val Loss: 9.6316 | Train Acc: 99.93| Val Acc: 61.16\n",
      "Epoch 3453: | Train Loss: 0.0029 | Val Loss: 9.6547 | Train Acc: 99.79| Val Acc: 61.16\n",
      "Epoch 3454: | Train Loss: 0.0024 | Val Loss: 9.6359 | Train Acc: 99.83| Val Acc: 61.16\n",
      "Epoch 3455: | Train Loss: 0.0032 | Val Loss: 9.6894 | Train Acc: 99.79| Val Acc: 61.26\n",
      "Epoch 3456: | Train Loss: 0.0036 | Val Loss: 9.6920 | Train Acc: 99.77| Val Acc: 61.46\n",
      "Epoch 3457: | Train Loss: 0.0020 | Val Loss: 9.6638 | Train Acc: 99.90| Val Acc: 61.46\n",
      "Epoch 3458: | Train Loss: 0.0034 | Val Loss: 9.6498 | Train Acc: 99.84| Val Acc: 61.16\n",
      "Epoch 3459: | Train Loss: 0.0034 | Val Loss: 9.6359 | Train Acc: 99.67| Val Acc: 61.27\n",
      "Epoch 3460: | Train Loss: 0.0028 | Val Loss: 9.6702 | Train Acc: 99.80| Val Acc: 61.27\n",
      "Epoch 3461: | Train Loss: 0.0033 | Val Loss: 9.6824 | Train Acc: 99.76| Val Acc: 61.48\n",
      "Epoch 3462: | Train Loss: 0.0041 | Val Loss: 9.6740 | Train Acc: 99.59| Val Acc: 61.58\n",
      "Epoch 3463: | Train Loss: 0.0030 | Val Loss: 9.6488 | Train Acc: 99.70| Val Acc: 61.37\n",
      "Epoch 3464: | Train Loss: 0.0034 | Val Loss: 9.6180 | Train Acc: 99.74| Val Acc: 61.27\n",
      "Epoch 3465: | Train Loss: 0.0031 | Val Loss: 9.6235 | Train Acc: 99.83| Val Acc: 61.37\n",
      "Epoch 3466: | Train Loss: 0.0037 | Val Loss: 9.6369 | Train Acc: 99.71| Val Acc: 61.48\n",
      "Epoch 3467: | Train Loss: 0.0019 | Val Loss: 9.6260 | Train Acc: 99.89| Val Acc: 61.58\n",
      "Epoch 3468: | Train Loss: 0.0019 | Val Loss: 9.6105 | Train Acc: 99.87| Val Acc: 61.68\n",
      "Epoch 3469: | Train Loss: 0.0024 | Val Loss: 9.6198 | Train Acc: 99.90| Val Acc: 61.68\n",
      "Epoch 3470: | Train Loss: 0.0015 | Val Loss: 9.5721 | Train Acc: 99.93| Val Acc: 61.48\n",
      "Epoch 3471: | Train Loss: 0.0029 | Val Loss: 9.5726 | Train Acc: 99.86| Val Acc: 61.37\n",
      "Epoch 3472: | Train Loss: 0.0023 | Val Loss: 9.6174 | Train Acc: 99.77| Val Acc: 61.69\n",
      "Epoch 3473: | Train Loss: 0.0032 | Val Loss: 9.6477 | Train Acc: 99.66| Val Acc: 61.60\n",
      "Epoch 3474: | Train Loss: 0.0032 | Val Loss: 9.6794 | Train Acc: 99.80| Val Acc: 61.69\n",
      "Epoch 3475: | Train Loss: 0.0021 | Val Loss: 9.6740 | Train Acc: 99.86| Val Acc: 61.69\n",
      "Epoch 3476: | Train Loss: 0.0021 | Val Loss: 9.6538 | Train Acc: 99.83| Val Acc: 61.89\n",
      "Epoch 3477: | Train Loss: 0.0024 | Val Loss: 9.6060 | Train Acc: 99.84| Val Acc: 61.78\n",
      "Epoch 3478: | Train Loss: 0.0050 | Val Loss: 9.5502 | Train Acc: 99.66| Val Acc: 61.57\n",
      "Epoch 3479: | Train Loss: 0.0051 | Val Loss: 9.5228 | Train Acc: 99.77| Val Acc: 61.67\n",
      "Epoch 3480: | Train Loss: 0.0038 | Val Loss: 9.5329 | Train Acc: 99.64| Val Acc: 61.67\n",
      "Epoch 3481: | Train Loss: 0.0034 | Val Loss: 9.5572 | Train Acc: 99.84| Val Acc: 61.88\n",
      "Epoch 3482: | Train Loss: 0.0034 | Val Loss: 9.5599 | Train Acc: 99.67| Val Acc: 61.78\n",
      "Epoch 3483: | Train Loss: 0.0036 | Val Loss: 9.5903 | Train Acc: 99.87| Val Acc: 61.78\n",
      "Epoch 3484: | Train Loss: 0.0033 | Val Loss: 9.6350 | Train Acc: 99.77| Val Acc: 61.77\n",
      "Epoch 3485: | Train Loss: 0.0023 | Val Loss: 9.6084 | Train Acc: 99.81| Val Acc: 61.77\n",
      "Epoch 3486: | Train Loss: 0.0029 | Val Loss: 9.5462 | Train Acc: 99.84| Val Acc: 61.97\n",
      "Epoch 3487: | Train Loss: 0.0023 | Val Loss: 9.5798 | Train Acc: 99.83| Val Acc: 61.67\n",
      "Epoch 3488: | Train Loss: 0.0040 | Val Loss: 9.6310 | Train Acc: 99.63| Val Acc: 61.58\n",
      "Epoch 3489: | Train Loss: 0.0037 | Val Loss: 9.6535 | Train Acc: 99.61| Val Acc: 61.59\n",
      "Epoch 3490: | Train Loss: 0.0028 | Val Loss: 9.6621 | Train Acc: 99.83| Val Acc: 61.38\n",
      "Epoch 3491: | Train Loss: 0.0037 | Val Loss: 9.6839 | Train Acc: 99.72| Val Acc: 61.27\n",
      "Epoch 3492: | Train Loss: 0.0027 | Val Loss: 9.6973 | Train Acc: 99.85| Val Acc: 61.36\n",
      "Epoch 3493: | Train Loss: 0.0029 | Val Loss: 9.6831 | Train Acc: 99.79| Val Acc: 61.27\n",
      "Epoch 3494: | Train Loss: 0.0044 | Val Loss: 9.6927 | Train Acc: 99.72| Val Acc: 61.36\n",
      "Epoch 3495: | Train Loss: 0.0023 | Val Loss: 9.6701 | Train Acc: 99.84| Val Acc: 61.57\n",
      "Epoch 3496: | Train Loss: 0.0044 | Val Loss: 9.6335 | Train Acc: 99.73| Val Acc: 61.48\n",
      "Epoch 3497: | Train Loss: 0.0037 | Val Loss: 9.6255 | Train Acc: 99.79| Val Acc: 61.37\n",
      "Epoch 3498: | Train Loss: 0.0036 | Val Loss: 9.6555 | Train Acc: 99.67| Val Acc: 61.07\n",
      "Epoch 3499: | Train Loss: 0.0031 | Val Loss: 9.6499 | Train Acc: 99.80| Val Acc: 60.95\n",
      "Epoch 3500: | Train Loss: 0.0035 | Val Loss: 9.6609 | Train Acc: 99.77| Val Acc: 61.16\n",
      "Epoch 3501: | Train Loss: 0.0026 | Val Loss: 9.6233 | Train Acc: 99.77| Val Acc: 61.26\n",
      "Epoch 3502: | Train Loss: 0.0025 | Val Loss: 9.6461 | Train Acc: 99.84| Val Acc: 61.15\n",
      "Epoch 3503: | Train Loss: 0.0045 | Val Loss: 9.6479 | Train Acc: 99.75| Val Acc: 61.27\n",
      "Epoch 3504: | Train Loss: 0.0026 | Val Loss: 9.6243 | Train Acc: 99.90| Val Acc: 61.27\n",
      "Epoch 3505: | Train Loss: 0.0033 | Val Loss: 9.6064 | Train Acc: 99.76| Val Acc: 60.95\n",
      "Epoch 3506: | Train Loss: 0.0022 | Val Loss: 9.6421 | Train Acc: 99.87| Val Acc: 60.86\n",
      "Epoch 3507: | Train Loss: 0.0021 | Val Loss: 9.6302 | Train Acc: 99.87| Val Acc: 60.87\n",
      "Epoch 3508: | Train Loss: 0.0042 | Val Loss: 9.6547 | Train Acc: 99.65| Val Acc: 60.98\n",
      "Epoch 3509: | Train Loss: 0.0040 | Val Loss: 9.6551 | Train Acc: 99.66| Val Acc: 61.18\n",
      "Epoch 3510: | Train Loss: 0.0031 | Val Loss: 9.6902 | Train Acc: 99.65| Val Acc: 61.47\n",
      "Epoch 3511: | Train Loss: 0.0034 | Val Loss: 9.6759 | Train Acc: 99.83| Val Acc: 61.07\n",
      "Epoch 3512: | Train Loss: 0.0036 | Val Loss: 9.6747 | Train Acc: 99.81| Val Acc: 61.17\n",
      "Epoch 3513: | Train Loss: 0.0023 | Val Loss: 9.6262 | Train Acc: 99.77| Val Acc: 61.17\n",
      "Epoch 3514: | Train Loss: 0.0040 | Val Loss: 9.6415 | Train Acc: 99.65| Val Acc: 61.27\n",
      "Epoch 3515: | Train Loss: 0.0018 | Val Loss: 9.6805 | Train Acc: 100.00| Val Acc: 61.06\n",
      "Epoch 3516: | Train Loss: 0.0034 | Val Loss: 9.6759 | Train Acc: 99.83| Val Acc: 60.96\n",
      "Epoch 3517: | Train Loss: 0.0033 | Val Loss: 9.6766 | Train Acc: 99.67| Val Acc: 61.27\n",
      "Epoch 3518: | Train Loss: 0.0023 | Val Loss: 9.6212 | Train Acc: 99.84| Val Acc: 61.17\n",
      "Epoch 3519: | Train Loss: 0.0032 | Val Loss: 9.6452 | Train Acc: 99.73| Val Acc: 61.17\n",
      "Epoch 3520: | Train Loss: 0.0031 | Val Loss: 9.6637 | Train Acc: 99.74| Val Acc: 61.36\n",
      "Epoch 3521: | Train Loss: 0.0043 | Val Loss: 9.6582 | Train Acc: 99.70| Val Acc: 61.47\n",
      "Epoch 3522: | Train Loss: 0.0038 | Val Loss: 9.6463 | Train Acc: 99.78| Val Acc: 61.48\n",
      "Epoch 3523: | Train Loss: 0.0030 | Val Loss: 9.6393 | Train Acc: 99.83| Val Acc: 61.58\n",
      "Epoch 3524: | Train Loss: 0.0024 | Val Loss: 9.5996 | Train Acc: 99.84| Val Acc: 61.58\n",
      "Epoch 3525: | Train Loss: 0.0034 | Val Loss: 9.5841 | Train Acc: 99.64| Val Acc: 61.48\n",
      "Epoch 3526: | Train Loss: 0.0034 | Val Loss: 9.6175 | Train Acc: 99.73| Val Acc: 61.48\n",
      "Epoch 3527: | Train Loss: 0.0029 | Val Loss: 9.6454 | Train Acc: 99.93| Val Acc: 61.27\n",
      "Epoch 3528: | Train Loss: 0.0029 | Val Loss: 9.6390 | Train Acc: 99.79| Val Acc: 61.37\n",
      "Epoch 3529: | Train Loss: 0.0030 | Val Loss: 9.6715 | Train Acc: 99.77| Val Acc: 61.57\n",
      "Epoch 3530: | Train Loss: 0.0026 | Val Loss: 9.6083 | Train Acc: 99.87| Val Acc: 61.46\n",
      "Epoch 3531: | Train Loss: 0.0026 | Val Loss: 9.6110 | Train Acc: 99.77| Val Acc: 61.25\n",
      "Epoch 3532: | Train Loss: 0.0019 | Val Loss: 9.5795 | Train Acc: 99.87| Val Acc: 61.25\n",
      "Epoch 3533: | Train Loss: 0.0026 | Val Loss: 9.5535 | Train Acc: 99.70| Val Acc: 61.05\n",
      "Epoch 3534: | Train Loss: 0.0026 | Val Loss: 9.5587 | Train Acc: 99.76| Val Acc: 60.97\n",
      "Epoch 3535: | Train Loss: 0.0022 | Val Loss: 9.5781 | Train Acc: 99.83| Val Acc: 60.87\n",
      "Epoch 3536: | Train Loss: 0.0035 | Val Loss: 9.5403 | Train Acc: 99.76| Val Acc: 61.08\n",
      "Epoch 3537: | Train Loss: 0.0025 | Val Loss: 9.5376 | Train Acc: 99.84| Val Acc: 61.08\n",
      "Epoch 3538: | Train Loss: 0.0021 | Val Loss: 9.5540 | Train Acc: 99.84| Val Acc: 60.97\n",
      "Epoch 3539: | Train Loss: 0.0030 | Val Loss: 9.5540 | Train Acc: 99.68| Val Acc: 60.97\n",
      "Epoch 3540: | Train Loss: 0.0041 | Val Loss: 9.6419 | Train Acc: 99.84| Val Acc: 61.18\n",
      "Epoch 3541: | Train Loss: 0.0024 | Val Loss: 9.7014 | Train Acc: 99.84| Val Acc: 61.27\n",
      "Epoch 3542: | Train Loss: 0.0027 | Val Loss: 9.6864 | Train Acc: 99.83| Val Acc: 61.27\n",
      "Epoch 3543: | Train Loss: 0.0040 | Val Loss: 9.6585 | Train Acc: 99.53| Val Acc: 61.38\n",
      "Epoch 3544: | Train Loss: 0.0063 | Val Loss: 9.5785 | Train Acc: 99.72| Val Acc: 61.07\n",
      "Epoch 3545: | Train Loss: 0.0024 | Val Loss: 9.4983 | Train Acc: 99.81| Val Acc: 61.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3546: | Train Loss: 0.0039 | Val Loss: 9.4824 | Train Acc: 99.63| Val Acc: 61.17\n",
      "Epoch 3547: | Train Loss: 0.0035 | Val Loss: 9.4162 | Train Acc: 99.68| Val Acc: 61.07\n",
      "Epoch 3548: | Train Loss: 0.0032 | Val Loss: 9.3978 | Train Acc: 99.79| Val Acc: 60.97\n",
      "Epoch 3549: | Train Loss: 0.0020 | Val Loss: 9.4569 | Train Acc: 99.84| Val Acc: 61.07\n",
      "Epoch 3550: | Train Loss: 0.0022 | Val Loss: 9.4619 | Train Acc: 99.90| Val Acc: 61.17\n",
      "Epoch 3551: | Train Loss: 0.0038 | Val Loss: 9.4298 | Train Acc: 99.71| Val Acc: 61.07\n",
      "Epoch 3552: | Train Loss: 0.0039 | Val Loss: 9.4341 | Train Acc: 99.70| Val Acc: 60.96\n",
      "Epoch 3553: | Train Loss: 0.0043 | Val Loss: 9.4758 | Train Acc: 99.84| Val Acc: 61.07\n",
      "Epoch 3554: | Train Loss: 0.0050 | Val Loss: 9.5053 | Train Acc: 99.60| Val Acc: 61.27\n",
      "Epoch 3555: | Train Loss: 0.0028 | Val Loss: 9.4747 | Train Acc: 99.80| Val Acc: 61.27\n",
      "Epoch 3556: | Train Loss: 0.0047 | Val Loss: 9.5559 | Train Acc: 99.75| Val Acc: 61.17\n",
      "Epoch 3557: | Train Loss: 0.0026 | Val Loss: 9.5514 | Train Acc: 99.90| Val Acc: 61.27\n",
      "Epoch 3558: | Train Loss: 0.0024 | Val Loss: 9.5442 | Train Acc: 99.84| Val Acc: 61.37\n",
      "Epoch 3559: | Train Loss: 0.0033 | Val Loss: 9.5481 | Train Acc: 99.87| Val Acc: 61.37\n",
      "Epoch 3560: | Train Loss: 0.0023 | Val Loss: 9.5261 | Train Acc: 99.87| Val Acc: 61.36\n",
      "Epoch 3561: | Train Loss: 0.0038 | Val Loss: 9.4760 | Train Acc: 99.67| Val Acc: 61.17\n",
      "Epoch 3562: | Train Loss: 0.0031 | Val Loss: 9.4781 | Train Acc: 99.68| Val Acc: 61.17\n",
      "Epoch 3563: | Train Loss: 0.0028 | Val Loss: 9.4765 | Train Acc: 99.72| Val Acc: 61.05\n",
      "Epoch 3564: | Train Loss: 0.0030 | Val Loss: 9.4803 | Train Acc: 99.66| Val Acc: 61.16\n",
      "Epoch 3565: | Train Loss: 0.0020 | Val Loss: 9.4674 | Train Acc: 99.86| Val Acc: 61.17\n",
      "Epoch 3566: | Train Loss: 0.0032 | Val Loss: 9.4528 | Train Acc: 99.70| Val Acc: 61.17\n",
      "Epoch 3567: | Train Loss: 0.0028 | Val Loss: 9.4566 | Train Acc: 99.74| Val Acc: 61.17\n",
      "Epoch 3568: | Train Loss: 0.0025 | Val Loss: 9.4837 | Train Acc: 99.86| Val Acc: 61.08\n",
      "Epoch 3569: | Train Loss: 0.0023 | Val Loss: 9.5200 | Train Acc: 99.87| Val Acc: 60.77\n",
      "Epoch 3570: | Train Loss: 0.0029 | Val Loss: 9.5198 | Train Acc: 99.84| Val Acc: 60.77\n",
      "Epoch 3571: | Train Loss: 0.0034 | Val Loss: 9.5649 | Train Acc: 99.77| Val Acc: 61.07\n",
      "Epoch 3572: | Train Loss: 0.0028 | Val Loss: 9.5834 | Train Acc: 99.86| Val Acc: 61.18\n",
      "Epoch 3573: | Train Loss: 0.0029 | Val Loss: 9.5907 | Train Acc: 99.90| Val Acc: 60.87\n",
      "Epoch 3574: | Train Loss: 0.0034 | Val Loss: 9.5781 | Train Acc: 99.81| Val Acc: 60.88\n",
      "Epoch 3575: | Train Loss: 0.0030 | Val Loss: 9.5595 | Train Acc: 99.74| Val Acc: 61.38\n",
      "Epoch 3576: | Train Loss: 0.0020 | Val Loss: 9.5397 | Train Acc: 99.90| Val Acc: 61.37\n",
      "Epoch 3577: | Train Loss: 0.0031 | Val Loss: 9.5043 | Train Acc: 99.66| Val Acc: 61.18\n",
      "Epoch 3578: | Train Loss: 0.0027 | Val Loss: 9.5003 | Train Acc: 99.86| Val Acc: 61.17\n",
      "Epoch 3579: | Train Loss: 0.0032 | Val Loss: 9.5355 | Train Acc: 99.73| Val Acc: 61.16\n",
      "Epoch 3580: | Train Loss: 0.0024 | Val Loss: 9.5684 | Train Acc: 99.79| Val Acc: 61.16\n",
      "Epoch 3581: | Train Loss: 0.0035 | Val Loss: 9.6182 | Train Acc: 99.86| Val Acc: 61.17\n",
      "Epoch 3582: | Train Loss: 0.0031 | Val Loss: 9.6084 | Train Acc: 99.92| Val Acc: 61.17\n",
      "Epoch 3583: | Train Loss: 0.0024 | Val Loss: 9.6136 | Train Acc: 99.72| Val Acc: 61.16\n",
      "Epoch 3584: | Train Loss: 0.0031 | Val Loss: 9.5954 | Train Acc: 99.76| Val Acc: 61.27\n",
      "Epoch 3585: | Train Loss: 0.0025 | Val Loss: 9.5450 | Train Acc: 99.89| Val Acc: 60.68\n",
      "Epoch 3586: | Train Loss: 0.0035 | Val Loss: 9.5513 | Train Acc: 99.65| Val Acc: 60.68\n",
      "Epoch 3587: | Train Loss: 0.0026 | Val Loss: 9.5388 | Train Acc: 99.83| Val Acc: 60.88\n",
      "Epoch 3588: | Train Loss: 0.0045 | Val Loss: 9.5279 | Train Acc: 99.70| Val Acc: 60.98\n",
      "Epoch 3589: | Train Loss: 0.0041 | Val Loss: 9.5141 | Train Acc: 99.74| Val Acc: 61.17\n",
      "Epoch 3590: | Train Loss: 0.0017 | Val Loss: 9.4846 | Train Acc: 99.93| Val Acc: 61.27\n",
      "Epoch 3591: | Train Loss: 0.0032 | Val Loss: 9.4189 | Train Acc: 99.70| Val Acc: 61.38\n",
      "Epoch 3592: | Train Loss: 0.0027 | Val Loss: 9.4263 | Train Acc: 99.93| Val Acc: 61.38\n",
      "Epoch 3593: | Train Loss: 0.0037 | Val Loss: 9.3560 | Train Acc: 99.80| Val Acc: 61.19\n",
      "Epoch 3594: | Train Loss: 0.0033 | Val Loss: 9.3696 | Train Acc: 99.79| Val Acc: 60.79\n",
      "Epoch 3595: | Train Loss: 0.0035 | Val Loss: 9.3490 | Train Acc: 99.71| Val Acc: 60.78\n",
      "Epoch 3596: | Train Loss: 0.0019 | Val Loss: 9.3680 | Train Acc: 99.86| Val Acc: 60.57\n",
      "Epoch 3597: | Train Loss: 0.0038 | Val Loss: 9.4047 | Train Acc: 99.61| Val Acc: 60.66\n",
      "Epoch 3598: | Train Loss: 0.0040 | Val Loss: 9.4115 | Train Acc: 99.78| Val Acc: 60.87\n",
      "Epoch 3599: | Train Loss: 0.0020 | Val Loss: 9.4344 | Train Acc: 99.86| Val Acc: 60.77\n",
      "Epoch 3600: | Train Loss: 0.0032 | Val Loss: 9.4546 | Train Acc: 99.78| Val Acc: 60.67\n",
      "Epoch 3601: | Train Loss: 0.0043 | Val Loss: 9.5127 | Train Acc: 99.79| Val Acc: 61.07\n",
      "Epoch 3602: | Train Loss: 0.0052 | Val Loss: 9.5380 | Train Acc: 99.62| Val Acc: 61.05\n",
      "Epoch 3603: | Train Loss: 0.0022 | Val Loss: 9.5171 | Train Acc: 99.90| Val Acc: 61.16\n",
      "Epoch 3604: | Train Loss: 0.0043 | Val Loss: 9.4995 | Train Acc: 99.51| Val Acc: 61.06\n",
      "Epoch 3605: | Train Loss: 0.0032 | Val Loss: 9.4349 | Train Acc: 99.77| Val Acc: 61.06\n",
      "Epoch 3606: | Train Loss: 0.0038 | Val Loss: 9.4612 | Train Acc: 99.83| Val Acc: 61.18\n",
      "Epoch 3607: | Train Loss: 0.0026 | Val Loss: 9.4681 | Train Acc: 99.86| Val Acc: 60.98\n",
      "Epoch 3608: | Train Loss: 0.0040 | Val Loss: 9.4613 | Train Acc: 99.83| Val Acc: 61.19\n",
      "Epoch 3609: | Train Loss: 0.0037 | Val Loss: 9.4743 | Train Acc: 99.84| Val Acc: 60.98\n",
      "Epoch 3610: | Train Loss: 0.0030 | Val Loss: 9.4732 | Train Acc: 99.84| Val Acc: 61.09\n",
      "Epoch 3611: | Train Loss: 0.0043 | Val Loss: 9.4807 | Train Acc: 99.70| Val Acc: 61.09\n",
      "Epoch 3612: | Train Loss: 0.0023 | Val Loss: 9.5282 | Train Acc: 99.87| Val Acc: 60.87\n",
      "Epoch 3613: | Train Loss: 0.0024 | Val Loss: 9.5696 | Train Acc: 99.77| Val Acc: 60.98\n",
      "Epoch 3614: | Train Loss: 0.0029 | Val Loss: 9.5790 | Train Acc: 99.76| Val Acc: 60.88\n",
      "Epoch 3615: | Train Loss: 0.0037 | Val Loss: 9.6060 | Train Acc: 99.65| Val Acc: 60.87\n",
      "Epoch 3616: | Train Loss: 0.0045 | Val Loss: 9.6152 | Train Acc: 99.60| Val Acc: 60.67\n",
      "Epoch 3617: | Train Loss: 0.0024 | Val Loss: 9.6095 | Train Acc: 99.76| Val Acc: 60.67\n",
      "Epoch 3618: | Train Loss: 0.0033 | Val Loss: 9.5746 | Train Acc: 99.70| Val Acc: 60.67\n",
      "Epoch 3619: | Train Loss: 0.0027 | Val Loss: 9.5458 | Train Acc: 99.86| Val Acc: 60.87\n",
      "Epoch 3620: | Train Loss: 0.0018 | Val Loss: 9.4920 | Train Acc: 99.93| Val Acc: 60.97\n",
      "Epoch 3621: | Train Loss: 0.0024 | Val Loss: 9.5337 | Train Acc: 99.90| Val Acc: 60.97\n",
      "Epoch 3622: | Train Loss: 0.0034 | Val Loss: 9.5322 | Train Acc: 99.90| Val Acc: 61.08\n",
      "Epoch 3623: | Train Loss: 0.0023 | Val Loss: 9.5250 | Train Acc: 99.90| Val Acc: 61.18\n",
      "Epoch 3624: | Train Loss: 0.0023 | Val Loss: 9.4922 | Train Acc: 99.93| Val Acc: 60.96\n",
      "Epoch 3625: | Train Loss: 0.0027 | Val Loss: 9.4901 | Train Acc: 99.76| Val Acc: 60.96\n",
      "Epoch 3626: | Train Loss: 0.0026 | Val Loss: 9.5071 | Train Acc: 99.85| Val Acc: 61.16\n",
      "Epoch 3627: | Train Loss: 0.0027 | Val Loss: 9.4731 | Train Acc: 99.83| Val Acc: 61.27\n",
      "Epoch 3628: | Train Loss: 0.0025 | Val Loss: 9.4874 | Train Acc: 99.86| Val Acc: 61.37\n",
      "Epoch 3629: | Train Loss: 0.0033 | Val Loss: 9.5002 | Train Acc: 99.70| Val Acc: 61.17\n",
      "Epoch 3630: | Train Loss: 0.0025 | Val Loss: 9.5335 | Train Acc: 99.87| Val Acc: 61.19\n",
      "Epoch 3631: | Train Loss: 0.0030 | Val Loss: 9.5643 | Train Acc: 99.93| Val Acc: 61.07\n",
      "Epoch 3632: | Train Loss: 0.0020 | Val Loss: 9.6367 | Train Acc: 99.86| Val Acc: 60.67\n",
      "Epoch 3633: | Train Loss: 0.0029 | Val Loss: 9.6140 | Train Acc: 99.76| Val Acc: 61.07\n",
      "Epoch 3634: | Train Loss: 0.0029 | Val Loss: 9.6575 | Train Acc: 99.87| Val Acc: 61.06\n",
      "Epoch 3635: | Train Loss: 0.0028 | Val Loss: 9.6442 | Train Acc: 99.78| Val Acc: 61.27\n",
      "Epoch 3636: | Train Loss: 0.0029 | Val Loss: 9.6113 | Train Acc: 99.80| Val Acc: 61.37\n",
      "Epoch 3637: | Train Loss: 0.0022 | Val Loss: 9.6360 | Train Acc: 99.86| Val Acc: 61.37\n",
      "Epoch 3638: | Train Loss: 0.0034 | Val Loss: 9.6498 | Train Acc: 99.65| Val Acc: 61.59\n",
      "Epoch 3639: | Train Loss: 0.0031 | Val Loss: 9.6475 | Train Acc: 99.76| Val Acc: 61.37\n",
      "Epoch 3640: | Train Loss: 0.0024 | Val Loss: 9.6247 | Train Acc: 99.87| Val Acc: 61.49\n",
      "Epoch 3641: | Train Loss: 0.0026 | Val Loss: 9.6246 | Train Acc: 99.87| Val Acc: 61.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3642: | Train Loss: 0.0019 | Val Loss: 9.6360 | Train Acc: 99.90| Val Acc: 61.27\n",
      "Epoch 3643: | Train Loss: 0.0045 | Val Loss: 9.6710 | Train Acc: 99.76| Val Acc: 61.17\n",
      "Epoch 3644: | Train Loss: 0.0026 | Val Loss: 9.6693 | Train Acc: 99.74| Val Acc: 61.57\n",
      "Epoch 3645: | Train Loss: 0.0037 | Val Loss: 9.6719 | Train Acc: 99.66| Val Acc: 60.96\n",
      "Epoch 3646: | Train Loss: 0.0085 | Val Loss: 9.6812 | Train Acc: 99.68| Val Acc: 60.87\n",
      "Epoch 3647: | Train Loss: 0.0023 | Val Loss: 9.6404 | Train Acc: 99.87| Val Acc: 60.88\n",
      "Epoch 3648: | Train Loss: 0.0025 | Val Loss: 9.6238 | Train Acc: 99.87| Val Acc: 61.10\n",
      "Epoch 3649: | Train Loss: 0.0031 | Val Loss: 9.6319 | Train Acc: 99.76| Val Acc: 60.98\n",
      "Epoch 3650: | Train Loss: 0.0029 | Val Loss: 9.5919 | Train Acc: 99.76| Val Acc: 61.09\n",
      "Epoch 3651: | Train Loss: 0.0033 | Val Loss: 9.6066 | Train Acc: 99.70| Val Acc: 61.20\n",
      "Epoch 3652: | Train Loss: 0.0026 | Val Loss: 9.6298 | Train Acc: 99.79| Val Acc: 61.09\n",
      "Epoch 3653: | Train Loss: 0.0025 | Val Loss: 9.6525 | Train Acc: 99.76| Val Acc: 61.08\n",
      "Epoch 3654: | Train Loss: 0.0031 | Val Loss: 9.6079 | Train Acc: 99.70| Val Acc: 61.08\n",
      "Epoch 3655: | Train Loss: 0.0033 | Val Loss: 9.6346 | Train Acc: 99.64| Val Acc: 60.97\n",
      "Epoch 3656: | Train Loss: 0.0022 | Val Loss: 9.6417 | Train Acc: 99.87| Val Acc: 61.08\n",
      "Epoch 3657: | Train Loss: 0.0025 | Val Loss: 9.6657 | Train Acc: 99.90| Val Acc: 61.08\n",
      "Epoch 3658: | Train Loss: 0.0029 | Val Loss: 9.6784 | Train Acc: 99.73| Val Acc: 60.96\n",
      "Epoch 3659: | Train Loss: 0.0042 | Val Loss: 9.6760 | Train Acc: 99.59| Val Acc: 61.18\n",
      "Epoch 3660: | Train Loss: 0.0021 | Val Loss: 9.6882 | Train Acc: 99.90| Val Acc: 61.18\n",
      "Epoch 3661: | Train Loss: 0.0028 | Val Loss: 9.6626 | Train Acc: 99.78| Val Acc: 61.18\n",
      "Epoch 3662: | Train Loss: 0.0021 | Val Loss: 9.6867 | Train Acc: 99.83| Val Acc: 61.09\n",
      "Epoch 3663: | Train Loss: 0.0027 | Val Loss: 9.6493 | Train Acc: 99.80| Val Acc: 60.99\n",
      "Epoch 3664: | Train Loss: 0.0036 | Val Loss: 9.6757 | Train Acc: 99.77| Val Acc: 60.79\n",
      "Epoch 3665: | Train Loss: 0.0020 | Val Loss: 9.6812 | Train Acc: 99.93| Val Acc: 60.67\n",
      "Epoch 3666: | Train Loss: 0.0059 | Val Loss: 9.6741 | Train Acc: 99.83| Val Acc: 60.87\n",
      "Epoch 3667: | Train Loss: 0.0027 | Val Loss: 9.6334 | Train Acc: 99.83| Val Acc: 60.98\n",
      "Epoch 3668: | Train Loss: 0.0026 | Val Loss: 9.6593 | Train Acc: 99.83| Val Acc: 60.87\n",
      "Epoch 3669: | Train Loss: 0.0024 | Val Loss: 9.6314 | Train Acc: 99.84| Val Acc: 60.97\n",
      "Epoch 3670: | Train Loss: 0.0025 | Val Loss: 9.6591 | Train Acc: 99.87| Val Acc: 60.87\n",
      "Epoch 3671: | Train Loss: 0.0021 | Val Loss: 9.6739 | Train Acc: 99.93| Val Acc: 60.87\n",
      "Epoch 3672: | Train Loss: 0.0031 | Val Loss: 9.6312 | Train Acc: 99.87| Val Acc: 60.77\n",
      "Epoch 3673: | Train Loss: 0.0028 | Val Loss: 9.6265 | Train Acc: 99.83| Val Acc: 60.77\n",
      "Epoch 3674: | Train Loss: 0.0033 | Val Loss: 9.6165 | Train Acc: 99.77| Val Acc: 61.06\n",
      "Epoch 3675: | Train Loss: 0.0025 | Val Loss: 9.5670 | Train Acc: 99.90| Val Acc: 61.26\n",
      "Epoch 3676: | Train Loss: 0.0031 | Val Loss: 9.5782 | Train Acc: 99.78| Val Acc: 61.56\n",
      "Epoch 3677: | Train Loss: 0.0032 | Val Loss: 9.5629 | Train Acc: 99.73| Val Acc: 61.26\n",
      "Epoch 3678: | Train Loss: 0.0035 | Val Loss: 9.5696 | Train Acc: 99.71| Val Acc: 60.95\n",
      "Epoch 3679: | Train Loss: 0.0021 | Val Loss: 9.5293 | Train Acc: 99.90| Val Acc: 60.76\n",
      "Epoch 3680: | Train Loss: 0.0022 | Val Loss: 9.5636 | Train Acc: 99.79| Val Acc: 60.86\n",
      "Epoch 3681: | Train Loss: 0.0037 | Val Loss: 9.5555 | Train Acc: 99.84| Val Acc: 61.07\n",
      "Epoch 3682: | Train Loss: 0.0035 | Val Loss: 9.5345 | Train Acc: 99.83| Val Acc: 60.87\n",
      "Epoch 3683: | Train Loss: 0.0028 | Val Loss: 9.5361 | Train Acc: 99.78| Val Acc: 60.56\n",
      "Epoch 3684: | Train Loss: 0.0035 | Val Loss: 9.5228 | Train Acc: 99.80| Val Acc: 60.56\n",
      "Epoch 3685: | Train Loss: 0.0027 | Val Loss: 9.5123 | Train Acc: 99.84| Val Acc: 60.47\n",
      "Epoch 3686: | Train Loss: 0.0024 | Val Loss: 9.4885 | Train Acc: 99.83| Val Acc: 60.86\n",
      "Epoch 3687: | Train Loss: 0.0028 | Val Loss: 9.4870 | Train Acc: 99.78| Val Acc: 60.86\n",
      "Epoch 3688: | Train Loss: 0.0028 | Val Loss: 9.5223 | Train Acc: 99.77| Val Acc: 60.95\n",
      "Epoch 3689: | Train Loss: 0.0031 | Val Loss: 9.5207 | Train Acc: 99.77| Val Acc: 60.85\n",
      "Epoch 3690: | Train Loss: 0.0032 | Val Loss: 9.5621 | Train Acc: 99.71| Val Acc: 60.95\n",
      "Epoch 3691: | Train Loss: 0.0028 | Val Loss: 9.5843 | Train Acc: 99.77| Val Acc: 60.85\n",
      "Epoch 3692: | Train Loss: 0.0034 | Val Loss: 9.5712 | Train Acc: 99.79| Val Acc: 60.75\n",
      "Epoch 3693: | Train Loss: 0.0041 | Val Loss: 9.5335 | Train Acc: 99.66| Val Acc: 60.76\n",
      "Epoch 3694: | Train Loss: 0.0030 | Val Loss: 9.5077 | Train Acc: 99.73| Val Acc: 60.87\n",
      "Epoch 3695: | Train Loss: 0.0029 | Val Loss: 9.4830 | Train Acc: 99.83| Val Acc: 60.87\n",
      "Epoch 3696: | Train Loss: 0.0029 | Val Loss: 9.5183 | Train Acc: 99.78| Val Acc: 60.68\n",
      "Epoch 3697: | Train Loss: 0.0038 | Val Loss: 9.5422 | Train Acc: 99.71| Val Acc: 60.68\n",
      "Epoch 3698: | Train Loss: 0.0022 | Val Loss: 9.5467 | Train Acc: 99.86| Val Acc: 60.88\n",
      "Epoch 3699: | Train Loss: 0.0030 | Val Loss: 9.5356 | Train Acc: 99.80| Val Acc: 60.88\n",
      "Epoch 3700: | Train Loss: 0.0017 | Val Loss: 9.5308 | Train Acc: 99.93| Val Acc: 60.88\n",
      "Epoch 3701: | Train Loss: 0.0015 | Val Loss: 9.5597 | Train Acc: 99.97| Val Acc: 60.87\n",
      "Epoch 3702: | Train Loss: 0.0042 | Val Loss: 9.5861 | Train Acc: 99.74| Val Acc: 61.09\n",
      "Epoch 3703: | Train Loss: 0.0018 | Val Loss: 9.6027 | Train Acc: 99.90| Val Acc: 61.19\n",
      "Epoch 3704: | Train Loss: 0.0022 | Val Loss: 9.5760 | Train Acc: 99.84| Val Acc: 61.19\n",
      "Epoch 3705: | Train Loss: 0.0022 | Val Loss: 9.5514 | Train Acc: 99.87| Val Acc: 61.19\n",
      "Epoch 3706: | Train Loss: 0.0025 | Val Loss: 9.5654 | Train Acc: 99.80| Val Acc: 61.28\n",
      "Epoch 3707: | Train Loss: 0.0028 | Val Loss: 9.5936 | Train Acc: 99.76| Val Acc: 61.38\n",
      "Epoch 3708: | Train Loss: 0.0026 | Val Loss: 9.5821 | Train Acc: 99.76| Val Acc: 61.38\n",
      "Epoch 3709: | Train Loss: 0.0021 | Val Loss: 9.5997 | Train Acc: 99.87| Val Acc: 61.78\n",
      "Epoch 3710: | Train Loss: 0.0026 | Val Loss: 9.5922 | Train Acc: 99.73| Val Acc: 61.67\n",
      "Epoch 3711: | Train Loss: 0.0023 | Val Loss: 9.5752 | Train Acc: 99.84| Val Acc: 61.47\n",
      "Epoch 3712: | Train Loss: 0.0021 | Val Loss: 9.5638 | Train Acc: 99.83| Val Acc: 61.27\n",
      "Epoch 3713: | Train Loss: 0.0017 | Val Loss: 9.5676 | Train Acc: 99.86| Val Acc: 61.16\n",
      "Epoch 3714: | Train Loss: 0.0027 | Val Loss: 9.5204 | Train Acc: 99.87| Val Acc: 61.18\n",
      "Epoch 3715: | Train Loss: 0.0035 | Val Loss: 9.5117 | Train Acc: 99.62| Val Acc: 61.28\n",
      "Epoch 3716: | Train Loss: 0.0027 | Val Loss: 9.5099 | Train Acc: 99.85| Val Acc: 61.38\n",
      "Epoch 3717: | Train Loss: 0.0026 | Val Loss: 9.5610 | Train Acc: 99.85| Val Acc: 61.48\n",
      "Epoch 3718: | Train Loss: 0.0027 | Val Loss: 9.5470 | Train Acc: 99.77| Val Acc: 61.58\n",
      "Epoch 3719: | Train Loss: 0.0028 | Val Loss: 9.5964 | Train Acc: 99.76| Val Acc: 61.48\n",
      "Epoch 3720: | Train Loss: 0.0016 | Val Loss: 9.5757 | Train Acc: 99.97| Val Acc: 61.27\n",
      "Epoch 3721: | Train Loss: 0.0028 | Val Loss: 9.5798 | Train Acc: 99.87| Val Acc: 61.49\n",
      "Epoch 3722: | Train Loss: 0.0024 | Val Loss: 9.5740 | Train Acc: 99.84| Val Acc: 61.28\n",
      "Epoch 3723: | Train Loss: 0.0025 | Val Loss: 9.5372 | Train Acc: 99.79| Val Acc: 61.40\n",
      "Epoch 3724: | Train Loss: 0.0042 | Val Loss: 9.5243 | Train Acc: 99.73| Val Acc: 61.29\n",
      "Epoch 3725: | Train Loss: 0.0032 | Val Loss: 9.4895 | Train Acc: 99.84| Val Acc: 61.69\n",
      "Epoch 3726: | Train Loss: 0.0030 | Val Loss: 9.4950 | Train Acc: 99.74| Val Acc: 61.37\n",
      "Epoch 3727: | Train Loss: 0.0037 | Val Loss: 9.4660 | Train Acc: 99.71| Val Acc: 61.27\n",
      "Epoch 3728: | Train Loss: 0.0018 | Val Loss: 9.4703 | Train Acc: 99.97| Val Acc: 61.37\n",
      "Epoch 3729: | Train Loss: 0.0025 | Val Loss: 9.4610 | Train Acc: 99.75| Val Acc: 61.68\n",
      "Epoch 3730: | Train Loss: 0.0026 | Val Loss: 9.4754 | Train Acc: 99.87| Val Acc: 61.58\n",
      "Epoch 3731: | Train Loss: 0.0021 | Val Loss: 9.4976 | Train Acc: 99.84| Val Acc: 61.47\n",
      "Epoch 3732: | Train Loss: 0.0023 | Val Loss: 9.4967 | Train Acc: 99.87| Val Acc: 61.67\n",
      "Epoch 3733: | Train Loss: 0.0029 | Val Loss: 9.4799 | Train Acc: 99.87| Val Acc: 61.67\n",
      "Epoch 3734: | Train Loss: 0.0032 | Val Loss: 9.5094 | Train Acc: 99.72| Val Acc: 61.78\n",
      "Epoch 3735: | Train Loss: 0.0033 | Val Loss: 9.4951 | Train Acc: 99.76| Val Acc: 61.78\n",
      "Epoch 3736: | Train Loss: 0.0036 | Val Loss: 9.5085 | Train Acc: 99.65| Val Acc: 61.59\n",
      "Epoch 3737: | Train Loss: 0.0027 | Val Loss: 9.5080 | Train Acc: 99.68| Val Acc: 61.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3738: | Train Loss: 0.0023 | Val Loss: 9.4970 | Train Acc: 99.80| Val Acc: 61.19\n",
      "Epoch 3739: | Train Loss: 0.0018 | Val Loss: 9.5383 | Train Acc: 99.97| Val Acc: 61.29\n",
      "Epoch 3740: | Train Loss: 0.0028 | Val Loss: 9.5533 | Train Acc: 99.80| Val Acc: 61.28\n",
      "Epoch 3741: | Train Loss: 0.0022 | Val Loss: 9.5703 | Train Acc: 99.76| Val Acc: 61.28\n",
      "Epoch 3742: | Train Loss: 0.0034 | Val Loss: 9.5517 | Train Acc: 99.77| Val Acc: 61.28\n",
      "Epoch 3743: | Train Loss: 0.0030 | Val Loss: 9.5453 | Train Acc: 99.79| Val Acc: 61.48\n",
      "Epoch 3744: | Train Loss: 0.0057 | Val Loss: 9.5523 | Train Acc: 99.74| Val Acc: 61.48\n",
      "Epoch 3745: | Train Loss: 0.0030 | Val Loss: 9.5506 | Train Acc: 99.90| Val Acc: 61.48\n",
      "Epoch 3746: | Train Loss: 0.0027 | Val Loss: 9.5112 | Train Acc: 99.80| Val Acc: 61.48\n",
      "Epoch 3747: | Train Loss: 0.0025 | Val Loss: 9.4776 | Train Acc: 99.78| Val Acc: 61.19\n",
      "Epoch 3748: | Train Loss: 0.0020 | Val Loss: 9.4825 | Train Acc: 99.84| Val Acc: 61.19\n",
      "Epoch 3749: | Train Loss: 0.0026 | Val Loss: 9.5016 | Train Acc: 99.73| Val Acc: 61.09\n",
      "Epoch 3750: | Train Loss: 0.0023 | Val Loss: 9.4918 | Train Acc: 99.87| Val Acc: 61.29\n",
      "Epoch 3751: | Train Loss: 0.0016 | Val Loss: 9.5356 | Train Acc: 99.90| Val Acc: 61.20\n",
      "Epoch 3752: | Train Loss: 0.0019 | Val Loss: 9.5640 | Train Acc: 99.78| Val Acc: 61.09\n",
      "Epoch 3753: | Train Loss: 0.0022 | Val Loss: 9.5342 | Train Acc: 99.76| Val Acc: 61.09\n",
      "Epoch 3754: | Train Loss: 0.0031 | Val Loss: 9.5863 | Train Acc: 99.73| Val Acc: 61.39\n",
      "Epoch 3755: | Train Loss: 0.0023 | Val Loss: 9.5810 | Train Acc: 99.80| Val Acc: 61.29\n",
      "Epoch 3756: | Train Loss: 0.0035 | Val Loss: 9.5757 | Train Acc: 99.63| Val Acc: 61.39\n",
      "Epoch 3757: | Train Loss: 0.0020 | Val Loss: 9.6148 | Train Acc: 99.89| Val Acc: 61.59\n",
      "Epoch 3758: | Train Loss: 0.0025 | Val Loss: 9.5896 | Train Acc: 99.84| Val Acc: 61.38\n",
      "Epoch 3759: | Train Loss: 0.0028 | Val Loss: 9.5946 | Train Acc: 99.77| Val Acc: 61.38\n",
      "Epoch 3760: | Train Loss: 0.0033 | Val Loss: 9.6099 | Train Acc: 99.84| Val Acc: 61.07\n",
      "Epoch 3761: | Train Loss: 0.0027 | Val Loss: 9.5791 | Train Acc: 99.76| Val Acc: 60.98\n",
      "Epoch 3762: | Train Loss: 0.0025 | Val Loss: 9.5871 | Train Acc: 99.77| Val Acc: 61.19\n",
      "Epoch 3763: | Train Loss: 0.0013 | Val Loss: 9.6292 | Train Acc: 99.93| Val Acc: 61.19\n",
      "Epoch 3764: | Train Loss: 0.0027 | Val Loss: 9.6398 | Train Acc: 99.77| Val Acc: 60.98\n",
      "Epoch 3765: | Train Loss: 0.0027 | Val Loss: 9.6097 | Train Acc: 99.92| Val Acc: 61.08\n",
      "Epoch 3766: | Train Loss: 0.0032 | Val Loss: 9.6117 | Train Acc: 99.74| Val Acc: 60.98\n",
      "Epoch 3767: | Train Loss: 0.0039 | Val Loss: 9.6578 | Train Acc: 99.52| Val Acc: 61.09\n",
      "Epoch 3768: | Train Loss: 0.0023 | Val Loss: 9.6717 | Train Acc: 99.84| Val Acc: 60.98\n",
      "Epoch 3769: | Train Loss: 0.0026 | Val Loss: 9.6887 | Train Acc: 99.93| Val Acc: 60.98\n",
      "Epoch 3770: | Train Loss: 0.0020 | Val Loss: 9.6866 | Train Acc: 99.86| Val Acc: 61.08\n",
      "Epoch 3771: | Train Loss: 0.0024 | Val Loss: 9.7181 | Train Acc: 99.86| Val Acc: 61.09\n",
      "Epoch 3772: | Train Loss: 0.0025 | Val Loss: 9.7049 | Train Acc: 99.86| Val Acc: 61.08\n",
      "Epoch 3773: | Train Loss: 0.0032 | Val Loss: 9.6557 | Train Acc: 99.75| Val Acc: 61.27\n",
      "Epoch 3774: | Train Loss: 0.0022 | Val Loss: 9.6482 | Train Acc: 99.80| Val Acc: 61.38\n",
      "Epoch 3775: | Train Loss: 0.0030 | Val Loss: 9.6147 | Train Acc: 99.87| Val Acc: 61.27\n",
      "Epoch 3776: | Train Loss: 0.0046 | Val Loss: 9.6342 | Train Acc: 99.73| Val Acc: 61.38\n",
      "Epoch 3777: | Train Loss: 0.0030 | Val Loss: 9.6365 | Train Acc: 99.75| Val Acc: 61.09\n",
      "Epoch 3778: | Train Loss: 0.0018 | Val Loss: 9.6400 | Train Acc: 99.90| Val Acc: 61.20\n",
      "Epoch 3779: | Train Loss: 0.0025 | Val Loss: 9.6524 | Train Acc: 99.84| Val Acc: 61.19\n",
      "Epoch 3780: | Train Loss: 0.0022 | Val Loss: 9.6785 | Train Acc: 99.80| Val Acc: 61.20\n",
      "Epoch 3781: | Train Loss: 0.0016 | Val Loss: 9.6698 | Train Acc: 99.97| Val Acc: 61.20\n",
      "Epoch 3782: | Train Loss: 0.0022 | Val Loss: 9.6531 | Train Acc: 99.81| Val Acc: 61.20\n",
      "Epoch 3783: | Train Loss: 0.0016 | Val Loss: 9.6921 | Train Acc: 99.90| Val Acc: 61.30\n",
      "Epoch 3784: | Train Loss: 0.0019 | Val Loss: 9.6714 | Train Acc: 99.90| Val Acc: 61.09\n",
      "Epoch 3785: | Train Loss: 0.0027 | Val Loss: 9.6758 | Train Acc: 99.76| Val Acc: 60.78\n",
      "Epoch 3786: | Train Loss: 0.0022 | Val Loss: 9.6611 | Train Acc: 99.93| Val Acc: 60.67\n",
      "Epoch 3787: | Train Loss: 0.0032 | Val Loss: 9.6681 | Train Acc: 99.85| Val Acc: 60.67\n",
      "Epoch 3788: | Train Loss: 0.0026 | Val Loss: 9.6977 | Train Acc: 99.80| Val Acc: 60.66\n",
      "Epoch 3789: | Train Loss: 0.0027 | Val Loss: 9.6744 | Train Acc: 99.80| Val Acc: 60.56\n",
      "Epoch 3790: | Train Loss: 0.0026 | Val Loss: 9.7305 | Train Acc: 99.76| Val Acc: 60.66\n",
      "Epoch 3791: | Train Loss: 0.0024 | Val Loss: 9.6997 | Train Acc: 99.87| Val Acc: 60.76\n",
      "Epoch 3792: | Train Loss: 0.0027 | Val Loss: 9.7025 | Train Acc: 99.83| Val Acc: 60.65\n",
      "Epoch 3793: | Train Loss: 0.0015 | Val Loss: 9.7453 | Train Acc: 99.92| Val Acc: 61.07\n",
      "Epoch 3794: | Train Loss: 0.0033 | Val Loss: 9.7177 | Train Acc: 99.70| Val Acc: 60.86\n",
      "Epoch 3795: | Train Loss: 0.0022 | Val Loss: 9.6963 | Train Acc: 99.87| Val Acc: 60.76\n",
      "Epoch 3796: | Train Loss: 0.0022 | Val Loss: 9.6984 | Train Acc: 99.89| Val Acc: 60.86\n",
      "Epoch 3797: | Train Loss: 0.0038 | Val Loss: 9.7029 | Train Acc: 99.80| Val Acc: 60.76\n",
      "Epoch 3798: | Train Loss: 0.0028 | Val Loss: 9.7092 | Train Acc: 99.89| Val Acc: 60.77\n",
      "Epoch 3799: | Train Loss: 0.0030 | Val Loss: 9.6939 | Train Acc: 99.76| Val Acc: 60.87\n",
      "Epoch 3800: | Train Loss: 0.0018 | Val Loss: 9.7082 | Train Acc: 99.90| Val Acc: 61.17\n",
      "Epoch 3801: | Train Loss: 0.0019 | Val Loss: 9.6965 | Train Acc: 99.87| Val Acc: 60.87\n",
      "Epoch 3802: | Train Loss: 0.0018 | Val Loss: 9.7331 | Train Acc: 99.90| Val Acc: 60.87\n",
      "Epoch 3803: | Train Loss: 0.0037 | Val Loss: 9.7320 | Train Acc: 99.73| Val Acc: 60.87\n",
      "Epoch 3804: | Train Loss: 0.0033 | Val Loss: 9.7193 | Train Acc: 99.70| Val Acc: 60.97\n",
      "Epoch 3805: | Train Loss: 0.0023 | Val Loss: 9.6927 | Train Acc: 99.79| Val Acc: 60.87\n",
      "Epoch 3806: | Train Loss: 0.0023 | Val Loss: 9.7174 | Train Acc: 99.77| Val Acc: 60.97\n",
      "Epoch 3807: | Train Loss: 0.0029 | Val Loss: 9.6442 | Train Acc: 99.90| Val Acc: 61.07\n",
      "Epoch 3808: | Train Loss: 0.0029 | Val Loss: 9.6027 | Train Acc: 99.76| Val Acc: 60.97\n",
      "Epoch 3809: | Train Loss: 0.0022 | Val Loss: 9.6064 | Train Acc: 99.87| Val Acc: 60.97\n",
      "Epoch 3810: | Train Loss: 0.0027 | Val Loss: 9.6034 | Train Acc: 99.80| Val Acc: 61.18\n",
      "Epoch 3811: | Train Loss: 0.0025 | Val Loss: 9.6237 | Train Acc: 99.90| Val Acc: 60.87\n",
      "Epoch 3812: | Train Loss: 0.0036 | Val Loss: 9.6180 | Train Acc: 99.77| Val Acc: 60.97\n",
      "Epoch 3813: | Train Loss: 0.0030 | Val Loss: 9.6229 | Train Acc: 99.70| Val Acc: 60.87\n",
      "Epoch 3814: | Train Loss: 0.0020 | Val Loss: 9.6533 | Train Acc: 99.92| Val Acc: 60.97\n",
      "Epoch 3815: | Train Loss: 0.0027 | Val Loss: 9.6608 | Train Acc: 99.80| Val Acc: 61.07\n",
      "Epoch 3816: | Train Loss: 0.0027 | Val Loss: 9.7157 | Train Acc: 99.77| Val Acc: 61.07\n",
      "Epoch 3817: | Train Loss: 0.0018 | Val Loss: 9.7476 | Train Acc: 99.87| Val Acc: 60.97\n",
      "Epoch 3818: | Train Loss: 0.0024 | Val Loss: 9.7453 | Train Acc: 99.84| Val Acc: 60.97\n",
      "Epoch 3819: | Train Loss: 0.0027 | Val Loss: 9.7556 | Train Acc: 99.84| Val Acc: 60.97\n",
      "Epoch 3820: | Train Loss: 0.0022 | Val Loss: 9.7649 | Train Acc: 99.76| Val Acc: 60.87\n",
      "Epoch 3821: | Train Loss: 0.0021 | Val Loss: 9.7883 | Train Acc: 99.90| Val Acc: 60.77\n",
      "Epoch 3822: | Train Loss: 0.0019 | Val Loss: 9.7585 | Train Acc: 99.80| Val Acc: 60.65\n",
      "Epoch 3823: | Train Loss: 0.0021 | Val Loss: 9.7757 | Train Acc: 99.87| Val Acc: 60.66\n",
      "Epoch 3824: | Train Loss: 0.0020 | Val Loss: 9.7426 | Train Acc: 99.90| Val Acc: 60.77\n",
      "Epoch 3825: | Train Loss: 0.0030 | Val Loss: 9.7188 | Train Acc: 99.73| Val Acc: 60.77\n",
      "Epoch 3826: | Train Loss: 0.0037 | Val Loss: 9.7223 | Train Acc: 99.80| Val Acc: 60.87\n",
      "Epoch 3827: | Train Loss: 0.0022 | Val Loss: 9.7510 | Train Acc: 99.84| Val Acc: 60.76\n",
      "Epoch 3828: | Train Loss: 0.0034 | Val Loss: 9.7833 | Train Acc: 99.74| Val Acc: 60.86\n",
      "Epoch 3829: | Train Loss: 0.0022 | Val Loss: 9.7947 | Train Acc: 99.86| Val Acc: 60.86\n",
      "Epoch 3830: | Train Loss: 0.0026 | Val Loss: 9.7911 | Train Acc: 99.89| Val Acc: 60.86\n",
      "Epoch 3831: | Train Loss: 0.0026 | Val Loss: 9.7760 | Train Acc: 99.92| Val Acc: 60.86\n",
      "Epoch 3832: | Train Loss: 0.0021 | Val Loss: 9.7497 | Train Acc: 99.86| Val Acc: 60.95\n",
      "Epoch 3833: | Train Loss: 0.0031 | Val Loss: 9.7216 | Train Acc: 99.77| Val Acc: 60.86\n",
      "Epoch 3834: | Train Loss: 0.0020 | Val Loss: 9.7262 | Train Acc: 99.84| Val Acc: 61.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3835: | Train Loss: 0.0037 | Val Loss: 9.7108 | Train Acc: 99.74| Val Acc: 60.85\n",
      "Epoch 3836: | Train Loss: 0.0026 | Val Loss: 9.7423 | Train Acc: 99.90| Val Acc: 60.85\n",
      "Epoch 3837: | Train Loss: 0.0023 | Val Loss: 9.7486 | Train Acc: 99.76| Val Acc: 60.65\n",
      "Epoch 3838: | Train Loss: 0.0021 | Val Loss: 9.7668 | Train Acc: 99.84| Val Acc: 60.75\n",
      "Epoch 3839: | Train Loss: 0.0019 | Val Loss: 9.7687 | Train Acc: 99.77| Val Acc: 60.65\n",
      "Epoch 3840: | Train Loss: 0.0037 | Val Loss: 9.8048 | Train Acc: 99.73| Val Acc: 60.55\n",
      "Epoch 3841: | Train Loss: 0.0015 | Val Loss: 9.8176 | Train Acc: 99.93| Val Acc: 60.55\n",
      "Epoch 3842: | Train Loss: 0.0022 | Val Loss: 9.8661 | Train Acc: 99.84| Val Acc: 60.65\n",
      "Epoch 3843: | Train Loss: 0.0024 | Val Loss: 9.8603 | Train Acc: 99.80| Val Acc: 61.06\n",
      "Epoch 3844: | Train Loss: 0.0026 | Val Loss: 9.8703 | Train Acc: 99.70| Val Acc: 60.87\n",
      "Epoch 3845: | Train Loss: 0.0031 | Val Loss: 9.8531 | Train Acc: 99.84| Val Acc: 61.07\n",
      "Epoch 3846: | Train Loss: 0.0021 | Val Loss: 9.8363 | Train Acc: 99.85| Val Acc: 61.07\n",
      "Epoch 3847: | Train Loss: 0.0030 | Val Loss: 9.7878 | Train Acc: 99.80| Val Acc: 61.07\n",
      "Epoch 3848: | Train Loss: 0.0023 | Val Loss: 9.7480 | Train Acc: 99.90| Val Acc: 60.88\n",
      "Epoch 3849: | Train Loss: 0.0022 | Val Loss: 9.7560 | Train Acc: 99.76| Val Acc: 60.78\n",
      "Epoch 3850: | Train Loss: 0.0015 | Val Loss: 9.7332 | Train Acc: 99.89| Val Acc: 60.78\n",
      "Epoch 3851: | Train Loss: 0.0028 | Val Loss: 9.6942 | Train Acc: 99.87| Val Acc: 60.76\n",
      "Epoch 3852: | Train Loss: 0.0022 | Val Loss: 9.7126 | Train Acc: 99.87| Val Acc: 60.67\n",
      "Epoch 3853: | Train Loss: 0.0018 | Val Loss: 9.7066 | Train Acc: 99.92| Val Acc: 61.19\n",
      "Epoch 3854: | Train Loss: 0.0020 | Val Loss: 9.7491 | Train Acc: 99.90| Val Acc: 61.19\n",
      "Epoch 3855: | Train Loss: 0.0021 | Val Loss: 9.7627 | Train Acc: 99.90| Val Acc: 60.98\n",
      "Epoch 3856: | Train Loss: 0.0026 | Val Loss: 9.7843 | Train Acc: 99.93| Val Acc: 61.09\n",
      "Epoch 3857: | Train Loss: 0.0065 | Val Loss: 9.8040 | Train Acc: 99.72| Val Acc: 60.98\n",
      "Epoch 3858: | Train Loss: 0.0029 | Val Loss: 9.8064 | Train Acc: 99.77| Val Acc: 61.08\n",
      "Epoch 3859: | Train Loss: 0.0020 | Val Loss: 9.7640 | Train Acc: 99.84| Val Acc: 61.19\n",
      "Epoch 3860: | Train Loss: 0.0025 | Val Loss: 9.7313 | Train Acc: 99.87| Val Acc: 61.07\n",
      "Epoch 3861: | Train Loss: 0.0021 | Val Loss: 9.7424 | Train Acc: 99.90| Val Acc: 61.19\n",
      "Epoch 3862: | Train Loss: 0.0025 | Val Loss: 9.7374 | Train Acc: 99.90| Val Acc: 61.08\n",
      "Epoch 3863: | Train Loss: 0.0032 | Val Loss: 9.7579 | Train Acc: 99.71| Val Acc: 61.07\n",
      "Epoch 3864: | Train Loss: 0.0028 | Val Loss: 9.7303 | Train Acc: 99.77| Val Acc: 61.07\n",
      "Epoch 3865: | Train Loss: 0.0030 | Val Loss: 9.7398 | Train Acc: 99.70| Val Acc: 61.27\n",
      "Epoch 3866: | Train Loss: 0.0025 | Val Loss: 9.7525 | Train Acc: 99.73| Val Acc: 61.08\n",
      "Epoch 3867: | Train Loss: 0.0023 | Val Loss: 9.7816 | Train Acc: 99.90| Val Acc: 60.97\n",
      "Epoch 3868: | Train Loss: 0.0027 | Val Loss: 9.7601 | Train Acc: 99.73| Val Acc: 60.97\n",
      "Epoch 3869: | Train Loss: 0.0024 | Val Loss: 9.7281 | Train Acc: 99.90| Val Acc: 60.87\n",
      "Epoch 3870: | Train Loss: 0.0020 | Val Loss: 9.7597 | Train Acc: 99.93| Val Acc: 61.07\n",
      "Epoch 3871: | Train Loss: 0.0019 | Val Loss: 9.7803 | Train Acc: 99.89| Val Acc: 61.17\n",
      "Epoch 3872: | Train Loss: 0.0030 | Val Loss: 9.7494 | Train Acc: 99.90| Val Acc: 61.07\n",
      "Epoch 3873: | Train Loss: 0.0023 | Val Loss: 9.7422 | Train Acc: 99.87| Val Acc: 61.08\n",
      "Epoch 3874: | Train Loss: 0.0031 | Val Loss: 9.7609 | Train Acc: 99.83| Val Acc: 60.97\n",
      "Epoch 3875: | Train Loss: 0.0037 | Val Loss: 9.7667 | Train Acc: 99.77| Val Acc: 61.07\n",
      "Epoch 3876: | Train Loss: 0.0024 | Val Loss: 9.7620 | Train Acc: 99.87| Val Acc: 61.06\n",
      "Epoch 3877: | Train Loss: 0.0020 | Val Loss: 9.7881 | Train Acc: 99.93| Val Acc: 61.06\n",
      "Epoch 3878: | Train Loss: 0.0020 | Val Loss: 9.8038 | Train Acc: 99.83| Val Acc: 61.06\n",
      "Epoch 3879: | Train Loss: 0.0030 | Val Loss: 9.7498 | Train Acc: 99.72| Val Acc: 61.16\n",
      "Epoch 3880: | Train Loss: 0.0022 | Val Loss: 9.7615 | Train Acc: 99.84| Val Acc: 61.17\n",
      "Epoch 3881: | Train Loss: 0.0016 | Val Loss: 9.7326 | Train Acc: 99.90| Val Acc: 61.05\n",
      "Epoch 3882: | Train Loss: 0.0031 | Val Loss: 9.7029 | Train Acc: 99.84| Val Acc: 60.85\n",
      "Epoch 3883: | Train Loss: 0.0024 | Val Loss: 9.7052 | Train Acc: 99.93| Val Acc: 60.85\n",
      "Epoch 3884: | Train Loss: 0.0033 | Val Loss: 9.7058 | Train Acc: 99.93| Val Acc: 60.95\n",
      "Epoch 3885: | Train Loss: 0.0024 | Val Loss: 9.7092 | Train Acc: 99.86| Val Acc: 60.84\n",
      "Epoch 3886: | Train Loss: 0.0018 | Val Loss: 9.7023 | Train Acc: 99.87| Val Acc: 60.64\n",
      "Epoch 3887: | Train Loss: 0.0020 | Val Loss: 9.7114 | Train Acc: 99.90| Val Acc: 60.75\n",
      "Epoch 3888: | Train Loss: 0.0031 | Val Loss: 9.7077 | Train Acc: 99.80| Val Acc: 60.85\n",
      "Epoch 3889: | Train Loss: 0.0032 | Val Loss: 9.7055 | Train Acc: 99.79| Val Acc: 60.85\n",
      "Epoch 3890: | Train Loss: 0.0034 | Val Loss: 9.7082 | Train Acc: 99.76| Val Acc: 60.85\n",
      "Epoch 3891: | Train Loss: 0.0023 | Val Loss: 9.6885 | Train Acc: 99.80| Val Acc: 60.95\n",
      "Epoch 3892: | Train Loss: 0.0022 | Val Loss: 9.6519 | Train Acc: 99.97| Val Acc: 61.06\n",
      "Epoch 3893: | Train Loss: 0.0019 | Val Loss: 9.6408 | Train Acc: 99.92| Val Acc: 61.06\n",
      "Epoch 3894: | Train Loss: 0.0016 | Val Loss: 9.6578 | Train Acc: 99.93| Val Acc: 61.27\n",
      "Epoch 3895: | Train Loss: 0.0023 | Val Loss: 9.6626 | Train Acc: 99.84| Val Acc: 61.16\n",
      "Epoch 3896: | Train Loss: 0.0026 | Val Loss: 9.6913 | Train Acc: 99.70| Val Acc: 61.27\n",
      "Epoch 3897: | Train Loss: 0.0027 | Val Loss: 9.6771 | Train Acc: 99.77| Val Acc: 60.96\n",
      "Epoch 3898: | Train Loss: 0.0025 | Val Loss: 9.6556 | Train Acc: 99.83| Val Acc: 60.96\n",
      "Epoch 3899: | Train Loss: 0.0019 | Val Loss: 9.6582 | Train Acc: 99.85| Val Acc: 60.96\n",
      "Epoch 3900: | Train Loss: 0.0032 | Val Loss: 9.6484 | Train Acc: 99.74| Val Acc: 61.06\n",
      "Epoch 3901: | Train Loss: 0.0038 | Val Loss: 9.6611 | Train Acc: 99.71| Val Acc: 61.06\n",
      "Epoch 3902: | Train Loss: 0.0021 | Val Loss: 9.6498 | Train Acc: 99.92| Val Acc: 60.96\n",
      "Epoch 3903: | Train Loss: 0.0019 | Val Loss: 9.6301 | Train Acc: 99.86| Val Acc: 60.96\n",
      "Epoch 3904: | Train Loss: 0.0036 | Val Loss: 9.6680 | Train Acc: 99.70| Val Acc: 60.86\n",
      "Epoch 3905: | Train Loss: 0.0026 | Val Loss: 9.6840 | Train Acc: 99.80| Val Acc: 60.86\n",
      "Epoch 3906: | Train Loss: 0.0031 | Val Loss: 9.7124 | Train Acc: 99.92| Val Acc: 60.95\n",
      "Epoch 3907: | Train Loss: 0.0027 | Val Loss: 9.7442 | Train Acc: 99.76| Val Acc: 61.05\n",
      "Epoch 3908: | Train Loss: 0.0020 | Val Loss: 9.7429 | Train Acc: 99.90| Val Acc: 61.16\n",
      "Epoch 3909: | Train Loss: 0.0030 | Val Loss: 9.7501 | Train Acc: 99.68| Val Acc: 61.16\n",
      "Epoch 3910: | Train Loss: 0.0024 | Val Loss: 9.7728 | Train Acc: 99.92| Val Acc: 61.06\n",
      "Epoch 3911: | Train Loss: 0.0032 | Val Loss: 9.7245 | Train Acc: 99.80| Val Acc: 60.95\n",
      "Epoch 3912: | Train Loss: 0.0041 | Val Loss: 9.6712 | Train Acc: 99.70| Val Acc: 60.95\n",
      "Epoch 3913: | Train Loss: 0.0026 | Val Loss: 9.6922 | Train Acc: 99.83| Val Acc: 60.95\n",
      "Epoch 3914: | Train Loss: 0.0025 | Val Loss: 9.6469 | Train Acc: 99.89| Val Acc: 61.06\n",
      "Epoch 3915: | Train Loss: 0.0028 | Val Loss: 9.6149 | Train Acc: 99.71| Val Acc: 60.96\n",
      "Epoch 3916: | Train Loss: 0.0016 | Val Loss: 9.6265 | Train Acc: 99.89| Val Acc: 60.75\n",
      "Epoch 3917: | Train Loss: 0.0021 | Val Loss: 9.6229 | Train Acc: 99.93| Val Acc: 60.86\n",
      "Epoch 3918: | Train Loss: 0.0015 | Val Loss: 9.6022 | Train Acc: 99.86| Val Acc: 60.75\n",
      "Epoch 3919: | Train Loss: 0.0020 | Val Loss: 9.5818 | Train Acc: 99.84| Val Acc: 60.75\n",
      "Epoch 3920: | Train Loss: 0.0019 | Val Loss: 9.5958 | Train Acc: 99.85| Val Acc: 60.96\n",
      "Epoch 3921: | Train Loss: 0.0020 | Val Loss: 9.6448 | Train Acc: 99.87| Val Acc: 60.86\n",
      "Epoch 3922: | Train Loss: 0.0020 | Val Loss: 9.6287 | Train Acc: 99.84| Val Acc: 60.96\n",
      "Epoch 3923: | Train Loss: 0.0019 | Val Loss: 9.6481 | Train Acc: 99.90| Val Acc: 60.96\n",
      "Epoch 3924: | Train Loss: 0.0032 | Val Loss: 9.6292 | Train Acc: 99.77| Val Acc: 60.87\n",
      "Epoch 3925: | Train Loss: 0.0025 | Val Loss: 9.6218 | Train Acc: 99.73| Val Acc: 60.66\n",
      "Epoch 3926: | Train Loss: 0.0037 | Val Loss: 9.6252 | Train Acc: 99.67| Val Acc: 60.56\n",
      "Epoch 3927: | Train Loss: 0.0040 | Val Loss: 9.6269 | Train Acc: 99.83| Val Acc: 60.66\n",
      "Epoch 3928: | Train Loss: 0.0028 | Val Loss: 9.6114 | Train Acc: 99.79| Val Acc: 60.55\n",
      "Epoch 3929: | Train Loss: 0.0021 | Val Loss: 9.6097 | Train Acc: 99.89| Val Acc: 60.85\n",
      "Epoch 3930: | Train Loss: 0.0028 | Val Loss: 9.6261 | Train Acc: 99.84| Val Acc: 61.05\n",
      "Epoch 3931: | Train Loss: 0.0037 | Val Loss: 9.5932 | Train Acc: 99.83| Val Acc: 60.95\n",
      "Epoch 3932: | Train Loss: 0.0028 | Val Loss: 9.5572 | Train Acc: 99.78| Val Acc: 61.05\n",
      "Epoch 3933: | Train Loss: 0.0027 | Val Loss: 9.5402 | Train Acc: 99.84| Val Acc: 61.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3934: | Train Loss: 0.0023 | Val Loss: 9.5257 | Train Acc: 99.84| Val Acc: 61.17\n",
      "Epoch 3935: | Train Loss: 0.0026 | Val Loss: 9.5318 | Train Acc: 99.77| Val Acc: 61.27\n",
      "Epoch 3936: | Train Loss: 0.0027 | Val Loss: 9.5177 | Train Acc: 99.77| Val Acc: 60.96\n",
      "Epoch 3937: | Train Loss: 0.0018 | Val Loss: 9.5134 | Train Acc: 99.92| Val Acc: 61.07\n",
      "Epoch 3938: | Train Loss: 0.0033 | Val Loss: 9.5313 | Train Acc: 99.73| Val Acc: 61.07\n",
      "Epoch 3939: | Train Loss: 0.0018 | Val Loss: 9.5373 | Train Acc: 99.83| Val Acc: 61.06\n",
      "Epoch 3940: | Train Loss: 0.0026 | Val Loss: 9.5880 | Train Acc: 99.83| Val Acc: 61.27\n",
      "Epoch 3941: | Train Loss: 0.0038 | Val Loss: 9.6102 | Train Acc: 99.73| Val Acc: 61.27\n",
      "Epoch 3942: | Train Loss: 0.0022 | Val Loss: 9.5814 | Train Acc: 99.74| Val Acc: 61.07\n",
      "Epoch 3943: | Train Loss: 0.0025 | Val Loss: 9.5805 | Train Acc: 99.73| Val Acc: 61.07\n",
      "Epoch 3944: | Train Loss: 0.0027 | Val Loss: 9.5870 | Train Acc: 99.84| Val Acc: 61.07\n",
      "Epoch 3945: | Train Loss: 0.0032 | Val Loss: 9.5913 | Train Acc: 99.71| Val Acc: 61.17\n",
      "Epoch 3946: | Train Loss: 0.0029 | Val Loss: 9.5961 | Train Acc: 99.77| Val Acc: 61.07\n",
      "Epoch 3947: | Train Loss: 0.0035 | Val Loss: 9.6097 | Train Acc: 99.70| Val Acc: 61.17\n",
      "Epoch 3948: | Train Loss: 0.0035 | Val Loss: 9.6099 | Train Acc: 99.90| Val Acc: 61.27\n",
      "Epoch 3949: | Train Loss: 0.0026 | Val Loss: 9.6184 | Train Acc: 99.80| Val Acc: 61.27\n",
      "Epoch 3950: | Train Loss: 0.0026 | Val Loss: 9.6209 | Train Acc: 99.87| Val Acc: 61.48\n",
      "Epoch 3951: | Train Loss: 0.0027 | Val Loss: 9.5811 | Train Acc: 99.77| Val Acc: 61.48\n",
      "Epoch 3952: | Train Loss: 0.0037 | Val Loss: 9.5511 | Train Acc: 99.67| Val Acc: 61.38\n",
      "Epoch 3953: | Train Loss: 0.0029 | Val Loss: 9.5693 | Train Acc: 99.72| Val Acc: 61.28\n",
      "Epoch 3954: | Train Loss: 0.0043 | Val Loss: 9.5542 | Train Acc: 99.79| Val Acc: 61.18\n",
      "Epoch 3955: | Train Loss: 0.0033 | Val Loss: 9.5286 | Train Acc: 99.77| Val Acc: 61.18\n",
      "Epoch 3956: | Train Loss: 0.0021 | Val Loss: 9.5418 | Train Acc: 99.87| Val Acc: 61.18\n",
      "Epoch 3957: | Train Loss: 0.0032 | Val Loss: 9.5506 | Train Acc: 99.73| Val Acc: 61.37\n",
      "Epoch 3958: | Train Loss: 0.0019 | Val Loss: 9.5128 | Train Acc: 99.90| Val Acc: 61.17\n",
      "Epoch 3959: | Train Loss: 0.0035 | Val Loss: 9.4668 | Train Acc: 99.87| Val Acc: 61.17\n",
      "Epoch 3960: | Train Loss: 0.0023 | Val Loss: 9.4700 | Train Acc: 99.87| Val Acc: 61.07\n",
      "Epoch 3961: | Train Loss: 0.0020 | Val Loss: 9.4488 | Train Acc: 99.90| Val Acc: 61.07\n",
      "Epoch 3962: | Train Loss: 0.0029 | Val Loss: 9.4469 | Train Acc: 99.80| Val Acc: 60.97\n",
      "Epoch 3963: | Train Loss: 0.0035 | Val Loss: 9.4392 | Train Acc: 99.83| Val Acc: 61.19\n",
      "Epoch 3964: | Train Loss: 0.0017 | Val Loss: 9.4446 | Train Acc: 99.87| Val Acc: 61.09\n",
      "Epoch 3965: | Train Loss: 0.0018 | Val Loss: 9.4453 | Train Acc: 99.87| Val Acc: 61.08\n",
      "Epoch 3966: | Train Loss: 0.0023 | Val Loss: 9.4389 | Train Acc: 99.76| Val Acc: 60.88\n",
      "Epoch 3967: | Train Loss: 0.0021 | Val Loss: 9.4650 | Train Acc: 99.84| Val Acc: 60.88\n",
      "Epoch 3968: | Train Loss: 0.0022 | Val Loss: 9.4784 | Train Acc: 99.83| Val Acc: 60.88\n",
      "Epoch 3969: | Train Loss: 0.0034 | Val Loss: 9.4636 | Train Acc: 99.73| Val Acc: 60.88\n",
      "Epoch 3970: | Train Loss: 0.0023 | Val Loss: 9.5094 | Train Acc: 99.84| Val Acc: 60.98\n",
      "Epoch 3971: | Train Loss: 0.0030 | Val Loss: 9.4937 | Train Acc: 99.76| Val Acc: 60.98\n",
      "Epoch 3972: | Train Loss: 0.0022 | Val Loss: 9.5045 | Train Acc: 99.83| Val Acc: 60.98\n",
      "Epoch 3973: | Train Loss: 0.0029 | Val Loss: 9.4938 | Train Acc: 99.74| Val Acc: 60.78\n",
      "Epoch 3974: | Train Loss: 0.0032 | Val Loss: 9.5216 | Train Acc: 99.80| Val Acc: 60.96\n",
      "Epoch 3975: | Train Loss: 0.0026 | Val Loss: 9.5659 | Train Acc: 99.80| Val Acc: 60.87\n",
      "Epoch 3976: | Train Loss: 0.0019 | Val Loss: 9.5852 | Train Acc: 99.92| Val Acc: 60.87\n",
      "Epoch 3977: | Train Loss: 0.0016 | Val Loss: 9.5665 | Train Acc: 99.92| Val Acc: 60.87\n",
      "Epoch 3978: | Train Loss: 0.0020 | Val Loss: 9.5551 | Train Acc: 99.92| Val Acc: 60.87\n",
      "Epoch 3979: | Train Loss: 0.0035 | Val Loss: 9.5695 | Train Acc: 99.83| Val Acc: 60.65\n",
      "Epoch 3980: | Train Loss: 0.0018 | Val Loss: 9.5393 | Train Acc: 99.87| Val Acc: 60.65\n",
      "Epoch 3981: | Train Loss: 0.0021 | Val Loss: 9.5150 | Train Acc: 99.87| Val Acc: 60.66\n",
      "Epoch 3982: | Train Loss: 0.0020 | Val Loss: 9.5459 | Train Acc: 99.89| Val Acc: 60.76\n",
      "Epoch 3983: | Train Loss: 0.0024 | Val Loss: 9.5525 | Train Acc: 99.87| Val Acc: 60.76\n",
      "Epoch 3984: | Train Loss: 0.0020 | Val Loss: 9.5563 | Train Acc: 99.86| Val Acc: 60.76\n",
      "Epoch 3985: | Train Loss: 0.0035 | Val Loss: 9.5507 | Train Acc: 99.80| Val Acc: 60.87\n",
      "Epoch 3986: | Train Loss: 0.0026 | Val Loss: 9.5187 | Train Acc: 99.80| Val Acc: 60.95\n",
      "Epoch 3987: | Train Loss: 0.0026 | Val Loss: 9.5748 | Train Acc: 99.84| Val Acc: 61.05\n",
      "Epoch 3988: | Train Loss: 0.0026 | Val Loss: 9.5479 | Train Acc: 99.76| Val Acc: 60.86\n",
      "Epoch 3989: | Train Loss: 0.0040 | Val Loss: 9.5697 | Train Acc: 99.73| Val Acc: 60.95\n",
      "Epoch 3990: | Train Loss: 0.0022 | Val Loss: 9.5822 | Train Acc: 99.90| Val Acc: 61.06\n",
      "Epoch 3991: | Train Loss: 0.0031 | Val Loss: 9.6043 | Train Acc: 99.93| Val Acc: 61.16\n",
      "Epoch 3992: | Train Loss: 0.0026 | Val Loss: 9.6108 | Train Acc: 99.87| Val Acc: 61.16\n",
      "Epoch 3993: | Train Loss: 0.0031 | Val Loss: 9.5327 | Train Acc: 99.84| Val Acc: 61.06\n",
      "Epoch 3994: | Train Loss: 0.0020 | Val Loss: 9.5408 | Train Acc: 99.87| Val Acc: 61.16\n",
      "Epoch 3995: | Train Loss: 0.0027 | Val Loss: 9.5095 | Train Acc: 99.80| Val Acc: 60.95\n",
      "Epoch 3996: | Train Loss: 0.0030 | Val Loss: 9.4907 | Train Acc: 99.76| Val Acc: 60.95\n",
      "Epoch 3997: | Train Loss: 0.0047 | Val Loss: 9.4884 | Train Acc: 99.80| Val Acc: 61.15\n",
      "Epoch 3998: | Train Loss: 0.0034 | Val Loss: 9.5601 | Train Acc: 99.67| Val Acc: 61.36\n",
      "Epoch 3999: | Train Loss: 0.0038 | Val Loss: 9.5224 | Train Acc: 99.75| Val Acc: 61.36\n",
      "Epoch 4000: | Train Loss: 0.0040 | Val Loss: 9.5204 | Train Acc: 99.81| Val Acc: 60.65\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, EPOCHS + 1)):\n",
    "    train_epoch_loss = 0.0\n",
    "    train_epoch_accuracy = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        \n",
    "        y_train_pred = model(X_train_batch)\n",
    "        \n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_accuracy = multi_accuracy(y_train_pred, y_train_batch)\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_accuracy += train_accuracy.item()\n",
    "        \n",
    "        \n",
    "    scheduler.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        val_epoch_loss = 0.0\n",
    "        val_epoch_accuracy = 0.0\n",
    "\n",
    "        model.eval()\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "\n",
    "            y_val_pred = model(X_val_batch)\n",
    "\n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_accuracy = multi_accuracy(y_val_pred, y_val_batch)\n",
    "\n",
    "            val_epoch_loss += val_loss.item()\n",
    "            val_epoch_accuracy += val_accuracy.item()\n",
    "            \n",
    "    mean_train_accuracy = train_epoch_accuracy / len(train_loader)\n",
    "    mean_val_accuracy = val_epoch_accuracy / len(val_loader)\n",
    "    mean_train_loss = train_epoch_loss / len(train_loader)\n",
    "    mean_val_loss = val_epoch_loss / len(val_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+0:04}: | Train Loss: {mean_train_loss:.4f} | Val Loss: {mean_val_loss:.4f} | Train Acc: {mean_train_accuracy:.2f}| Val Acc: {mean_val_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "01441cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "y_test_pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X_test_batch, _ in test_loader:\n",
    "        X_test_batch = X_test_batch.to(device)\n",
    "        y_test_pred = model(X_test_batch)\n",
    "        y_test_pred_softmax = torch.log_softmax(y_test_pred, dim=1)\n",
    "        _, y_test_pred_tags = torch.max(y_test_pred_softmax, dim = 1)\n",
    "        y_test_pred_list.append(y_test_pred_tags.cpu().numpy())\n",
    "        \n",
    "y_test_pred_list = [a.squeeze().tolist() for a in y_test_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "12c7b20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Real')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test 결과 시각화\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_test, y_test_pred_list)).rename(columns=idx2class, index=idx2class)\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "sns.heatmap(confusion_matrix_df, annot=True)\n",
    "\n",
    "ax.set_xlabel('Predict')\n",
    "ax.set_ylabel('Real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c0762a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(61.0204)\n"
     ]
    }
   ],
   "source": [
    "# test 정확도 계산\n",
    "correct_pred = (y_test == torch.tensor(y_test_pred_list))\n",
    "\n",
    "accuracy = correct_pred.sum() / len(correct_pred)\n",
    "\n",
    "accuracy *= 100.0\n",
    "\n",
    "print('Test accuracy: ', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
